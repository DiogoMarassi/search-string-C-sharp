[
  {
    "source": "semantic_scholar",
    "DOI": "10.1103/PhysRevD.105.044016",
    "title": "Conditional noise deep learning for parameter estimation of gravitational wave events",
    "abstract": "We construct a Bayesian inference deep learning machine for parameter estimation of gravitational wave events of binaries of black hole coalescence. The structure of our deep Bayesian machine adopts the conditional variational autoencoder scheme by conditioning on both the gravitational wave strains and the variations of the amplitude spectral density (ASD) of the detector noise. We show that our deep Bayesian machine is capable of yielding posteriors compatible with the ones from the nested sampling method and better than the one without conditioning on the ASD. Our result implies that the process of parameter estimation can be accelerated significantly by deep learning even with large ASD drifting/variation. We also apply our deep Bayesian machine to the LIGO/Virgo O3 events, the result is compatible with the one by the traditional Bayesian inference method for the gravitational wave events with signal-to-noise ratios higher than typical threshold value. We also discuss some possible ways for future improvement.",
    "authors": [
      "H. Kuo",
      "Feng-Li Lin"
    ],
    "url": "https://arxiv.org/pdf/2107.10730",
    "venue": null,
    "publicationDate": "2021-07-22",
    "CitationCount": 3,
    "type": null,
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.4103/jmss.jmss_47_23",
    "title": "Radiomics based Machine Learning Models for Classification of Prostate Cancer Grade Groups from Multi Parametric MRI Images",
    "abstract": "Purpose: This study aimed to investigate the performance of multiparametric magnetic resonance imaging (mpMRI) radiomic feature-based machine learning (ML) models in classifying the Gleason grade group (GG) of prostate cancer. Methods: In this retrospective study, a total of 203 patients with histopathologically confirmed prostate cancer who underwent mpMRI before prostate biopsy were included. After manual segmentation, radiomic features (RFs) were extracted from T2-weighted, apparent diffusion coefficient, and high b-value diffusion-weighted magnetic resonance imaging (DWMRI). Patients were split into training sets and testing sets according to a ratio of 8:2. A pipeline considering combinations of two feature selection (FS) methods and six ML classifiers was developed and evaluated. The performance of models was assessed using the accuracy, sensitivity, precision, F1-measure, and the area under curve (AUC). Results: On high b-value DWMRI-derived features, a combination of FS method recursive feature elimination (RFE) and classifier random forest achieved the highest performance for classification of prostate cancer into five GGs, with 97.0% accuracy, 98.0% sensitivity, 98.0% precision, and 97.0% F1-measure. The method also achieved an average AUC for GG of 98%. Conclusion: Preoperative mpMRI radiomic analysis based on ML, as a noninvasive approach, showed good performance for classification of prostate cancer into five GGs. Advances in Knowledge: Herein, radiomic models based on preoperative mpMRI and ML were developed to classify prostate cancer into 5 GGs. Our study provides evidence that analysis of quantitative RFs extracted from high b-value DWMRI images based on a combination of FS method RFE and classifier random forest can be applied for multiclass grading of prostate cancer with an accuracy of 97.0%.",
    "authors": [
      "Fatemeh Zandie",
      "Mohammad Salehi",
      "A. Maziar",
      "M. Bayatiani",
      "Reza Paydar"
    ],
    "url": "https://doi.org/10.4103/jmss.jmss_47_23",
    "venue": "Journal of Medical Signals & Sensors",
    "publicationDate": "2024-12-01",
    "CitationCount": 1,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1002/minf.202500067",
    "title": "Comparing Explanations of Molecular Machine Learning Models Generated with Different Methods for the Calculation of Shapley Values",
    "abstract": "Feature attribution methods from explainable artificial intelligence (XAI) provide explanations of machine learning models by quantifying feature importance for predictions of test instances. While features determining individual predictions have frequently been identified in machine learning applications, the consistency of feature importance-based explanations of machine learning models using different attribution methods has not been thoroughly investigated. We have systematically compared model explanations in molecular machine learning. Therefore, a test system of highly accurate compound activity predictions for different targets using different machine learning methods was generated. For these predictions, explanations were computed using methodological variants of the Shapley value formalism, a popular feature attribution approach in machine learning adapted from game theory. Predictions of each model were assessed using a model-agnostic and model-specific Shapley value-based method. The resulting feature importance distributions were characterized and compared by a global statistical analysis using diverse measures. Unexpectedly, methodological variants for Shapley value calculations yielded distinct feature importance distributions for highly accurate predictions. There was only little agreement between alternative model explanations. Our findings suggest that feature importance-based explanations of machine learning predictions should include an assessment of consistency using alternative methods.",
    "authors": [
      "Alec Lamens",
      "Jürgen Bajorath"
    ],
    "url": null,
    "venue": "Molecular Informatics",
    "publicationDate": "2025-03-01",
    "CitationCount": 2,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.18535/ijsrm/v12i12.ec09",
    "title": "Data-Driven Process Optimization Using AI and Statistical Methods in High-Tech Manufacturing",
    "abstract": "High-tech manufacturing industries—including semiconductor fabrication, automotive assembly, and aerospace component production—face increasing demands for precision, efficiency, and adaptability. Traditional process optimization methods such as Design of Experiments (DOE), Six Sigma, and Measurement System Analysis (MSA) have long provided structured frameworks for improving quality and consistency. However, these statistical approaches are often limited by their static nature and reliance on fixed experimental models, which can fall short in rapidly changing or highly complex production environments.\nThis research presents a comprehensive, data-driven framework that integrates classical statistical techniques with modern artificial intelligence (AI) methodologies to enable dynamic and continuous process optimization. By leveraging AI algorithms—such as supervised machine learning models, reinforcement learning, and anomaly detection—alongside DOE, Six Sigma, and MSA, manufacturers can achieve real-time adaptability, enhanced process control, and predictive accuracy. The integration allows for a synergistic approach where AI models are trained using data generated from traditional experimental designs and refined through continuous feedback from manufacturing execution systems and IoT-enabled devices.\nThe effectiveness of the proposed framework is demonstrated through three case studies: (1) semiconductor etching optimization using AI-augmented DOE, (2) torque correction in automotive assembly lines using Six Sigma with machine learning, and (3) defect reduction in aerospace fabrication through predictive maintenance and enhanced MSA protocols. Across these applications, the hybrid approach led to substantial improvements in key performance indicators—yield increases up to 5.2%, defect reductions by as much as 70%, and cycle time decreases of over 15%.\nThese findings confirm that AI does not replace traditional statistical methods but rather enhances their utility by adding flexibility, speed, and the ability to model complex, nonlinear relationships. As manufacturing becomes more digitized and data-rich, integrating AI into established process improvement frameworks will be essential for maintaining global competitiveness, operational resilience, and product excellence. The paper concludes with recommendations for future research on explainable AI, cross-disciplinary training, and standardized integration protocols for industrial deployment.",
    "authors": [
      "Gaurav Rajendra Parashare"
    ],
    "url": "",
    "venue": "International Journal of Scientific Research and Management",
    "publicationDate": "2024-12-30",
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/s25010214",
    "title": "A Comprehensive Survey of Machine Learning Techniques and Models for Object Detection",
    "abstract": "Object detection is a pivotal research domain within computer vision, with applications spanning from autonomous vehicles to medical diagnostics. This comprehensive survey presents an in-depth analysis of the evolution and significant advancements in object detection, emphasizing the critical role of machine learning (ML) and deep learning (DL) techniques. We explore a wide spectrum of methodologies, ranging from traditional approaches to the latest DL models, thoroughly evaluating their performance, strengths, and limitations. Additionally, the survey delves into various metrics for assessing model effectiveness, including precision, recall, and intersection over union (IoU), while addressing ongoing challenges in the field, such as managing occlusions, varying object scales, and improving real-time processing capabilities. Furthermore, we critically examine recent breakthroughs, including advanced architectures like Transformers, and discuss challenges and future research directions aimed at overcoming existing barriers. By synthesizing current advancements, this survey provides valuable insights for enhancing the robustness, accuracy, and efficiency of object detection systems across diverse and challenging applications.",
    "authors": [
      "Μαρία Τρίγκα",
      "Ηλίας Δρίτσας"
    ],
    "url": null,
    "venue": "Sensors",
    "publicationDate": "2025-01-02",
    "CitationCount": 9,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/fi17010041",
    "title": "Digital Twins: Strategic Guide to Utilize Digital Twins to Improve Operational Efficiency in Industry 4.0",
    "abstract": "The Fourth Industrial Revolution, known as Industry 4.0, has transformed the manufacturing landscape by integrating advanced digital technologies, fostering automation, interconnectivity, and data-driven decision-making. Among these innovations, Digital Twins (DTs) have emerged as a pivotal tool, enabling real-time monitoring, simulation, and optimization of production processes. This paper provides a comprehensive exploration of DT technology, offering a strategic framework for its effective implementation within Industry 4.0 environments to enhance operational efficiency. The proposed methodology integrates key enabling technologies such as the Internet of Things (IoT), Artificial Intelligence (AI), and Machine Learning to create accurate digital replicas of manufacturing systems. Through a detailed case study, this work demonstrates how DTs can optimize production processes, reduce downtime, and improve maintenance strategies. The findings highlight DTs’ transformative potential in achieving continuous improvement, competitiveness, and operational excellence. This research aims to provide organizations with actionable insights and a roadmap to leverage DT technology for sustainable industrial innovation.",
    "authors": [
      "Italo Cesidio Fantozzi",
      "Annalisa Santolamazza",
      "Giancarlo Loy",
      "Massimiliano M. Schiraldi"
    ],
    "url": null,
    "venue": "Future Internet",
    "publicationDate": "2025-01-17",
    "CitationCount": 11,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.56294/dm2025545",
    "title": "Diabetes Prediction and Management Using Machine Learning Approaches",
    "abstract": "Diabetes has emerged as a significant global health issue, especially with the increasing number of cases in many countries. This trend Underlines the need for a greater emphasis on early detection and proactive management to avert or mitigate the severe health complications of this disease. Over recent years, machine learning algorithms have shown promising potential in predicting diabetes risk and are beneficial for practitioners. Objective: This study highlights the prediction capabilities of statistical and non-statistical machine learning methods over Diabetes risk classification in 768 samples from the Pima Indians Diabetes Database. It consists of the significant demographic and clinical features of age, body mass index (BMI) and blood glucose levels that greatly depend on the vulnerability against Diabetes. The experimentation assesses the various types of machine learning algorithms in terms of accuracy and effectiveness regarding diabetes prediction. These algorithms include Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, Naive Bayes, Support Vector Machine, Gradient Boosting and Neural Network Models. The results show that the Neural Network algorithm gained the highest predictive accuracy with 78.57%, and then the Random Forest algorithm had the second position with 76.30% accuracy. These findings show that machine learning techniques are not just highly effective. Still, they also can potentially act as early screening tools in predicting Diabetes within a data-driven fashion with valuable information on who is more likely to get affected. In addition, this study can help to realize the potential of machine learning for timely intervention over the longer term, which is a step towards reducing health outcomes and disease burden attributable to Diabetes on healthcare systems.",
    "authors": [
      "Mowafaq Salem Alzboon",
      "Muhyeeddin Alqaraleh",
      "Mohammad Subhi Al-Batah"
    ],
    "url": null,
    "venue": "Data & Metadata",
    "publicationDate": "2025-02-18",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/IHMSC.2015.181",
    "title": "Evolutionary Extreme Learning Machine Based Weighted Nearest-Neighbor Equality Classification",
    "abstract": null,
    "authors": [
      "N. Zhang",
      "Yanpeng Qu",
      "Ansheng Deng"
    ],
    "url": "",
    "venue": "International Conference on Intelligent Human-Machine Systems and Cybernetics",
    "publicationDate": "2015-11-23",
    "CitationCount": 6,
    "type": [
      "Conference"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1080/07038992.2024.2448169",
    "title": "Machine learning approaches to landsat change detection analysis",
    "abstract": "The Landsat mission has captured images of the Earth's surface for over 50 years, and the data have enabled researchers to investigate a vast array of different change phenomena using machine learning models. Landsat-based monitoring research has been influential in geography, forestry, hydrology, ecology, agriculture, geology, and public health. When monitoring Earth's surface change using Landsat data and machine learning, it is essential to consider the implications of the size of the study area, specifics of the machine learning model, and image temporal density. We found that there are two general approaches to Landsat change detection analysis with machine learning: post-classification comparison and sequential imagery stack approaches. The two approaches have different advantages, and the design of an appropriate type of Landsat change detection analysis depends on the task at hand and the available computing resources. This review provides an overview of different Landsat change detection approaches using machine learning, outlines a framework for understanding the relevant considerations, and discusses recent developments such as generative artificial intelligence, explainable machine learning, and ethical analysis considerations.",
    "authors": [
      "Galen Richardson",
      "Anders Knudby",
      "Morgan A. Crowley",
      "M. Sawada",
      "Wenjun Chen"
    ],
    "url": null,
    "venue": "Canadian Journal of Remote Sensing",
    "publicationDate": "2025-01-10",
    "CitationCount": 2,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1515/zna-2025-0050",
    "title": "Locally weighted linear regression–optimized graphene–metal metasurface sensor for high-sensitivity organic compound detection in terahertz regime",
    "abstract": "Abstract This study presents the design and optimization of a graphene–gold–silver metasurface sensor for the highly sensitive detection of organic compounds in the terahertz (THz) regime. By leveraging the plasmonic properties of gold and silver combined with the tunable electronic characteristics of graphene, the sensor demonstrates enhanced molecular interaction and improved detection performance. COMSOL Multiphysics simulations show a high refractive index sensitivity up to the value of 810 GHzRIU −1 and excellent resonance characteristics with a quality factor (Q) of 11.197. The sensor achieves a detection limit (DL) as low as 0.075 RIU and a dynamic range (DR) from 2.765 to 2.555, indicating exceptional sensitivity and broad applicability. Additionally, the integration of machine learning optimization, particularly Locally Weighted Linear Regression (LWLR), improves prediction accuracy, achieving a value of R 2 near to 1. The results highlight the sensor’s real-time, label-free detection capabilities, with a signal-to-noise ratio (SNR) up to the value of 0.377. These findings demonstrate the sensor’s potential for applications in environmental monitoring, biomedical diagnostics, and industrial quality control, offering a significant advancement in THz-based sensing technologies.",
    "authors": [
      "Jacob Wekalao",
      "Ahmed Mehaney",
      "Bashir Salah",
      "Mostafa R. Abukhadra",
      "Hussein A. Elsayed"
    ],
    "url": null,
    "venue": "Zeitschrift für Naturforschung A",
    "publicationDate": "2025-04-07",
    "CitationCount": 15,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1504/ijbm.2022.10048974",
    "title": "Recognition method of unspecified face expressions based on machine learning",
    "abstract": null,
    "authors": [
      "Zheshu Jia",
      "Deyun Chen"
    ],
    "url": "",
    "venue": "International Journal of Biometrics (IJBM)",
    "publicationDate": null,
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1007/978-981-13-1056-0_32",
    "title": "Developing a Testing Framework for Intrusion Detection Algorithms Using Software Defined Networking",
    "abstract": null,
    "authors": [
      "Anton Miguel Suba",
      "Kurt Vincent Bautista",
      "Julio Carlos Tomas Ledesma",
      "W. E. Yu"
    ],
    "url": "",
    "venue": "International Conference on Information Science and Applications",
    "publicationDate": "2018-06-25",
    "CitationCount": 2,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": null,
    "title": "A neural network strategy for supervised classification via the Learning Under Privileged Information paradigm",
    "abstract": null,
    "authors": [
      "Ludovica Sacco",
      "D. Ienco",
      "R. Interdonato"
    ],
    "url": "",
    "venue": "Sistemi Evoluti per Basi di Dati",
    "publicationDate": null,
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1007/s00521-021-05876-0",
    "title": "Stacked neural networks for predicting the membranes performance by treating the pharmaceutical active compounds",
    "abstract": null,
    "authors": [
      "Y. Ammi",
      "L. Khaouane",
      "S. Hanini"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2021-04-08",
    "CitationCount": 8,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1021/acsnano.4c13312",
    "title": "Machine Learning-Assisted High-Donor-Number Electrolyte Additive Screening toward Construction of Dendrite-Free Aqueous Zinc-Ion Batteries",
    "abstract": "The utilization of electrolyte additives has been regarded as an efficient strategy to construct dendrite-free aqueous zinc-ion batteries (AZIBs). However, the blurry screening criteria and time-consuming experimental tests inevitably restrict the application prospect of the electrolyte additive strategy. With the rise of artificial intelligence technology, machine learning (ML) provides an avenue to promote upgrading of energy storage devices. Herein, we proposed an intriguing ML-assisted method to accelerate the development efficiency of electrolyte additives on dendrite-free AZIBs. Concretely, we selected the Gutmann donor number (DN value) as a screen parameter, which can reflect the interaction between solvent molecules and ions, and proposed an integrated ML model that can predict the DN values of organic molecules via molecular fingerprints, thereby achieving the screening of electrolyte additives. Then, combined with experimental tests and theoretical calculations, the influence law of three additive molecules with different DN values on the thermodynamic stability of the Zn anode and its corresponding optimization mechanisms were revealed; the DN values of the additives are in positive correlation with the electrochemical performance of the Zn anode. Especially, an isopropyl alcohol (IPA) additive with a high DN value (36) integrated with various Zn-based cells presented a superior electrochemical performance, including a high calendar life (1500 h), a stable Coulombic efficiency (99% within 450 cycles), and a favorable cycling retention. This work pioneers ML techniques for predicting DN values for electrolyte additives, offering a compelling investigation method for the investigation of AZIBs.",
    "authors": [
      "Haoran Luo",
      "Qianzhi Gou",
      "Yu Zheng",
      "Kaixin Wang",
      "Ruduan Yuan",
      "Sida Zhang",
      "Wei Fang",
      "Ziga Luogu",
      "Yu Lin Hu",
      "Huaping Mei",
      "Bingye Song",
      "Kuan Sun",
      "John Wang",
      "Meng Li"
    ],
    "url": null,
    "venue": "ACS Nano",
    "publicationDate": "2025-01-07",
    "CitationCount": 20,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.3390/en17040925",
    "title": "Insights into Household Electric Vehicle Charging Behavior: Analysis and Predictive Modeling",
    "abstract": "In the era of burgeoning electric vehicle (EV) popularity, understanding the patterns of EV users’ behavior is imperative. This paper examines the trends in household charging sessions’ timing, duration, and energy consumption by analyzing real-world residential charging data. By leveraging the information collected from each session, a novel framework is introduced for the efficient, real-time prediction of important charging characteristics. Utilizing historical data and user-specific features, machine learning models are trained to predict the connection duration, charging duration, charging demand, and time until the next session. These models enhance the understanding of EV users’ behavior and provide practical tools for optimizing the EV charging infrastructure and effectively managing the charging demand. As the transportation sector becomes increasingly electrified, this work aims to empower stakeholders with insights and reliable models, enabling them to anticipate the localized demand and contribute to the sustainable integration of electric vehicles into the grid.",
    "authors": [
      "Ahmad Almaghrebi",
      "Kevin James",
      "Fares al Juheshi",
      "Mahmoud Alahmad"
    ],
    "url": "https://www.mdpi.com/1996-1073/17/4/925/pdf?version=1708077912",
    "venue": "Energies",
    "publicationDate": "2024-02-16",
    "CitationCount": 7,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/a18030156",
    "title": "Quantum Computing and Machine Learning in Medical Decision-Making: A Comprehensive Review",
    "abstract": "Medical decision-making is increasingly integrating quantum computing (QC) and machine learning (ML) to analyze complex datasets, improve diagnostics, and enable personalized treatments. While QC holds the potential to accelerate optimization, drug discovery, and genomic analysis as hardware capabilities advance, current implementations remain limited compared to classical computing in many practical applications. Meanwhile, ML has already demonstrated significant success in medical imaging, predictive modeling, and decision support. Their convergence, particularly through quantum machine learning (QML), presents opportunities for future advancements in processing high-dimensional healthcare data and improving clinical outcomes. This review examines the foundational concepts, key applications, and challenges of these technologies in healthcare, explores their potential synergy in solving clinical problems, and outlines future directions for quantum-enhanced ML in medical decision-making.",
    "authors": [
      "James C. L. Chow"
    ],
    "url": null,
    "venue": "Algorithms",
    "publicationDate": "2025-03-09",
    "CitationCount": 9,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1136/bmj.281.6232.27-a",
    "title": "Drug fever due to oxprenolol.",
    "abstract": "<h3>Abstract</h3> <h3>Background</h3> Little is known about the dynamics of SARS-CoV-2 antigen burden in respiratory samples in different patient populations at different stages of infection. Current rapid antigen tests cannot quantitate and track antigen dynamics with high sensitivity and specificity in respiratory samples. <h3>Methods</h3> We developed and validated an ultra-sensitive SARS-CoV-2 antigen assay with smartphone readout using the Microbubbling Digital Assay previously developed by our group, which is a platform that enables highly sensitive detection and quantitation of protein biomarkers. A computer vision-based algorithm was developed for microbubble smartphone image recognition and quantitation. A machine learning-based classifier was developed to classify the smartphone images based on detected microbubbles. Using this assay, we tracked antigen dynamics in serial swab samples from COVID patients hospitalized in ICU and immunocompromised COVID patients. <h3>Results</h3> The limit of detection (LOD) of the Microbubbling SARS-CoV-2 Antigen Assay was 0.5 pg/mL (10.6 fM) recombinant nucleocapsid (N) antigen or 4000 copies/mL inactivated SARS-CoV-2 virus in nasopharyngeal (NP) swabs, comparable to many rRT-PCR methods. The assay had high analytical specificity towards SARS-CoV-2. Compared to EUA-approved rRT-PCR methods, the Microbubbling Antigen Assay demonstrated a positive percent agreement (PPA) of 97% (95% confidence interval (CI), 92-99%) in symptomatic individuals within 7 days of symptom onset and positive SARS-CoV-2 nucleic acid results, and a negative percent agreement (NPA) of 97% (95% CI, 94-100%) in symptomatic and asymptomatic individuals with negative nucleic acid results. Antigen positivity rate in NP swabs gradually decreased as days-after-symptom-onset increased, despite persistent nucleic acid positivity of the same samples. The computer vision and machine learning-based automatic microbubble image classifier could accurately identify positives and negatives, based on microbubble counts and sizes. Total microbubble volume, a potential marker of antigen burden, correlated inversely with Ct values and days-after-symptom-onset. Antigen was detected for longer periods of time in immunocompromised patients with hematologic malignancies, compared to immunocompetent individuals. Simultaneous detectable antigens and nucleic acids may indicate the presence of replicating viruses in patients with persistent infections. <h3>Conclusions</h3> The Microbubbling SARS-CoV-2 Antigen Assay enables sensitive and specific detection of acute infections, and quantitation and tracking of antigen dynamics in different patient populations at various stages of infection. With smartphone compatibility and automated image processing, the assay is well-positioned to be adapted for point-of-care diagnosis and to explore the clinical implications of antigen dynamics in future studies.",
    "authors": [
      "Koki Hasegawa",
      "Y. Sakamoto",
      "Katsuyoshi Mitsunaga",
      "Helena Midori Kashiwagi"
    ],
    "url": "https://www.bmj.com/content/bmj/281/6232/27.2.full.pdf",
    "venue": "BMJ",
    "publicationDate": "1980-07-05",
    "CitationCount": 10,
    "type": "journal-article",
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s41598-025-85352-0",
    "title": "A python approach for prediction of physicochemical properties of anti-arrhythmia drugs using topological descriptors",
    "abstract": "In recent years, machine learning has gained substantial attention for its ability to predict complex chemical and biological properties, including those of pharmaceutical compounds. This study proposes a machine learning-based quantitative structure-property relationship (QSPR) model for predicting the physicochemical properties of anti-arrhythmia drugs using topological descriptors. Anti-arrhythmic drug development is challenging due to the complex relationship between chemical structure and drug efficacy. To address this, we applied machine learning techniques, specifically linear regression models combined with K-fold cross-validation, to predict critical properties such as Density, Boiling Point, Flash Point, Bioconcentration Factor (BCF), Organic Carbon Partition Coefficient (KOC), Polarizability, and Molar Volume. The models were developed using data from ten anti-arrhythmic drugs ([Formula: see text] to [Formula: see text]). We evaluated the models based on performance metrics such as R and [Formula: see text] and obtained significant results. Most accurate predictions are obtained for polarizability from models with H(G) and [Formula: see text].",
    "authors": [
      "Huiling Qin",
      "Muhammad Zaka Ur Rehman",
      "Muhammad Farhan Hanif",
      "Muhammad Yousaf Bhatti",
      "Muhammad Kamran Siddiqui",
      "Mohamed Abubakar Fiidow"
    ],
    "url": null,
    "venue": "Scientific Reports",
    "publicationDate": "2025-01-11",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/ICMIPE47306.2019.9098233",
    "title": "A Matlab Toolbox for Feature Importance Ranking",
    "abstract": "More attention is paid for the feature importance ranking (FIR), in particular when high-throughput features can be extracted for intelligent diagnosis and personalized medicine. A large number of FIR methods have been proposed, while few are integrated for comparison and real-life applications. In this study, a matlab toolbox is presented and a total of 30 algorithms are collected. Moreover, the toolbox is evaluated on a database of 163 ultrasound images. To each breast lesion, 15 features are handcrafted. And to Figure out an optimal subset of features for classification, all combinations of features are tested and linear support vector machine is used for the malignancy prediction of lesions annotated in ultrasound images. At last, the effectiveness of FIR is analyzed according to performance comparison. The toolbox is available (https://github.com/NicoYuCN/matFIR). In the future work, more FIR methods, feature selection methods and machine learning classifiers will be integrated.",
    "authors": [
      "Shaode Yu",
      "Zhicheng Zhang",
      "Xiaokun Liang",
      "Junjie Wu",
      "Erlei Zhang",
      "Wenjian Qin",
      "Yaoqin Xie"
    ],
    "url": "https://arxiv.org/pdf/2003.08737",
    "venue": null,
    "publicationDate": "2019-11-01",
    "CitationCount": 8,
    "type": [
      "JournalArticle",
      "Conference"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 1
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1038/s41598-018-34671-6",
    "title": "Application of Wearable Inertial Sensors and A New Test Battery for Distinguishing Retrospective Fallers from Non-fallers among Community-dwelling Older People",
    "abstract": "Considering the challenge of population ageing and the substantial health problem among the elderly population from falls, the purpose of this study was to verify whether it is possible to distinguish accurately between older fallers and non-fallers, based on data from wearable inertial sensors collected during a specially designed test battery. A comprehensive but practical test battery using 5 wearable inertial sensors for multifactorial fall risk assessment was designed. This was followed by an experimental study on 196 community-dwelling Korean older women, categorized as fallers (N1 = 82) and non-fallers (N2 = 114) based on prior history of falls. Six machine learning models (logistic regression, naïve bayes, decision tree, random forest, boosted tree and support vector machine) were proposed for faller classification. Results indicated that compared with non-fallers, fallers performed significantly worse on the test battery. In addition, the application of sensor data and support vector machine for faller classification achieved an overall accuracy of 89.4% with 92.7% sensitivity and 84.9% specificity. These findings suggest that wearable inertial sensor based systems show promise for elderly fall risk assessment, which could be implemented in clinical practice to identify “at-risk” individuals reliably to promote proactive fall prevention.",
    "authors": [
      "Hai Qiu",
      "R. Rehman",
      "Xiaoqun Yu",
      "S. Xiong"
    ],
    "url": "https://www.nature.com/articles/s41598-018-34671-6.pdf",
    "venue": "Scientific Reports",
    "publicationDate": "2018-11-05",
    "CitationCount": 65,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 5
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/jmse13030425",
    "title": "Towards Predictive Maintenance in the Maritime Industry: A Component-Based Overview",
    "abstract": "The maritime industry has a significant influence on the global economy, underscoring the need for operational availability and safety through effective maintenance practices. Predictive maintenance emerges as a promising solution compared to conventional maintenance schemes currently employed by the industry, offering proactive failure predictions, reduced downtime events, and extended machinery lifespan. This paper addresses a critical gap in the existing literature by providing a comprehensive overview of the main data-driven PdM systems. Specifically, the review explores common issues found in vessel components (i.e., propulsion, auxiliary, electric, hull), examining how different state-of-the-art PdM architectures, ranging from basic machine learning models to advanced deep learning techniques aim to address them. Additionally, the concepts of centralized machine learning, federated, and transfer learning are also discussed, demonstrating their potential to enhance PdM systems as well as their limitations. Finally, the current challenges hindering adoption are discussed, together with the future directions to advance implementation in the field.",
    "authors": [
      "Alexandros Kalafatelis",
      "Νικόλαος Νομικός",
      "Anastasios Giannopoulos",
      "Georgios Alexandridis",
      "Aikaterini Karditsa",
      "Panagiotis Trakadas"
    ],
    "url": null,
    "venue": "Journal of Marine Science and Engineering",
    "publicationDate": "2025-02-25",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/TENCON.2005.300837",
    "title": "Applying Machine Learning Techniques to Improve Linux Process Scheduling",
    "abstract": null,
    "authors": [
      "A. Negi",
      "K. P. Kishore"
    ],
    "url": "http://www.cs.ucr.edu/%7Ekishore/papers/tencon.pdf",
    "venue": "IEEE Region 10 Conference",
    "publicationDate": "2005-11-01",
    "CitationCount": 42,
    "type": [
      "Conference"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 3
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.33395/sinkron.v8i3.12721",
    "title": "Comparison of Residual Network-50 and Convolutional Neural Network Conventional Architecture For Fruit Image Classification",
    "abstract": "Classification of fruit images using machine learning technology has had a significant impact on human life by enabling accurate recognition of various fruits. With the advancements in technology, machine learning architectures have become increasingly diverse and sophisticated, providing enhanced capabilities for fruit image classification. However, previous studies have primarily focused on classifying fruits at a basic level. Therefore, there is a growing need for the development and application of Fruit Image Classification systems within the community, particularly in the field of agriculture. Such applications can play a pivotal role in leveraging technology to benefit the agricultural sector, empowering users to gain satisfaction and knowledge regarding different fruits through the utilization of these applications. In this study, we employ both a conventional Convolutional Neural Network (CNN) architecture and a Residual Network-50 for fruit image classification. To ensure robust performance evaluation, the dataset is divided into training and testing subsets, with fruits categorized into specific classes. Furthermore, identical preprocessing and optimization techniques are applied to both architectures to maintain consistency and fairness during the evaluation process. The results of our classification experiments on a dataset consisting of 17 different fruit classes reveal that the conventional CNN architecture achieves an impressive accuracy of 0.998 (99%) with a minimal loss of 0.009. On the other hand, the Residual Network-50 demonstrates a slightly lower accuracy of 0.994 (99%) but with a slightly higher loss of 0.02. Despite the higher loss, the Residual Network-50's accuracy remains comparable to that of the conventional architecture, showcasing its potential for fruit image classification. By leveraging the power of machine learning and these advanced architectures, fruit image classification systems can provide valuable insights and assistance to users. They can facilitate informed decision-making in various domains, including agriculture, food production, and consumer education.",
    "authors": [
      "Arie Satia Dharma",
      "Judah Michael Parluhutan Sitorus",
      "Andreas Hatigoran"
    ],
    "url": "https://jurnal.polgan.ac.id/index.php/sinkron/article/download/12721/1847",
    "venue": "SinkrOn",
    "publicationDate": "2023-07-30",
    "CitationCount": 4,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/TIM.2010.2049228",
    "title": "A Study on GPS GDOP Approximation Using Support-Vector Machines",
    "abstract": null,
    "authors": [
      "Chih-Hung Wu",
      "Wei-Han Su",
      "Ya-Wei Ho"
    ],
    "url": "",
    "venue": "IEEE Transactions on Instrumentation and Measurement",
    "publicationDate": null,
    "CitationCount": 74,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1021/jacs.4c15235",
    "title": "Diatomic Palladium Catalyst for Enhanced Photocatalytic Water-Donating Transfer Hydrogenation",
    "abstract": "Diatomic catalysts (DACs) present unique opportunities for harnessing ensemble effects between adjacent metal atoms, thus, expanding the properties of single-atom catalysts (SACs). However, the precise preparation and characterization of this type of catalyst remains challenging. Following a precursor-preselected strategy, here, we report the synthesis of a carbon nitride-supported Pd-DAC, which achieves an excellent yield of 92% for photocatalytic water-donating transfer hydrogenation of 4-vinylphenol to 4-ethylphenol, far exceeding that of other metal species, including Pd single atoms (47%) and nanoparticles (1%). Combining transmission electron microscopy with standardized machine learning atom-detection methods confirms the stabilization of a substantial fraction of dimeric Pd species over carbon nitride. Density functional theory (DFT) simulations associate the outstanding performance of Pd-DAC to enhanced substrate activation in the hydrogenation path compared to Pd-SAC. The work provides criteria for DACs characterization and demonstrates a transfer hydrogenation application that is sustainable and eco-friendly over conventional hydrogenation technologies.",
    "authors": [
      "En Zhao",
      "Jordi Morales‐Vidal",
      "Yue Yang",
      "Sharon Mitchell",
      "Yinlong Zhu",
      "Zhiwei Hu",
      "Jin‐Ming Chen",
      "Shu-Chih Haw",
      "Ting‐Shan Chan",
      "Ziyi Fan",
      "Zhu‐Jun Wang",
      "Núria López",
      "Javier Pérez‐Ramírez",
      "Zupeng Chen"
    ],
    "url": null,
    "venue": "Journal of the American Chemical Society",
    "publicationDate": "2025-01-05",
    "CitationCount": 11,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/a18020074",
    "title": "Optimizing Apache Spark MLlib: Predictive Performance of Large-Scale Models for Big Data Analytics",
    "abstract": "In this study, we analyze the performance of the machine learning operators in Apache Spark MLlib for K-Means, Random Forest Regression, and Word2Vec. We used a multi-node Spark cluster along with collected detailed execution metrics computed from the data of diverse datasets and parameter settings. The data were used to train predictive models that had up to 98% accuracy in forecasting performance. By building actionable predictive models, our research provides a unique treatment for key hyperparameter tuning, scalability, and real-time resource allocation challenges. Specifically, the practical value of traditional models in optimizing Apache Spark MLlib workflows was shown, achieving up to 30% resource savings and a 25% reduction in processing time. These models enable system optimization, reduce the amount of computational overheads, and boost the overall performance of big data applications. Ultimately, this work not only closes significant gaps in predictive performance modeling, but also paves the way for real-time analytics over a distributed environment.",
    "authors": [
      "Leonidas Theodorakopoulos",
      "Aristeidis Karras",
      "George A. Krimpas"
    ],
    "url": null,
    "venue": "Algorithms",
    "publicationDate": "2025-02-01",
    "CitationCount": 16,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1002/smll.202408670",
    "title": "Porous Nanoframe Based Plasmonic Structure With High‐Density Hotspots for the Quantitative Detection of Gaseous Benzaldehyde",
    "abstract": "Abstract Owing to its high sensitivity, surface‐enhanced Raman scattering (SERS) has immense potential for the identification of lung cancer from the variation in volatile biomarkers in the exhaled gas. However, two prevailing factors limit the application of SERS: 1) the adsorption of target molecules into SERS hotspots and 2) the detection specificity in multiple interference environments. To improve the density of the SERS hotspots, 3D Au@Ag‐Au particles are prepared in a porous nanoframes (PPFs) based plasmonic structure, which facilitated a richer local electromagnetic field distribution among the Au nanocubic (NC) cores, Au‐Ag porous nanoframes, and Au nanoparticles, thereby promoting the adsorption probability of gaseous aldehydes into the hotspots. L‐cysteines (l‐Cys)‐modified 3D Au@Ag‐Au PPFs are proposed as a benzaldehyde (BA) gas detection carrier to accurately detect biomarkers in complex exhaled gases and eliminate interference from other components. Unlike the conventional use of 4‐aminothiophenol as a linker molecule, the novel L‐Cys‐modified SERS substrate is sensitive toward the aldehyde molecules and immune to other volatile organic compounds (ethanol, cyclohexane, toluene, etc.). Furthermore, a medical mask consisting of this SERS substrate is designed to realize intelligent detection of gaseous BA concentrations assisted by a machine learning algorithm.",
    "authors": [
      "Guoqiang Fang",
      "Xiang Lin",
      "Jinlei Wu",
      "Wen Xu",
      "Wuliji Hasi",
      "Bin Dong"
    ],
    "url": null,
    "venue": "Small",
    "publicationDate": "2025-01-07",
    "CitationCount": 36,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1021/acs.jctc.4c01449",
    "title": "Multiscale Force Field Model Based on a Graph Neural Network for Complex Chemical Systems",
    "abstract": "Inspired by the QM/MM methodology, the ML/MM approach introduces a new opportunity for multiscale simulation, improving the balance between accuracy and computational efficiency. Benefited from the rapid advancements in molecular embedding methods, density functional theory level quantum mechanical (QM) calculations within the QM/MM framework can be accelerated by several orders of magnitude through the application of machine learning (ML) potential energy surfaces. As a problem inherited from the QM/MM methodology, challenges exist in designing the interactions between machine learning and molecular mechanics (MM) regions. In this study, electrostatic interactions between machine learning and MM atoms are treated by using a graphical neural network based on stationary perturbation theory. In this protocol, we process coordinates and MM charges to yield electrostatic energy and forces, resulting in a high-performance electrostatic embedding ML/MM architecture. The accuracy of the ML/MM energy was validated in aqueous solutions of alanine dipeptide and allyl vinyl ether (AVE). We investigated the transferability of parameters trained from AVE in a single solvent to various other solvents, including water, methanol, dimethyl sulfoxide, toluene, ionic liquids, and water-toluene interface environments. We then established a solvent-free protocol for data set preparation. Comparison of the free energy landscapes of the Claisen rearrangement of AVE in different solvation environments showed the catalytic effect of aqueous solutions, consistent with experiments.",
    "authors": [
      "Zhi‐Ping Xie",
      "Yanheng Li",
      "Yijie Xia",
      "Jun Zhang",
      "Sihao Yuan",
      "Fan Cheng",
      "Yi Yang",
      "Yi Qin Gao"
    ],
    "url": null,
    "venue": "Journal of Chemical Theory and Computation",
    "publicationDate": "2025-02-27",
    "CitationCount": 5,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1161/atvbaha.124.321673",
    "title": "Artificial Intelligence and Machine Learning in Preeclampsia",
    "abstract": "Preeclampsia is a multisystem hypertensive disorder that manifests itself after 20 weeks of pregnancy, along with proteinuria. The pathophysiology of preeclampsia is incompletely understood. Artificial intelligence, especially machine learning with its capability to identify patterns in complex data, has the potential to revolutionize preeclampsia research. These data-driven techniques can improve early diagnosis, personalize risk assessment, uncover the disease’s molecular basis, optimize treatments, and enable remote monitoring. This brief review discusses the recent applications of artificial intelligence and machine learning in preeclampsia management and research, including the improvements these approaches have brought, along with their challenges and limitations.",
    "authors": [
      "Anita T. Layton"
    ],
    "url": null,
    "venue": "Arteriosclerosis Thrombosis and Vascular Biology",
    "publicationDate": "2025-01-02",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1101/2024.09.19.613896",
    "title": "CanDrivR-CS: A Cancer-Specific Machine Learning Framework for Distinguishing Recurrent and Rare Variants",
    "abstract": "Motivation Missense variants play a crucial role in cancer development, and distinguishing between those that frequently occur in cancer genomes and those that are rare may provide valuable insights into important functional mechanisms and consequences. Specifically, if common variants confer growth advantages, they may have undergone positive selection across different patients due to similar selection pressures. Moreover, studies have demonstrated the significance of rare mutations that arise as resistance mechanisms in response to drug treatment. This highlights the importance of understanding the role of both recurrent and rare variants in cancer. In addition to this, most existing tools for variant prediction focus on distinguishing variants found in normal and disease populations, often without considering the specific disease contexts in which these variants arise. Instead, they typically build predictors that generalise across all diseases. Here, we introduce CanDrivR-CS, a set of cancer-specific gradient boosting models designed to distinguish between rare and recurrent cancer variants. Results We curated missense variant data from the International Cancer Genome Consortium (ICGC). Cancer-type-specific models significantly outperformed a baseline pan-cancer model, achieving a maximum leave-one-group-out cross-validation (LOGO-CV) F1 score of up to 90% for CanDrivRSKCM (Skin Cutaneous Melanoma) and 89% for CanDrivR-SKCA (Skin Adenocarcinoma), compared to 79.2% for the baseline model. Notably, DNA shape properties consistently ranked among the top features for distinguishing recurrent and rare variants across all cancers. Specifically, recurrent missense variants frequently occurred in DNA bends and rolls, potentially implicating regions prone to DNA replication errors and acting as mutational hotspots. Availability and Implementation All training and test data, and Python code are available in our CanDrivR-CS GitHub repository: https://github.com/amyfrancis97/CanDrivR-CS.",
    "authors": [
      "Amy Francis",
      "Colin Campbell",
      "Tom Gaunt"
    ],
    "url": "https://doi.org/10.1101/2024.09.19.613896",
    "venue": "bioRxiv",
    "publicationDate": "2024-09-23",
    "CitationCount": 0,
    "type": null,
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.3390/w14081300",
    "title": "An Improved Transfer Learning Model for Cyanobacterial Bloom Concentration Prediction",
    "abstract": "The outbreak of cyanobacterial blooms is a serious water environmental problem, and the harm it brings to aquatic ecosystems and water supply systems cannot be underestimated. It is very important to establish an accurate prediction model of cyanobacterial bloom concentration, which is a challenging issue. Machine learning techniques can improve the prediction accuracy, but a large amount of historical monitoring data is needed to train these models. For some waters with an inconvenient geographical location or frequent sensor failures, there are not enough historical data to train the model. To deal with this problem, a fused model based on a transfer learning method is proposed in this paper. In this study, the data of water environment with a large amount of historical monitoring data are taken as the source domain in order to learn the knowledge of cyanobacterial bloom growth characteristics and train the prediction model. The data of the water environment with a small amount of historical monitoring data are taken as the target domain in order to load the model trained in the source domain. Then, the training set of the target domain is used to participate in the inter-layer fine-tuning training of the model to obtain the transfer learning model. At last, the transfer learning model is fused with a convolutional neural network to obtain the prediction model. Various experiments are conducted for a 2 h prediction on the test set of the target domain. The results show that the proposed model can significantly improve the prediction accuracy of cyanobacterial blooms for the water environment with a low data volume.",
    "authors": [
      "J. Ni",
      "Ruping Liu",
      "Yingqi Li",
      "Guangyi Tang",
      "P. Shi"
    ],
    "url": "https://www.mdpi.com/2073-4441/14/8/1300/pdf?version=1650096933",
    "venue": "Water",
    "publicationDate": "2022-04-16",
    "CitationCount": 10,
    "type": null,
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.3390/sym13030486",
    "title": "Towards Accurate Scene Text Detection with Bidirectional Feature Pyramid Network",
    "abstract": "Scene text detection, this task of detecting text from real images, is a hot research topic in the machine vision community. Most of the current research is based on an anchor box. These methods are complex in model design and time-consuming to train. In this paper, we propose a new Fully Convolutional One-Stage Object Detection (FCOS)-based text detection method that can robustly detect multioriented and multilingual text from natural scene images in a per pixel prediction approach. Our proposed text detector employs an anchor-free approach, unlike state-of-the-art text detectors that do not rely on a predefined anchor box. In order to enhance the feature representation ability of FCOS for text detection tasks, we apply the Bidirectional Feature Pyramid Network (BiFPN) as the backbone network, enhancing the model learning capacity and increasing the receptive field. We demonstrate the superior performance of our method on multioriented (ICDAR-2015, ICDAR-2017 MLT) and horizontal (ICDAR-2013) text detection benchmark tasks. Moreover, our method has an f-measure of 88.65 and 86.32 for the benchmark datasets ICDAR 2013 and ICDAR 2015, respectively, and 80.75 for the ICDAR-2017 MLT dataset.",
    "authors": [
      "Dongping Cao",
      "Jiachen Dang",
      "Yong Zhong"
    ],
    "url": "https://www.mdpi.com/2073-8994/13/3/486/pdf?version=1615970497",
    "venue": "Symmetry",
    "publicationDate": "2021-03-16",
    "CitationCount": 8,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 1
  },
  {
    "source": "open_alex",
    "DOI": "10.1016/j.molcel.2025.01.034",
    "title": "Predictomes, a classifier-curated database of AlphaFold-modeled protein-protein interactions",
    "abstract": "Protein-protein interactions (PPIs) are ubiquitous in biology, yet a comprehensive structural characterization of the PPIs underlying cellular processes is lacking. AlphaFold-Multimer (AF-M) has the potential to fill this knowledge gap, but standard AF-M confidence metrics do not reliably separate relevant PPIs from an abundance of false positive predictions. To address this limitation, we used machine learning on curated datasets to train a structure prediction and omics-informed classifier (SPOC) that effectively separates true and false AF-M predictions of PPIs, including in proteome-wide screens. We applied SPOC to an all-by-all matrix of nearly 300 human genome maintenance proteins, generating ∼40,000 predictions that can be viewed at predictomes.org, where users can also score their own predictions with SPOC. High-confidence PPIs discovered using our approach enable hypothesis generation in genome maintenance. Our results provide a framework for interpreting large-scale AF-M screens and help lay the foundation for a proteome-wide structural interactome.",
    "authors": [
      "E. Schmid",
      "Johannes C. Walter"
    ],
    "url": null,
    "venue": "Molecular Cell",
    "publicationDate": "2025-02-01",
    "CitationCount": 14,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1186/s12967-025-06081-6",
    "title": "Identification and validation of the important role of KIF11 in the development and progression of endometrial cancer",
    "abstract": "Human kinesin family member 11 (KIF11) plays a vital role in regulating the cell cycle and is implicated in the tumorigenesis and progression of various cancers, but its role in endometrial cancer (EC) is still unclear. Our current research explored the prognostic value, biological function and targeting strategy of KIF11 in EC through approaches including bioinformatics, machine learning and experimental studies. The GSE17025 dataset from the GEO database was analyzed via the limma package to identify differentially expressed genes (DEGs) in EC. Functional enrichment analysis of the DEGs was conducted using Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) enrichment analyses. DEGs were further screened for hub genes through protein–protein interaction (PPI) network analysis and machine learning. The role of the hub gene KIF11 in EC was analyzed using clinical data from the TCGA database. The expression of KIF11 in EC was subsequently validated in clinical samples. In vitro experiments were utilized to evaluate the effects of KIF11 on biological functions such as proliferation, migration, apoptosis, and the cell cycle in endometrial cancer cells. A total of 877 DEGs, which are widely involved in important biological processes such as cell division, tubulin binding, and the cell cycle, were identified. Through PPI network analysis and machine learning, KIF11 was selected as the hub gene for subsequent analysis and experimental validation. An analysis of TCGA data revealed that KIF11 is highly expressed in EC and is associated with tumor grade, stage, and a low survival rate. The overexpression of KIF11 in tumor tissues was further confirmed in EC patient samples. KIF11 knockdown had inhibitory effects on cell proliferation, migration and invasion. Flow cytometry analysis revealed that KIF11 knockdown induced G2/M phase arrest and promoted apoptosis in EC cells. Our study demonstrated that KIF11 was upregulated in EC and was strongly associated with a poor prognosis. Notably, we found that reduced KIF11 expression inhibited EC cell proliferation, migration and invasion. KIF11 knockdown caused more EC cells to arrest in the G2/M phase and undergo apoptosis. The findings of our study emphasized that KIF11 may be a promising prognostic biomarker and therapeutic target for EC patients.",
    "authors": [
      "Biying Wang",
      "Lunmin Bao",
      "Xiaoduo Li",
      "Guang Sun",
      "Yang Wu",
      "Nanzi Xie",
      "Lei Ling",
      "Wei Chen",
      "Hailong Zhang",
      "Man Chen",
      "Xiaofeng Zhao",
      "Xiufang Wan",
      "Rui Yuan",
      "Hongmei Jiang"
    ],
    "url": null,
    "venue": "Journal of Translational Medicine",
    "publicationDate": "2025-01-13",
    "CitationCount": 5,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": null,
    "title": "Software Behavior: Automatic Classification and its Applications",
    "abstract": null,
    "authors": [
      "J. Bowring",
      "James M. Rehg",
      "M. J. Harrold"
    ],
    "url": "",
    "venue": null,
    "publicationDate": null,
    "CitationCount": 9,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/ICIRCA54612.2022.9985747",
    "title": "A Systematic Review of Machine Learning Approaches for Classifying Indian Sign Language Gestures and Facial Expressions",
    "abstract": "Indian Sign Language is the primary mode of communication known to persons who use Indian Sign Language for people who have hearing or language deficits. Different types of machine learning models are used to broaden the scope of communication for those with impairments and illiteracy. There are numerous machine learning models for analyzing gestures, postures, and facial recognition in Indian Sign Language for single-handed and double-handed signals. The present study on hand gestures, recognition, and translation intends to build an essential foundation for developing a platform to facilitate communication for the s pecially-abled with anyone. Machine learning algorithms generally focus on letter recognition or a few fundamental indicators. Communication is essential for exchanging ideas, thoughts, and feelings. Sign language is a kind of communication that uses hand motions. This is aimed toward those with impairments such as muteness and deafness. Machine learning, a branch of artificial intelligence, will aid in identifying various hand motions and predicting the language created by those inputs based on those inputs[2]. Sign language has a grammar that is unique from and independent of English. When compared to English, SL allows for far more freedom in word order. Tense is marked morphologically on verbs in English, but SL (like many other languages, such as Indian Sign Language) communicates tense lexically using temporal adverbs. The structure of ISL and English differs at the phonological level as well. Signed languages, like spoken languages, include a degree of sublexical structure that includes segments and combinatorial rules; however, phonological elements are manual rather than vocal. The way spatial information is conveyed in English and ISL differs substantially. All Deaf people are illiterate in written English. As an output, the SL text can be produced. SL is just physically executed English, where English and SL share the identical linguistic structure-that one is a straight encoding of the other. Many software designers mistakenly believe that deaf users can always access printed the English language in a user interface. Many designers feel that if auditory information is also supplied as written English, the deaf user's demands will be addressed. Prepositions such as “in,” “on,” and “under” are used to indicate locative information in English, as in many other spoken languages. On the other hand, SL encodes locative and motion information via verbal classifier formulations in which hand shape morphemes define item type, and the location of the hands in signing space schematically depicts the spatial relationship between two things. Thus, English and ASL differ significantly in phonological, morphological, and syntactic areas.",
    "authors": [
      "Manpreet Singh Bajwa",
      "G. Gandhi"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2022-09-21",
    "CitationCount": 0,
    "type": [
      "Conference",
      "Review"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/SANER50967.2021.00046",
    "title": "On the Co-evolution of ML Pipelines and Source Code - Empirical Study of DVC Projects",
    "abstract": "The growing popularity of machine learning (ML) applications has led to the introduction of software engineering tools such as Data Versioning Control (DVC), MLFlow and Pachyderm that enable versioning ML data, models, pipelines and model evaluation metrics. Since these versioned ML artifacts need to be synchronized not only with each other, but also with the source and test code of the software applications into which the models are integrated, prior findings on co-evolution and coupling between software artifacts might need to be revisited. Hence, in order to understand the degree of coupling between ML-related and other software artifacts, as well as the adoption of ML versioning features, this paper empirically studies the usage of DVC in 391 Github projects, 25 of which in detail. Our results show that more than half of the DVC files in a project are changed at least once every one-tenth of the project’s lifetime. Furthermore, we observe a tight coupling between DVC files and other artifacts, with 1/4 pull requests changing source code and 1/2 pull requests changing tests requiring a change to DVC files. As additional evidence of the observed complexity associated with adopting ML-related software engineering tools like DVC, an average of 78% of the studied projects showed a non-constant trend in pipeline complexity.",
    "authors": [
      "Amine Barrak",
      "Ellis E. Eghan",
      "Bram Adams"
    ],
    "url": "",
    "venue": "IEEE International Conference on Software Analysis, Evolution, and Reengineering",
    "publicationDate": "2021-03-01",
    "CitationCount": 34,
    "type": [
      "JournalArticle",
      "Conference"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 4
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1021/acs.jcim.9b00313",
    "title": "Learning To Predict Reaction Conditions: Relationships between Solvent, Molecular Structure, and Catalyst",
    "abstract": "Reaction databases provide a great deal of useful information to assist planning of experiments, but do not provide any interpretation or chemical concepts to accompany this information. In this work reactions are labeled with experimental conditions and network analysis shows that consistencies within clusters of data points can be leveraged to organize this information. In particular, this analysis shows how particular experimental conditions (specifically solvent) are effective in enabling specific organic reactions (Friedel-Crafts, Aldol addition, Claisen condensation, Diels-Alder, and Wittig), including variations within each reaction class. An example of network analysis is shown in the graphical abstract, where data points for a Claisen condensation reaction break into clusters that depend on the catalyst and chemical structure. This type of clustering, which mimics how a chemist reasons, is derived directly from the network. Therefore the findings of this work could augment synthesis planning by providing predictions in a fashion that mimics human chemists. To numerically evaluate solvent prediction ability, three methods are compared: network analysis (through the k-nearest neighbor algorithm), a support vector machine, and a deep neural network. The most accurate method in 4 of the 5 test cases is the network analysis, with deep neural networks also showing good prediction scores. The network analysis tool was evaluated by an expert panel of chemists, who generally agreed that the algorithm produced accurate solvent choices while simultaneously being transparent in the underlying reasons for its predictions.",
    "authors": [
      "E. Walker",
      "Joshua A Kammeraad",
      "John W. Goetz",
      "Michael T. Robo",
      "Ambuj Tewari",
      "P. Zimmerman"
    ],
    "url": "https://figshare.com/articles/journal_contribution/Learning_To_Predict_Reaction_Conditions_Relationships_between_Solvent_Molecular_Structure_and_Catalyst/9681719/1/files/17344115.pdf",
    "venue": "Journal of Chemical Information and Modeling",
    "publicationDate": "2019-08-05",
    "CitationCount": 39,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/s25041169",
    "title": "From Data to Insights: Modeling Urban Land Surface Temperature Using Geospatial Analysis and Interpretable Machine Learning",
    "abstract": "This study introduces an innovative machine learning method to model the spatial variation of land surface temperature (LST) with a focus on the urban center of Da Nang, Vietnam. Light Gradient Boosting Machine (LightGBM), support vector machine, random forest, and Deep Neural Network are employed to establish functional relationships between urban LST and its influencing factors. The machine learning approaches are trained and validated using remote sensing data from 2014, 2019, and 2024. Various explanatory variables representing topographical and spatial characteristics, as well as urban landscapes, are used. Experimental results show that LightGBM outperforms other benchmark methods. In addition, Shapley Additive Explanations are utilized to clarify the impact of the factors affecting LST. The analysis outcomes indicate that while the importance of these variables changes over time, urban density and greenspace density consistently emerge as the most influential factors. LightGBM attained R2 values of 0.85, 0.92, and 0.91 for the years 2014, 2019, and 2024, respectively. The findings of this work can be helpful for deeper understanding of urban heat stress dynamics and facilitate urban planning.",
    "authors": [
      "Nhat‐Duc Hoang",
      "Van-Duc Tran",
      "Thanh‐Canh Huynh"
    ],
    "url": null,
    "venue": "Sensors",
    "publicationDate": "2025-02-14",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1093/jamia/ocae278",
    "title": "Machine learning-based infection diagnostic and prognostic models in post-acute care settings: a systematic review",
    "abstract": "OBJECTIVES\nThis study aims to (1) review machine learning (ML)-based models for early infection diagnostic and prognosis prediction in post-acute care (PAC) settings, (2) identify key risk predictors influencing infection-related outcomes, and (3) examine the quality and limitations of these models.\n\n\nMATERIALS AND METHODS\nPubMed, Web of Science, Scopus, IEEE Xplore, CINAHL, and ACM digital library were searched in February 2024. Eligible studies leveraged PAC data to develop and evaluate ML models for infection-related risks. Data extraction followed the CHARMS checklist. Quality appraisal followed the PROBAST tool. Data synthesis was guided by the socio-ecological conceptual framework.\n\n\nRESULTS\nThirteen studies were included, mainly focusing on respiratory infections and nursing homes. Most used regression models with structured electronic health record data. Since 2020, there has been a shift toward advanced ML algorithms and multimodal data, biosensors, and clinical notes being significant sources of unstructured data. Despite these advances, there is insufficient evidence to support performance improvements over traditional models. Individual-level risk predictors, like impaired cognition, declined function, and tachycardia, were commonly used, while contextual-level predictors were barely utilized, consequently limiting model fairness. Major sources of bias included lack of external validation, inadequate model calibration, and insufficient consideration of data complexity.\n\n\nDISCUSSION AND CONCLUSION\nDespite the growth of advanced modeling approaches in infection-related models in PAC settings, evidence supporting their superiority remains limited. Future research should leverage a socio-ecological lens for predictor selection and model construction, exploring optimal data modalities and ML model usage in PAC, while ensuring rigorous methodologies and fairness considerations.",
    "authors": [
      "Zidu Xu",
      "Danielle Scharp",
      "Mollie Hobensack",
      "Jiancheng Ye",
      "Jungang Zou",
      "Sirui Ding",
      "Jingjing Shang",
      "Maxim Topaz"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2024-11-12",
    "CitationCount": 1,
    "type": [
      "JournalArticle",
      "Review"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1057/s41599-021-00792-z",
    "title": "Informing action for United Nations SDG target 8.7 and interdependent SDGs: Examining modern slavery from space",
    "abstract": "This article provides an example of the ways in which remote sensing, Earth observation, and machine learning can be deployed to provide the most up to date quantitative portrait of the South Asian ‘Brick Belt’, with a view to understanding the extent of the prevalence of modern slavery and exploitative labour. This analysis represents the first of its kind in estimating the spatiotemporal patterns in the Bull’s Trench Kilns across the Brick Belt, as well as its connections with various UN Sustainable Development Goals (SDGs). With a principal focus on Sustainable Development Goal Target 8.7 regarding the effective measures to end modern slavery by 2030, the article provides additional evidence on the intersections that exist between SDG 8.7 and those relating to urbanisation (SDG 11, 12), environmental degradation and pollution (SDG 3, 14, 15), and climate change (SDG 13). Our findings are then used to make a series of pragmatic suggestions for mitigating the most extreme SDG risks associated with brick production in ways that can improve human lives and human freedom.",
    "authors": [
      "D. Boyd",
      "Bertrand Perrat",
      "Xiaodong Li",
      "B. Jackson",
      "T. Landman",
      "F. Ling",
      "K. Bales",
      "A. Choi-Fitzpatrick",
      "James Goulding",
      "S. Marsh",
      "G. Foody"
    ],
    "url": "https://www.nature.com/articles/s41599-021-00792-z.pdf",
    "venue": "Humanities and Social Sciences Communications",
    "publicationDate": "2021-05-14",
    "CitationCount": 15,
    "type": null,
    "isOpenAccess": true,
    "relevanceMetric": 1
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.3390/data10050073",
    "title": "A Data-Driven Approach to Tourism Demand Forecasting: Integrating Web Search Data into a SARIMAX Model",
    "abstract": "Tourism is a core sector of Singapore’s economy, contributing significantly to Gross Domestic Product (GDP) and employment. Accurate tourism demand forecasting is essential for strategic planning, resource allocation, and economic stability, particularly in the post-COVID-19 era. This study develops a SARIMAX-based forecasting model to predict monthly visitor arrivals to Singapore, integrating web search data from Google Trends and external factors. To enhance model accuracy, a systematic selection process was applied to identify the effective subset of external variables. Results of the empirical experiments demonstrate that the proposed SARIMAX model outperforms traditional univariate models, including SARIMA, Holt–Winters, and Prophet, as well as machine learning-based approaches such as Long Short-Term Memory (LSTM) and Recurrent Neural Networks (RNNs). When forecasting the 24-month period of 2023 and 2024, the proposed model achieves the lowest Mean Absolute Percentage Error (MAPE) of 7.32%.",
    "authors": [
      "Geun-Cheol Lee"
    ],
    "url": "",
    "venue": "International Conference on Data Technologies and Applications",
    "publicationDate": "2025-05-10",
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1167/iovs.12-11449",
    "title": "Automatic drusen quantification and risk assessment of age-related macular degeneration on color fundus images.",
    "abstract": "PURPOSE\nTo evaluate a machine learning algorithm that allows for computer-aided diagnosis (CAD) of nonadvanced age-related macular degeneration (AMD) by providing an accurate detection and quantification of drusen location, area, and size.\n\n\nMETHODS\nColor fundus photographs of 407 eyes without AMD or with early to moderate AMD were randomly selected from a large European multicenter database. A machine learning system was developed to automatically detect and quantify drusen on each image. Based on detected drusen, the CAD software provided a risk assessment to develop advanced AMD. Evaluation of the CAD system was performed using annotations made by two blinded human graders.\n\n\nRESULTS\nFree-response receiver operating characteristics (FROC) analysis showed that the proposed system approaches the performance of human observers in detecting drusen. The estimated drusen area showed excellent agreement with both observers, with mean intraclass correlation coefficients (ICC) larger than 0.85. Maximum druse diameter agreement was lower, with a maximum ICC of 0.69, but comparable to the interobserver agreement (ICC = 0.79). For automatic AMD risk assessment, the system achieved areas under the receiver operating characteristic (ROC) curve of 0.948 and 0.954, reaching similar performance as human observers.\n\n\nCONCLUSIONS\nA machine learning system capable of separating high-risk from low-risk patients with nonadvanced AMD by providing accurate detection and quantification of drusen, was developed. The proposed method allows for quick and reliable diagnosis of AMD, opening the way for large dataset analysis within population studies and genotype-phenotype correlation analysis.",
    "authors": [
      "Mark J. J. P. van Grinsven",
      "Y. Lechanteur",
      "Johannes P. H. van de Ven",
      "B. van Ginneken",
      "C. Hoyng",
      "T. Theelen",
      "C. I. Sánchez"
    ],
    "url": "https://repository.ubn.ru.nl//bitstream/handle/2066/118034/118034.pdf",
    "venue": "Investigative Ophthalmology and Visual Science",
    "publicationDate": "2013-04-01",
    "CitationCount": 48,
    "type": [
      "JournalArticle",
      "Study"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 2
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/app15041781",
    "title": "Emerging Applications of Machine Learning in 3D Printing",
    "abstract": "Three-dimensional (3D) printing techniques already enable the precise deposition of many materials, becoming a promising approach for materials engineering, mechanical engineering, or biomedical engineering. Recent advances in 3D printing enable scientists and engineers to create models with precisely controlled and complex microarchitecture, shapes, and surface finishes, including multi-material printing. The incorporation of artificial intelligence (AI) at various stages of 3D printing has made it possible to reconstruct objects from images (including, for example, medical images), select and optimize materials and the printing process, and monitor the lifecycle of products. New emerging opportunities are provided by the ability of machine learning (ML) to analyze complex data sets and learn from previous (historical) experience and predictions to dynamically optimize and individuate products and processes. This includes the synergistic capabilities of 3D printing and ML for the development of personalized products.",
    "authors": [
      "Izabela Rojek",
      "Dariusz Mikołajewski",
      "Marcin Kempiński",
      "Krzysztof Galas",
      "Adrianna Piszcz"
    ],
    "url": null,
    "venue": "Applied Sciences",
    "publicationDate": "2025-02-10",
    "CitationCount": 9,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1002/vnl.22195",
    "title": "Mechanical performance optimization in <scp>FFF 3D</scp> printing using Taguchi design and machine learning approach with <scp>PLA</scp>/walnut Shell composites filaments",
    "abstract": "Abstract This study explores the optimization of mechanical properties in 3D‐printed components made from a Polylactic Acid (PLA) and Walnut Shell Composite using Fused Filament Fabrication (FFF). Employing a machine learning‐based approach, the research identifies the optimal regression model for predicting relationships between printing parameters and material properties. A Taguchi L18 design is used to minimize experiment count while accurately determining parameter levels. Testing was conducted on a composite containing 30% walnut shell fibers, with the Ultimate Tensile Strength (UTS) and Elastic Modulus (E) measured as per ASTM D638 standards. Experimental factors included Layer Thickness (LT), Nozzle Temperature (NT), Deposition Angle (DA), and Printing Speed (PS). Using Analysis of Variance (ANOVA) and machine learning techniques, the effects of these parameters on UTS and E were evaluated. Results highlight the deposition angle as the dominant parameter, with machine learning models, especially Random Forest Regression, providing highly accurate predictions. This approach presents a novel, data‐driven method for optimizing 3D printing processes with sustainable, composite materials. Highlights Higher UTS and E achieved with optimized PLA/walnut shell composite. Deposition angle is the key element of mechanical performance in FFF printing. Layer thickness is important to improve Elastic Modulus. Statistical and machine learning techniques combined for sustainable printing. Improved machine learning process understanding for 3D printed components.",
    "authors": [
      "Arslan Kaptan"
    ],
    "url": null,
    "venue": "Journal of Vinyl and Additive Technology",
    "publicationDate": "2025-01-18",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1016/j.bdr.2017.07.002",
    "title": "Tensor Decomposition Based Approach for Training Extreme Learning Machines",
    "abstract": null,
    "authors": [
      "Nikhitha K. Nair",
      "S. Asharaf"
    ],
    "url": "",
    "venue": "Big Data Research",
    "publicationDate": "2017-12-01",
    "CitationCount": 9,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 1
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.35940/ijitee.d1004.0394s220",
    "title": "Deep Learning based Effective Steganalysis",
    "abstract": "There is an evident paradigm shift in steganalysis techniques with discovery of deep learning networks. As steganalysis is a classification task, it is done by machine learning classifiers and ensembles of them. But with the proliferation of deep learning and Convolutional Neural Networks in many areas, the performance of steganalysis techniques have jumped up to a another high, because of the application of Convolutional Neural Networks. The traditional steganalysis techniques consists two important steps, i.e., feature extraction and classification; where as deep learning networks learn the features automatically, eliminating the need of extraction of handcrafted features. Because of this feature CNNs were highly successful in image recognition and image classification techniques. In addition to that, feature extraction and classification are combined together in deep learning hence classification would be more effective because of the learning of the features which are really important for classification. But in Steganalysis the task is to detect very subtle and weak noise created by the hidden data with steganography techniques. We have designed a deep CNN architecture customized for steganalysis task based on existing residual neural networks frame. We have introduced a descriptor to capture the inter pixel dependencies and which acts as an indicator for weightage of a particular feature maps. Thus the classifier can give more weightage to effective feature maps instead of treating all the feature maps equally. We have also used a gating mechanism by using sigmoid function after nonlinear activation function sandwiched between two fully connected layers. This enhancement to the existing deep residual neural networks has given better results in terms of error detection rate compared to the other deep learning based steganalysis techniques.",
    "authors": [],
    "url": "https://doi.org/10.35940/ijitee.d1004.0394s220",
    "venue": null,
    "publicationDate": "2020-03-15",
    "CitationCount": 0,
    "type": null,
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1021/acs.molpharmaceut.4c00744",
    "title": "Computational Methods for Modeling Lipid-Mediated Active Pharmaceutical Ingredient Delivery",
    "abstract": "Lipid-mediated delivery of active pharmaceutical ingredients (API) opened new possibilities in advanced therapies. By encapsulating an API into a lipid nanocarrier (LNC), one can safely deliver APIs not soluble in water, those with otherwise strong adverse effects, or very fragile ones such as nucleic acids. However, for the rational design of LNCs, a detailed understanding of the composition-structure-function relationships is missing. This review presents currently available computational methods for LNC investigation, screening, and design. The state-of-the-art physics-based approaches are described, with the focus on molecular dynamics simulations in all-atom and coarse-grained resolution. Their strengths and weaknesses are discussed, highlighting the aspects necessary for obtaining reliable results in the simulations. Furthermore, a machine learning, i.e., data-based learning, approach to the design of lipid-mediated API delivery is introduced. The data produced by the experimental and theoretical approaches provide valuable insights. Processing these data can help optimize the design of LNCs for better performance. In the final section of this Review, state-of-the-art of computer simulations of LNCs are reviewed, specifically addressing the compatibility of experimental and computational insights.",
    "authors": [
      "Markéta Paloncýová",
      "Mariana Valério",
      "Ricardo Nascimento dos Santos",
      "Petra Kührová",
      "Martin Šrejber",
      "Petra Čechová",
      "Dimitar A. Dobchev",
      "Akshay Balsubramani",
      "Pavel Banáš",
      "Vikram Agarwal",
      "Paulo C. T. Souza",
      "Michal Otyepka"
    ],
    "url": "https://pubs.acs.org/doi/pdf/10.1021/acs.molpharmaceut.4c00744?ref=article_openPDF",
    "venue": "Molecular Pharmaceutics",
    "publicationDate": "2025-01-29",
    "CitationCount": 9,
    "type": "journal-article",
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1016/j.procs.2024.08.044",
    "title": "An empirical analysis of ESG and financial performance of clean energy companies through unsupervised machine learning",
    "abstract": null,
    "authors": [
      "Mayank Parashar",
      "Ritika Jaiswal",
      "Manish Sharma"
    ],
    "url": "https://doi.org/10.1016/j.procs.2024.08.044",
    "venue": null,
    "publicationDate": null,
    "CitationCount": 3,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.18488/76.v9i1.2983",
    "title": "Machine Learning and Deep Learning Based Phishing Websites Detection: The Current Gaps and Next Directions",
    "abstract": "There are many phishing websites detection techniques in literature, namely white-listing, black-listing, visual-similarity, heuristic-based, and others. However, detecting zero-hour or newly designed phishing website attacks is an inherent property of machine learning and deep learning techniques. By considering a promising solution of machine learning and deep learning techniques, researchers have made a great deal of effort to tackle the this problem, which persists due to attackers constantly devising novel strategies to exploit vulnerability or gaps in existing anti-phishing measures. In this study, an extensive effort has been made to rigorously review recent studies focusing on Machine Learning and Deep Learning Based Phishing Websites Detection to excavate the root cause of the aforementioned problems and offer suitable solutions. The study followed the significant criterion to search, download, and screen relevant studies, then to evaluate criterion-based selected studies. The findings show that significant research gaps are available in the rigorously reviewed studies. These gaps are mainly related to imbalanced dataset usage, improper selection of dataset source(s), the unjustified reason for using specific train-test dataset split ratio, scientific disputes on website features inclusion and exclusion, lack of universal consensus on phishing website lifespans and on what is defining a small dataset size, and run-time analysis issues. The study clearly presented a summary of the comparative analysis performed on each reviewed research work so that future researchers could use it as a structured guideline to develop a novel solution for anti-phishing website attacks.",
    "authors": [
      "Kibreab Adane",
      "B. Beyene"
    ],
    "url": "https://archive.conscientiabeam.com/index.php/76/article/download/2983/6434",
    "venue": "Review of Computer Engineering Research",
    "publicationDate": "2022-05-06",
    "CitationCount": 13,
    "type": [
      "Review"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 1
  },
  {
    "source": "open_alex",
    "DOI": "10.1002/ece3.70736",
    "title": "Machine Learning and Spatio Temporal Analysis for Assessing Ecological Impacts of the Billion Tree Afforestation Project",
    "abstract": "ABSTRACT This study evaluates the Billion Tree Afforestation Project (BTAP) in Pakistan's Khyber Pakhtunkhwa (KPK) province using remote sensing and machine learning. Applying Random Forest (RF) classification to Sentinel‐2 imagery, we observed an increase in tree cover from 25.02% in 2015 to 29.99% in 2023 and a decrease in barren land from 20.64% to 16.81%, with an accuracy above 85%. Hotspot and spatial clustering analyses revealed significant vegetation recovery, with high‐confidence hotspots rising from 36.76% to 42.56%. A predictive model for the Normalized Difference Vegetation Index (NDVI), supported by SHAP analysis, identified soil moisture and precipitation as primary drivers of vegetation growth, with the ANN model achieving an R 2 of 0.8556 and an RMSE of 0.0607 on the testing dataset. These results demonstrate the effectiveness of integrating machine learning with remote sensing as a framework to support data‐driven afforestation efforts and inform sustainable environmental management practices.",
    "authors": [
      "Kaleem Mehmood",
      "Shoaib Ahmad Anees",
      "Sultan Muhammad",
      "Fahad Shahzad",
      "Qijing Liu",
      "Waseem Razzaq Khan",
      "Mansour Shrahili",
      "Mohammad Javed Ansari",
      "Timothy Dube"
    ],
    "url": null,
    "venue": "Ecology and Evolution",
    "publicationDate": "2025-02-01",
    "CitationCount": 11,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.63180/jcsra.thestap.2025.3.2",
    "title": "Adversarial Attack Detection in Industrial Control Systems Using LSTM-Based Intrusion Detection and Black-Box Defense Strategies",
    "abstract": "In industrial control systems (ICS), neural networks are increasingly being utilized to detect intrusions. The term ICS refers to a group of controlling technology and associated equipment that includes the devices, systems, networks, and controllers that are used to manage and/or execute manufacturing processes. Each ICS is developed to successfully handle work digitally and operates differently depending on the business. ICS devices and procedures are now found in practically every industry sector and key infrastructure, including production, transportation, power, and treatment plants. To avoid detection, attackers who aim to inflict harm on an ICS may resort to techniques such as adversarial examples to mask their attacks. ICS-based autoregressive intrusion detection systems (IDSs) are the focus of this study because of the unique issues that arise when being attacked. The attacker here is an LSTM-based IDS that can compromise a ICSs subset of sensors. In the wild cyber-physical attacks take place in ICSs that are masked from the IDS by the attacker manipulating data provided to it. Automation of ICS intrusion detection has become more flexible and efficient thanks to the growth and use of IDSs based on machine learning. Adversarial machine learning (AML), a term coined to describe cyberattacks on learning models, has been formed developed in response to the advent of the IDS. In ICSs, such attacks can have disastrous repercussions if the IDS is bypassed. Delay in attack detection could lead to damage to infrastructure, financial loss, and even human life. In this study we are proposing a defense study method that have been effective in combatting adversarial threats to ICSs and to assess adversarial attacks successfully in real-world circumstances. We are proposing a security solution IDS which can detect an adversarial attack on the industrial control system. We were able in this study to detect a black box attack by conducting DDoS attack scenario trained by black box adversarial attack in the ICS environment and use data from an ICS to train a classification model and test the ability to detect cyber intrusions in a similar context using IDS.",
    "authors": [
      "Motaz Abdulaziz Almedires",
      "Ahmed Elkhalil",
      "Mohammed Amin"
    ],
    "url": null,
    "venue": "",
    "publicationDate": "2025-05-05",
    "CitationCount": 7,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s41598-025-88134-w",
    "title": "Identification of therapeutic targets for Alzheimer’s Disease Treatment using bioinformatics and machine learning",
    "abstract": "Alzheimer's disease (AD) is a complex neurodegenerative disorder that currently lacks effective treatment options. This study aimed to identify potential therapeutic targets for the treatment of AD using comprehensive bioinformatics methods and machine learning algorithms. By integrating differential gene expression analysis, weighted gene co-expression network analysis, Mfuzz clustering, single-cell RNA sequencing, and machine learning algorithms including LASSO regression, SVM-RFE, and random forest, five hub genes related to AD, including PLCB1, NDUFAB1, KRAS, ATP2A2, and CALM3 were identified. PLCB1, in particular, exhibited the highest diagnostic value in AD and showed significant correlation with Braak stages and neuronal expression. Furthermore, Noscapine, PX-316, and TAK-901 were selected as potential therapeutic drugs for AD based on PLCB1. This research provides a comprehensive and reliable method for the discovery of AD therapeutic targets and the construction of diagnostic models, offering important insights and directions for future AD treatment strategies and drug development.",
    "authors": [
      "Zhongcong Xie",
      "Yongli Situ",
      "Li Deng",
      "Meng Liang",
      "Hang Ding",
      "Zhen Guo",
      "Qinying Xu",
      "Liang Zhu",
      "Shao Jian Zheng"
    ],
    "url": null,
    "venue": "Scientific Reports",
    "publicationDate": "2025-01-31",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1007/3-540-60428-6_28",
    "title": "Using Stochastic Grammars to Learn Robotic Tasks",
    "abstract": null,
    "authors": [
      "P. Lima",
      "G. Saridis"
    ],
    "url": "",
    "venue": "Portuguese Conference on Artificial Intelligence",
    "publicationDate": "1995-10-03",
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": null,
    "title": "Interactive comment on “Data efficient Random Forest model for avalanche forecasting” by",
    "abstract": null,
    "authors": [
      "Manesh Chawla",
      "Amreek Singh",
      "Bret Shandro Referee"
    ],
    "url": "",
    "venue": null,
    "publicationDate": null,
    "CitationCount": 0,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1186/s12967-025-06517-z",
    "title": "Decoding per- and polyfluoroalkyl substances (PFAS) in hepatocellular carcinoma: a multi-omics and computational toxicology approach",
    "abstract": "Abstract Background Per- and polyfluoroalkyl substances (PFAS), particularly perfluorooctanoic acid (PFOA) and perfluorooctane sulfonate (PFOS), are synthetic chemicals known for their widespread use and environmental persistence. These compounds have been increasingly linked to hepatotoxicity and the development of hepatocellular carcinoma (HCC). However, the molecular mechanisms by which PFAS contribute to HCC remain underexplored. Methods This study employs a multi-omics approach that combines network toxicology, integrated machine learning, single-cell RNA sequencing, spatial transcriptomics, experimental validation, and molecular docking simulations to uncover the mechanisms through which PFAS exposure drives HCC. We analyzed publicly available transcriptomic data from several HCC cohorts and used differential gene expression analysis to identify targets associated with both PFAS exposure and HCC. We constructed a protein–protein interaction (PPI) network and a survival risk model, the PFAS-related HCC signature (PFASRHSig), based on integrated machine learning to identify prognostic biomarkers, with the goal of identifying core targets of PFAS in HCC progression and prognosis. RT-qPCR and immunohistochemical (IHC) staining were used to validate the expression levels of the targets in both tumor and normal tissues. Molecular docking simulations were conducted to assess the binding affinities between PFAS compounds and selected target proteins. Results Functional enrichment studies revealed that PFAS targets were associated with metabolic signaling pathways, which are actively involved in lipid, glucose, drug metabolism, etc. Through integrated machine learning and PPI network analysis, we identified six genes, APOA1, ESR1, IGF1, PPARGC1A, SERPINE1, and PON1, that serve as core targets of PFAS in both HCC progression and prognosis. These targets were further validated via bulk RNA-seq, single-cell RNA-seq, and spatial transcriptomics, which revealed differential expression patterns across various cell types in the HCC tumor microenvironment. The results of RT-qPCR and IHC staining were consistent with the in silico findings. Molecular docking simulations revealed strong binding affinities between PFAS compounds and these core targets, supporting their potential roles in PFAS-induced hepatocarcinogenesis. Conclusions Our study highlights key molecular targets and pathways involved in PFAS-induced liver carcinogenesis and proposes a robust survival risk model (PFASRHSig) for HCC. These findings provide new insights into PFAS toxicity mechanisms and offer potential therapeutic targets for mitigating the health risks associated with PFAS exposure. Collectively, our findings help in advancing clinical applications by providing insights into disease mechanisms and potential therapeutic interventions.",
    "authors": [
      "Yanggang Hong",
      "Deqi Wang",
      "Zeyu Liu",
      "Yuxin Chen",
      "Yi Wang",
      "Jiajun Li"
    ],
    "url": null,
    "venue": "Journal of Translational Medicine",
    "publicationDate": "2025-05-02",
    "CitationCount": 8,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1007/978-3-030-11012-3_23",
    "title": "Bridging machine learning and cryptography in defence against adversarial attacks",
    "abstract": "In the last decade, deep learning algorithms have become very popular thanks to the achieved performance in many machine learning and computer vision tasks. However, most of the deep learning architectures are vulnerable to so called adversarial examples. This questions the security of deep neural networks (DNN) for many security- and trust-sensitive domains. The majority of the proposed existing adversarial attacks are based on the differentiability of the DNN cost function.Defence strategies are mostly based on machine learning and signal processing principles that either try to detect-reject or filter out the adversarial perturbations and completely neglect the classical cryptographic component in the defence. In this work, we propose a new defence mechanism based on the second Kerckhoffs's cryptographic principle which states that the defence and classification algorithm are supposed to be known, but not the key. To be compliant with the assumption that the attacker does not have access to the secret key, we will primarily focus on a gray-box scenario and do not address a white-box one. More particularly, we assume that the attacker does not have direct access to the secret block, but (a) he completely knows the system architecture, (b) he has access to the data used for training and testing and (c) he can observe the output of the classifier for each given input. We show empirically that our system is efficient against most famous state-of-the-art attacks in black-box and gray-box scenarios.",
    "authors": [
      "O. Taran",
      "Shideh Rezaeifar",
      "S. Voloshynovskiy"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2018-09-05",
    "CitationCount": 22,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 4
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s41598-024-82062-x",
    "title": "A robust and interpretable ensemble machine learning model for predicting healthcare insurance fraud",
    "abstract": "Healthcare insurance fraud imposes a significant financial burden on healthcare systems worldwide, with annual losses reaching billions of dollars. This study aims to improve fraud detection accuracy using machine learning techniques. Our approach consists of three key stages: data preprocessing, model training and integration, and result analysis with feature interpretation. Initially, we examined the dataset's characteristics and employed embedded and permutation methods to test the performance and runtime of single models under different feature sets, selecting the minimal number of features that could still achieve high performance. We then applied ensemble techniques, including Voting, Weighted, and Stacking methods, to combine different models and compare their performances. Feature interpretation was achieved through partial dependence plots (PDP), SHAP, and LIME, allowing us to understand each feature's impact on the predictions. Finally, we benchmarked our approach against existing studies to evaluate its advantages and limitations. The findings demonstrate improved fraud detection accuracy and offer insights into the interpretability of machine learning models in this context.",
    "authors": [
      "Zeyu Wang",
      "Xiaofang Chen",
      "Yiwei Wu",
      "Linke Jiang",
      "Siming Lin",
      "Gang Qiu"
    ],
    "url": null,
    "venue": "Scientific Reports",
    "publicationDate": "2025-01-02",
    "CitationCount": 5,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.37943/19ppfn3256",
    "title": "METHODS OF FORECASTING GRAIN CROP YIELD INDICATORS TAKING INTO ACCOUNT THE INFLUENCE OF METEOROLOGICAL CONDITIONS IN THE INFORMATION-ANALYTICAL SUBSYSTEM",
    "abstract": "Forecasting crop yields is one of the key challenges for the agricultural sector, especially in the context of a changing climate and unstable weather conditions. Kazakhstan, possessing significant territories suitable for growing grain crops, faces many challenges related to the effective management of agricultural activities. In this regard, yield forecasting becomes an integral part of planning and decision-making processes in agriculture. Information and analytical subsystems that integrate yield forecasting methods allow agribusinesses to estimate future production more accurately, minimise risks associated with climate change and optimise resource use. An important component of such systems is the consideration of weather conditions, as weather factors have a direct impact on crop growth and development. The purpose of this article is to develop and evaluate modern methods of forecasting grain yields taking into account the influence of weather conditions, as well as their integration into information-analytical subsystems to improve the accuracy of agricultural forecasting. To achieve this goal, the article addresses the following tasks: to analyse existing methods of yield forecasting and identify their advantages and disadvantages, to develop forecasting models, including machine learning methods such as gradient bousting and recurrent neural networks, to validate the developed models on the basis of historical data using cross-validation methods, to evaluate the effectiveness of the proposed methods and compare them with basic models such as linear regression and simple average, to evaluate the effectiveness of the proposed methods and to compare them with the basic models such as linear regression and simple average. This article reviews modern methods of forecasting grain crop yields in Kazakhstan, as well as technologies used in information-analytical subsystems. Particular attention is paid to the analysis of the influence of meteorological conditions on yields and the development of models that take this factor into account. The presented review and research results are aimed at improving the existing approaches to the management of agricultural processes under conditions of growing uncertainty caused by climate change. The article explores an important scientific task related to the development of methods for step-by-step forecasting of agrometeorological factors and grain yields, relying on the principle of analogy.",
    "authors": [
      "S. Toxanov",
      "D. Abzhanova",
      "A. Neftissov",
      "A. Biloshchytskyi"
    ],
    "url": "",
    "venue": "Scientific Journal of Astana IT University",
    "publicationDate": "2024-09-30",
    "CitationCount": 1,
    "type": [
      "JournalArticle",
      "Review"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s41467-025-56472-y",
    "title": "Advances in lignocellulosic feedstocks for bioenergy and bioproducts",
    "abstract": "Lignocellulose, an abundant renewable resource, presents a promising alternative for sustainable energy and industrial applications. However, large-scale adoption of lignocellulosic feedstocks faces considerable obstacles, including scalability, bioprocessing efficiency, and resilience to climate change. This Review examines current efforts and future opportunities for leveraging lignocellulosic feedstocks in bio-based energy and products, with a focus on enhancing conversion efficiency and scalability. It also explores emerging biotechnologies such as CRISPR-based genome editing informed by machine learning, aimed at improving feedstock traits and reducing the environmental impact of fossil fuel dependence. Lignocellulose is a promising feedstock to produce bioenergy and biomaterials. Here, the authors review current efforts, including genome editing informed by machine learning, for lignocellulosic feedstock-based bioenergy and biomaterials production and provide outlook for improving feedstock traits.",
    "authors": [
      "Daniel B. Sulis",
      "Nathalie Lavoine",
      "Heike Sederoff",
      "Xiao Jiang",
      "Barbara M. Marques",
      "Kai Lan",
      "Carlos Cofre-Vega",
      "Rodolphe Barrangou",
      "Jack Wang"
    ],
    "url": null,
    "venue": "Nature Communications",
    "publicationDate": "2025-02-01",
    "CitationCount": 20,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.3390/APP11114834",
    "title": "Categorizing Touch-Input Locations from Touchscreen Device Interfaces via On-Board Mechano-Acoustic Transducers",
    "abstract": "Many mobile electronics devices, including smartphones and tablets, require the user to interact physically with the device via tapping the touchscreen. Conveniently, these compact devices are also equipped with high-precision transducers such as accelerometers and microphones, integrated mechanically and designed on-board to support a range of user functionalities. However, unintended access to these transducer signals (bypassing normal on-board data access controls) may allow sensitive user interaction information to be detected and thereby exploited. In this study, we show that acoustic features extracted from the on-board microphone signals, supported with accelerometer and gyroscope signals, may be used together with machine learning techniques to successfully determine the user’s touch input location on a touchscreen: our ensemble model, namely the random forest model, predicts touch input location with up to 86% accuracy in a realistic scenario. Accordingly, we present the approach and techniques used, the performance of the model developed, and also discuss limitations and possible mitigation methods to thwart possible exploitation of such unintended signal channels.",
    "authors": [
      "K. Teo",
      "B. B. T.",
      "Jianying Zhou",
      "Jer-Ming Chen"
    ],
    "url": "https://www.mdpi.com/2076-3417/11/11/4834/pdf?version=1621931975",
    "venue": "Applied Sciences",
    "publicationDate": "2021-05-25",
    "CitationCount": 3,
    "type": null,
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1146/annurev.fl.12.010180.000453",
    "title": "Water Transport in Soils",
    "abstract": "The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from experiments, field measurements, and large-scale simulations at multiple spatiotemporal scales. Machine learning (ML) offers a wealth of techniques to extract ...Read More",
    "authors": [
      "J.‐Y. Parlange"
    ],
    "url": null,
    "venue": "Annual Review of Fluid Mechanics",
    "publicationDate": "1980-01-01",
    "CitationCount": 160,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/TELFOR59449.2023.10372693",
    "title": "Towards more flexible human-machine speech communication",
    "abstract": "The research presented in the paper addresses challenges related to the development of more flexible systems for speech communication between humans and machines. Specifically, the paper presents the main results of the speech technology research group at the Faculty of Technical Sciences, University of Novi Sad, Serbia, in the development of a multilingual human-machine communication system. The approach, which fully exploits recent advances in the area of machine learning and artificial intelligence, extends the basic functionality of a text-to-speech system by increasing its flexibility with respect to the speaking style, speaker identity and even language, by means of neural network embedding. At the same time, the performance of automatic speech recognition is improved in terms of its adaptability to different channels and speakers based on machine learning algorithms originally used in image processing. Domain transfer, as well as creation of dynamic dictionaries have played a crucial role in most recent developments in the area of speech recognition. The focus of the research presented in the paper is on the cases when the available quantity of adaptation data is very small, which corresponds to an increased practical usability of proposed approaches in many real world scenarios.",
    "authors": [
      "M. Secujski",
      "N. Jakovljević",
      "Nikola Simić",
      "V. Delić",
      "Lidija Krstanović",
      "Tijana V. Nosek",
      "Branislav M. Popović",
      "S. Suzic",
      "Vuk Stanojev"
    ],
    "url": "",
    "venue": "Telecommunications Forum",
    "publicationDate": "2023-11-21",
    "CitationCount": 0,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1073/pnas.2417920122",
    "title": "Prediction of phase-separation propensities of disordered proteins from sequence",
    "abstract": "Phase separation is one possible mechanism governing the selective cellular enrichment of biomolecular constituents for processes such as transcriptional activation, mRNA regulation, and immune signaling. Phase separation is mediated by multivalent interactions of macromolecules including intrinsically disordered proteins and regions (IDRs). Despite considerable advances in experiments, theory, and simulations, the prediction of the thermodynamics of IDR phase behavior remains challenging. We combined coarse-grained molecular dynamics simulations and active learning to develop a fast and accurate machine learning model to predict the free energy and saturation concentration for phase separation directly from sequence. We validate the model using computational and previously measured experimental data, as well as new experimental data for six proteins. We apply our model to all 27,663 IDRs of chain length up to 800 residues in the human proteome and find that 1,420 of these (5%) are predicted to undergo homotypic phase separation with transfer free energies < −2 kBT. We use our model to understand the relationship between single-chain compaction and phase separation and find that changes from charge- to hydrophobicity-mediated interactions can break the symmetry between intra- and intermolecular interactions. We also provide proof of principle for how the model can be used in force field refinement. Our work refines and quantifies the established rules governing the connection between sequence features and phase-separation propensities, and our prediction models will be useful for interpreting and designing cellular experiments on the role of phase separation, and for the design of IDRs with specific phase-separation propensities.",
    "authors": [
      "Sören von Bülow",
      "Giulio Tesei",
      "Fatima Zaidi",
      "Tanja Mittag",
      "Kresten Lindorff‐Larsen"
    ],
    "url": null,
    "venue": "Proceedings of the National Academy of Sciences",
    "publicationDate": "2025-03-25",
    "CitationCount": 14,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s41467-025-56330-x",
    "title": "Application of machine learning and genomics for orphan crop improvement",
    "abstract": "Orphan crops are important sources of nutrition in developing regions and many are tolerant to biotic and abiotic stressors; however, modern crop improvement technologies have not been widely applied to orphan crops due to the lack of resources available. There are orphan crop representatives across major crop types and the conservation of genes between these related species can be used in crop improvement. Machine learning (ML) has emerged as a promising tool for crop improvement. Transferring knowledge from major crops to orphan crops and using machine learning to improve accuracy and efficiency can be used to improve orphan crops. Machine learning has emerged as a promising tool for crop improvement. Here, the authors review transferring knowledge from major crops to orphan crops and using machine learning to improve accuracy and efficiency of orphan crops breeding.",
    "authors": [
      "Tessa R. MacNish",
      "Monica F. Danilevicz",
      "Philipp E. Bayer",
      "Mitchell Bestry",
      "David Edwards"
    ],
    "url": null,
    "venue": "Nature Communications",
    "publicationDate": "2025-01-24",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s41598-025-89606-9",
    "title": "Predicting the compressive strength of polymer-infused bricks: A machine learning approach with SHAP interpretability",
    "abstract": "Abstract The rapid increase in global waste production, particularly Polymer wastes, poses significant environmental challenges because of its nonbiodegradable nature and harmful effects on both vegetation and aquatic life. To address this issue, innovative construction approaches have emerged, such as repurposing waste Polymers into building materials. This study explores the development of eco-friendly bricks incorporating cement, fly ash, M sand, and polypropylene (PP) fibers derived from waste Polymers. The primary innovation lies in leveraging advanced machine learning techniques, namely, artificial neural networks (ANN), support vector machines (SVM), Random Forest and AdaBoost to predict the compressive strength of these Polymer-infused bricks. The polymer bricks’ compressive strength was recorded as the output parameter, with cement, fly ash, M sand, PP waste, and age serving as the input parameters. Machine learning models often function as black boxes, thereby providing limited interpretability; however, our approach addresses this limitation by employing the SHapley Additive exPlanations (SHAP) interpretation method. This enables us to explain the influence of different input variables on the predicted outcomes, thus making the models more transparent and explainable. The performance of each model was evaluated rigorously using various metrics, including Taylor diagrams and accuracy matrices. Among the compared models, the ANN and RF demonstrated superior accuracy which is in close agreement with the experimental results. ANN model achieves R 2 values of 0.99674 and 0.99576 in training and testing respectively, whereas RMSE value of 0.0151 (Training) and 0.01915 (Testing). This underscores the reliability of the ANN model in estimating compressive strength. Age, fly ash were found to be the most important variable in predicting the output as determined through SHAP analysis. This study not only highlights the potential of machine learning to enhance the accuracy of predictive models for sustainable construction materials and demonstrates a novel application of SHAP to improve the interpretability of machine learning models in the context of Polymer waste repurposing.",
    "authors": [
      "S. Sathvik",
      "Rakesh Kumar",
      "Archudha Arjunasamy",
      "Sakshi Galagali",
      "Adithya Tantri",
      "Sujay Raghavendra Naganna"
    ],
    "url": null,
    "venue": "Scientific Reports",
    "publicationDate": "2025-03-08",
    "CitationCount": 6,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.3390/mps4040068",
    "title": "Combining Multiple RNA-Seq Data Analysis Algorithms Using Machine Learning Improves Differential Isoform Expression Analysis",
    "abstract": "RNA sequencing has become the standard technique for high resolution genome-wide monitoring of gene expression. As such, it often comprises the first step towards understanding complex molecular mechanisms driving various phenotypes, spanning organ development to disease genesis, monitoring and progression. An advantage of RNA sequencing is its ability to capture complex transcriptomic events such as alternative splicing which results in alternate isoform abundance. At the same time, this advantage remains algorithmically and computationally challenging, especially with the emergence of even higher resolution technologies such as single-cell RNA sequencing. Although several algorithms have been proposed for the effective detection of differential isoform expression from RNA-Seq data, no widely accepted golden standards have been established. This fact is further compounded by the significant differences in the output of different algorithms when applied on the same data. In addition, many of the proposed algorithms remain scarce and poorly maintained. Driven by these challenges, we developed a novel integrative approach that effectively combines the most widely used algorithms for differential transcript and isoform analysis using state-of-the-art machine learning techniques. We demonstrate its usability by applying it on simulated data based on several organisms, and using several performance metrics; we conclude that our strategy outperforms the application of the individual algorithms. Finally, our approach is implemented as an R Shiny application, with the underlying data analysis pipelines also available as docker containers.",
    "authors": [
      "A. Dimopoulos",
      "Konstantinos Koukoutegos",
      "F. Psomopoulos",
      "P. Moulos"
    ],
    "url": "https://www.mdpi.com/2409-9279/4/4/68/pdf?version=1632750531",
    "venue": "Methods and Protocols",
    "publicationDate": "2021-09-27",
    "CitationCount": 4,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.22399/ijasrar.19",
    "title": "AI and Machine Learning for Sustainable Energy: Predictive Modelling, Optimization and Socioeconomic Impact In The USA",
    "abstract": "This research explores how Machine Learning and AI can be used to enhance energy efficiency, forecast energy consumption trends, and optimize energy systems in the USA. This research used datasets comprising household energy usage, electric vehicle adoption trends, and smart grid analytics obtained from public sources, databases, and IoT sensor devices. This study applies advanced machine learning techniques such as deep learning, regression models, and ensemble learning to improve forecasting accuracy aimed at achieving efficient resource allocation. Additionally, this study investigates fault prediction in New Energy Vehicles (NEVs) and its implications for grid stability and energy demand management. The research also examines the socioeconomic impact of AI-driven energy policies and highlights their role in reducing carbon footprints, promoting energy equity, and fostering sustainable economic growth. Recurrent Neural Networks are applied to predict energy consumption trends and electric vehicle(EV) adoption rates by analyzing historical usage data. Convolutional Neural Networks and Autoencoders are used for anomaly detection in NEV battery performance and predictive maintenance. Deep Learning models also use real-time IoT sensor data to enhance the efficiency of energy distribution in smart grids. Linear Regression models are used to predict household and industrial energy demand based on factors such as weather, pricing, and socioeconomic variables. Linear Regression also predicts energy consumption trends in hospitals and factories. Random Forest and XGBoost are used in energy demand forecasting and energy consumption clustering. Performance evaluation metrics such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared (R²) are utilized to assess model accuracy and effectiveness.",
    "authors": [
      "Chidera Victoria Ibeh",
      "Ayodeji Enoch Adegbola"
    ],
    "url": null,
    "venue": "",
    "publicationDate": "2025-03-14",
    "CitationCount": 40,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1002/adfm.202419209",
    "title": "Wearable Pressure Sensor Based on Triboelectric Nanogenerator for Information Encoding, Gesture Recognition, and Wireless Real‐Time Robot Control",
    "abstract": "Abstract Wearable sensor has attracted a broad interesting in application prospect of human‐machine interaction (HMI). However, most of sensors are assembled in the shape of gloves to accurately capture complex hand motion information, thereby seriously blocking the hand to complete complex tasks. Herein, a wearable pressure sensor based on drum‐structured triboelectric nanogenerator (DS‐TENG) is developed to capture subtle pressure signals for physiological signal detection, information encoding, gesture recognition, and wireless real‐time robot control. The DS‐TENG enables a limit of detection down to 3.9 Pa pressure, which can sensitively capture human micromotion signals of pulse, throat sounds, and wrist muscles contraction. Especially, combined with a microprocessor and Morse code, the DS‐TENG worn on wrist can detect single‐finger motion signals to translate into regular voltage signals, which is employed to encode information of 26 letters and subsequently decode into the corresponding letters. Furthermore, with an aid of machine learning, the DS‐TENG array (2 × 2) can successfully achieve gesture recognition with high accuracy of 92% to wirelessly perform real‐time robot control. Consequently, the wearable pressure sensor based on DS‐TENG can capture subtle pressure signals for information encoding and wireless real‐time robot control, which demonstrates extreme potential in the field of HMI and artificial intelligence.",
    "authors": [
      "Mengjia Guo",
      "Yifan Xia",
      "Jiaxuan Liu",
      "Yinghao Zhang",
      "Min Li",
      "Xin Wang"
    ],
    "url": null,
    "venue": "Advanced Functional Materials",
    "publicationDate": "2025-01-21",
    "CitationCount": 11,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s41598-025-87187-1",
    "title": "Enhanced streamflow forecasting using hybrid modelling integrating glacio-hydrological outputs, deep learning and wavelet transformation",
    "abstract": "Abstract Understanding snow and ice melt dynamics is vital for flood risk assessment and effective water resource management in populated river basins sourced in inaccessible high-mountains. This study provides an AI-enabled hybrid approach integrating glacio-hydrological model outputs (GSM-SOCONT), with different machine learning and deep learning techniques framed as alternative ‘computational scenarios, leveraging both physical processes and data-driven insights for enhanced predictive capabilities. The standalone deep learning model (CNN-LSTM), relying solely on meteorological data, outperformed its counterpart machine learning and glacio-hydrological model equivalents. Hybrid models (CNN-LSTM1 to CNN-LSTM15) were trained using meteorological data augmented with glacio-hydrological model outputs representing ice and snow-melt contributions to streamflow. The hybrid model (CNN-LSTM14), using only glacier-derived features, performed best with high NSE (0.86), KGE (0.80), and R (0.93) values during calibration, and the highest NSE (0.83), KGE (0.88), R (0.91), and lowest RMSE (892) and MAE (544) during validation. Finally, a multi-scale analysis using different feature permutations was explored using wavelet transformation theory, integrating these into the final hybrid model (CNN-LSTM19), which significantly enhances predictive accuracy, particularly for high-flow events, as evidenced by improved NSE (from 0.83 to 0.97) and reduced RMSE (from 892 to 442) during validation. The comparative analysis illustrates how AI-enhanced hydrological models improve the accuracy of runoff forecasting and provide more reliable and actionable insights for managing water resources and mitigating flood risks - despite the paucity of direct measurements.",
    "authors": [
      "Jamal Hassan Ougahi",
      "John S. Rowan"
    ],
    "url": null,
    "venue": "Scientific Reports",
    "publicationDate": "2025-01-22",
    "CitationCount": 7,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1017/eds.2024.14",
    "title": "Time series predictions in unmonitored sites: a survey of machine learning techniques in water resources",
    "abstract": "Abstract Prediction of dynamic environmental variables in unmonitored sites remains a long-standing challenge for water resources science. The majority of the world’s freshwater resources have inadequate monitoring of critical environmental variables needed for management. Yet, the need to have widespread predictions of hydrological variables such as river flow and water quality has become increasingly urgent due to climate and land use change over the past decades, and their associated impacts on water resources. Modern machine learning methods increasingly outperform their process-based and empirical model counterparts for hydrologic time series prediction with their ability to extract information from large, diverse data sets. We review relevant state-of-the art applications of machine learning for streamflow, water quality, and other water resources prediction and discuss opportunities to improve the use of machine learning with emerging methods for incorporating watershed characteristics and process knowledge into classical, deep learning, and transfer learning methodologies. The analysis here suggests most prior efforts have been focused on deep learning frameworks built on many sites for predictions at daily time scales in the United States, but that comparisons between different classes of machine learning methods are few and inadequate. We identify several open questions for time series predictions in unmonitored sites that include incorporating dynamic inputs and site characteristics, mechanistic understanding and spatial context, and explainable AI techniques in modern machine learning frameworks.",
    "authors": [
      "Jared Willard",
      "Charuleka Varadharajan",
      "Xiaowei Jia",
      "Vipin Kumar"
    ],
    "url": null,
    "venue": "Environmental Data Science",
    "publicationDate": "2025-01-01",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1088/1674-1056/ad4328",
    "title": "Physical information-enhanced graph neural network for predicting phase separation",
    "abstract": "Although phase separation is a ubiquitous phenomenon, the interactions between multiple components make it difficult to accurately model and predict. In recent years, machine learning has been widely used in physics simulations. Here, we present a physical information-enhanced graph neural network (PIENet) to simulate and predict the evolution of phase separation. The accuracy of our model in predicting particle positions is improved by 40.3% and 51.77% compared with CNN and SVM respectively. Moreover, we design an order parameter based on local density to measure the evolution of phase separation and analyze the systematic changes with different repulsion coefficients and different Schmidt numbers. The results demonstrate that our model can achieve long-term accurate predictions of order parameters without requiring complex handcrafted features. These results prove that graph neural networks can become new tools and methods for predicting the structure and properties of complex physical systems.",
    "authors": [
      "Yaqiang 亚强 Zhang 张",
      "Xuwen 煦文 Wang 王",
      "Y. Wang 王",
      "W. Zheng 郑"
    ],
    "url": "",
    "venue": "Chinese Physics B",
    "publicationDate": "2024-04-25",
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/ma18010148",
    "title": "Application of Machine Learning to the Prediction of Surface Roughness in the Milling Process on the Basis of Sensor Signals",
    "abstract": "This article presents an investigation of the use of machine learning methodologies for the prediction of surface roughness in milling operations, using sensor data as the primary source of information. The sensors, which included current transformers, a microphone, and displacement sensors, captured comprehensive machining signals at a frequency of 10 kHz. The signals were subjected to preprocessing using the Savitzky–Golay filter, with the objective of isolating relevant moments of active material machining and reducing noise. Two machine learning models, namely Elastic Net and neural networks, were employed for the prediction purposes. The Elastic Net model demonstrated effective handling of multicollinearity and reduction in the data dimensionality, while the neural networks, utilizing the ReLU activation function, exhibited the capacity to capture complex, nonlinear patterns. The models were evaluated using the coefficient of determination (R²), which yielded values of 0.94 for Elastic Net and 0.95 for neural networks, indicating a high degree of predictive accuracy. These findings illustrate the potential of machine learning to optimize manufacturing processes by facilitating precise predictions of surface roughness. Elastic Net demonstrated its utility in reducing dimensionality and selecting features, while neural networks proved effective in modeling complex data. Consequently, these methods exemplify the efficacy of integrating data-driven approaches with robust predictive models to improve the quality and efficiency of surface.",
    "authors": [
      "Katarzyna Antosz",
      "Edward Kozłowski",
      "Jarosław Sęp",
      "Sławomir Prucnal"
    ],
    "url": null,
    "venue": "Materials",
    "publicationDate": "2025-01-02",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1002/mrm.29906",
    "title": "Current status in spatiotemporal analysis of contrast‐based perfusion MRI",
    "abstract": "In perfusion MRI, image voxels form a spatially organized network of systems, all exchanging indicator with their immediate neighbors. Yet the current paradigm for perfusion MRI analysis treats all voxels or regions‐of‐interest as isolated systems supplied by a single global source. This simplification not only leads to long‐recognized systematic errors but also fails to leverage the embedded spatial structure within the data. Since the early 2000s, a variety of models and implementations have been proposed to analyze systems with between‐voxel interactions. In general, this leads to large and connected numerical inverse problems that are intractible with conventional computational methods. With recent advances in machine learning, however, these approaches are becoming practically feasible, opening up the way for a paradigm shift in the approach to perfusion MRI. This paper seeks to review the work in spatiotemporal modelling of perfusion MRI using a coherent, harmonized nomenclature and notation, with clear physical definitions and assumptions. The aim is to introduce clarity in the state‐of‐the‐art of this promising new approach to perfusion MRI, and help to identify gaps of knowledge and priorities for future research.",
    "authors": [
      "Eve S Shalom",
      "Amirul Khan",
      "S. van Loo",
      "S. Sourbron"
    ],
    "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mrm.29906",
    "venue": "Magnetic Resonance in Medicine",
    "publicationDate": "2023-11-06",
    "CitationCount": 5,
    "type": [
      "Review",
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.55041/isjem02419",
    "title": "Artificial Intelligence",
    "abstract": "Artificial Intelligence (AI) is a rapidly evolving field that aims to create systems capable of performing tasks that typically require human intelligence. These tasks include learning, reasoning, problem-solving, perception, and language understanding. AI is categorized into narrow AI, which is designed for specific tasks like speech recognition and image processing, and general AI, which aspires to replicate human cognitive abilities across various domains. AI technologies, including machine learning, deep learning, and natural language processing, have significantly impacted industries such as healthcare, finance, education, and automation. While AI offers immense benefits in efficiency, accuracy, and innovation, it also raises ethical concerns related to privacy, bias, and job displacement.",
    "authors": [
      "Shilpa Suresh",
      "C Sasidharan"
    ],
    "url": null,
    "venue": "International Scientific Journal of Engineering and Management",
    "publicationDate": "2025-03-16",
    "CitationCount": 7,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1021/acs.jpca.4c08170",
    "title": "Diffusion Generative Models for Designing Efficient Singlet Fission Dimers.",
    "abstract": "Diffusion generative models, a class of machine learning techniques, have shown remarkable promise in materials science and chemistry by enabling the precise generation of complex molecular structures. In this article, we propose a novel application of diffusion generative models for stabilizing reactive molecular structures identified through quantum mechanical screening. Specifically, we focus on the design challenge presented by singlet fission (SF), a phenomenon crucial for advancing solar cell efficiency beyond theoretical limits. While theoretical chemistry has been successful in predicting intermolecular arrangements with enhanced SF coupling, the practical implementation of these configurations faces challenges due to discrepancies between favorable and stabilized structures. To address this gap, we introduce a three-step strategy combining quantum mechanical screening for identifying optimal molecular arrangements and diffusion generative models for predicting stabilizing linkers. Through a case study of cibalackrot dimers, a promising SF material, we demonstrate the efficacy of our approach in enhancing SF efficiency by stabilizing the desired molecular arrangements.",
    "authors": [
      "Lasse Kreimendahl",
      "Mikhail Karnaukh",
      "M. Röhr"
    ],
    "url": "",
    "venue": "Journal of Physical Chemistry A",
    "publicationDate": "2024-12-30",
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/s25020498",
    "title": "A Comprehensive Review of Vision-Based Sensor Systems for Human Gait Analysis",
    "abstract": "Analysis of the human gait represents a fundamental area of investigation within the broader domains of biomechanics, clinical research, and numerous other interdisciplinary fields. The progression of visual sensor technology and machine learning algorithms has enabled substantial developments in the creation of human gait analysis systems. This paper presents a comprehensive review of the advancements and recent findings in the field of vision-based human gait analysis systems over the past five years, with a special emphasis on the role of vision sensors, machine learning algorithms, and technological innovations. The relevant papers were subjected to analysis using the PRISMA method, and 72 articles that met the criteria for this research project were identified. A detailing of the most commonly used visual sensor systems, machine learning algorithms, human gait analysis parameters, optimal camera placement, and gait parameter extraction methods is presented in the analysis. The findings of this research indicate that non-invasive depth cameras are gaining increasing popularity within this field. Furthermore, depth learning algorithms, such as convolutional neural networks (CNNs) and long short-term memory (LSTM) networks, are being employed with increasing frequency. This review seeks to establish the foundations for future innovations that will facilitate the development of more effective, versatile, and user-friendly gait analysis tools, with the potential to significantly enhance human mobility, health, and overall quality of life. This work was supported by [GOBIERNO DE ESPANA/PID2023-150967OB-I00].",
    "authors": [
      "Xiaofeng Han",
      "Diego Guffanti",
      "Alberto Brunete"
    ],
    "url": null,
    "venue": "Sensors",
    "publicationDate": "2025-01-16",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.7554/ELIFE.64940.SA2",
    "title": "Author response: DIPPER, a spatiotemporal proteomics atlas of human intervertebral discs for exploring ageing and degeneration dynamics",
    "abstract": "The spatiotemporal proteome of the intervertebral disc (IVD) underpins its integrity and function. We present DIPPER, a deep and comprehensive IVD proteomic resource comprising 94 genome-wide profiles from 17 individuals. To begin with, protein modules defining key directional trends spanning the lateral and anteroposterior axes were derived from high-resolution spatial proteomes of intact young cadaveric lumbar IVDs. They revealed novel region-specific profiles of regulatory activities and displayed potential paths of deconstruction in the leveland location-matched aged cadaveric discs. Machine learning methods predicted a ‘hydration matrisome’ that connects extracellular matrix with MRI intensity. Importantly, the static proteome used as point-references can be integrated with dynamic proteome (SILAC/degradome) and transcriptome data from multiple clinical samples, enhancing robustness and clinical relevance. The data, findings, and methodology, available on a web interface (http://www.sbms.hku.hk/dclab/ DIPPER/), will be valuable references in the field of IVD biology and proteomic analytics. Introduction The 23 intervertebral discs (IVDs) in the human spine provide stability, mobility, and flexibility. IVD degeneration (IDD), most common in the lumbar region (Saleem et al., 2013; Teraguchi et al., 2014), is associated with a decline in function and a major cause of back pain, affecting up to 80% of the world’s population at some point in life (Rubin, 2007), presenting significant socioeconomic burdens. Multiple interacting factors such as genetics, influenced by ageing, mechanical and other stress factors, contribute to the pathobiology, onset, severity, and progression of IDD (Munir et al., 2018). IVDs are large, avascular, extracellular matrix (ECM)-rich structures comprising three compartments: a hydrated nucleus pulposus (NP) at the centre, surrounded by a tough annulus fibrosus (AF) at the periphery, and cartilaginous endplates of the adjoining vertebral bodies (Humzah and Soames, 1988). The early adolescent NP is populated with vacuolated notochordal-like cells, which are gradually replaced by small chondrocyte-like cells (Risbud et al., 2015). Blood vessels terminate Tam, Chen, et al. eLife 2020;9:e64940. DOI: https://doi.org/10.7554/eLife.64940 1 of 37 TOOLS AND RESOURCES",
    "authors": [
      "V. Tam",
      "Peikai Chen",
      "A. Yee",
      "N. Solis",
      "T. Klein",
      "M. Kudelko",
      "Rakesh Sharma",
      "W. Chan",
      "C. Overall",
      "L. Haglund",
      "P. Sham",
      "K. Cheah",
      "D. Chan"
    ],
    "url": "https://doi.org/10.7554/elife.64940.sa2",
    "venue": null,
    "publicationDate": "2020-12-30",
    "CitationCount": 1,
    "type": null,
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.3390/buildings14030820",
    "title": "Research on Prediction of EPB Shield Tunneling Parameters Based on LGBM",
    "abstract": "At present, the determination of tunnel parameters mainly rely on engineering experience and human judgment, which leads to the subjective decision of parameters and an increased construction risk. Machine learning algorithms could provide an objective theoretical basis for tunnel parameter decision making. However, due to the limitations of a machine learning model’s performance and parameter selection methods, the prediction model had poor prediction results and low reliability for parameter research. To solve the above problems, based on a large number of construction parameters of a composite section subway in Shenzhen, this paper combined dimensionality reduction data with service analysis to optimize the selection process of shield tunneling parameters, and determined the total propulsion force, cutter head torque, cutter head speed, and advance rate as key tunneling parameters. Based on an LGBM algorithm and Bayesian optimization, the prediction model of key tunneling parameters of an earth pressure balance shield was established. The results showed that the average error of the LGBM model on the test set was 8.18%, the average error of the cutter head torque was 13.93%, the average error of the cutter head speed was 3.16%, and the average error of advance rate was 13.35%. Compared with the RF model, the prediction effect and the generalization on the test set were better. Therefore, an LGBM algorithm could be used as an effective prediction method for tunneling parameters in tunnel construction and provide guidance for the setting of tunneling parameters.",
    "authors": [
      "Wei Wang",
      "Huanhuan Feng",
      "Yanzong Li",
      "Quanwei You",
      "Xu Zhou"
    ],
    "url": "https://www.mdpi.com/2075-5309/14/3/820/pdf?version=1710749010",
    "venue": "Buildings",
    "publicationDate": "2024-03-18",
    "CitationCount": 4,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1111/2041-210x.70037",
    "title": "Deep learning meets tree phenology modelling: PhenoFormer versus process‐based models",
    "abstract": "Predicting phenology, that is the timing of seasonal events of plant life such as leaf emergence and colouration in relation to climate fluctuations, is essential for anticipating future changes in carbon sequestration and tree vitality in temperate forest ecosystems. Existing approaches typically rely on either hypothesis‐driven process models or data‐driven statistical methods. Several studies have shown that process models outperform statistical methods when predicting under climatic conditions that differ from those of the training data, such as for climate change scenarios. However, in terms of statistical methods, deep learning approaches remain underexplored for species‐level phenology modelling. We present a deep neural architecture, PhenoFormer, for species‐level phenology prediction using meteorological time series. Our experiments utilise a country‐scale data set comprising 70 years of climate data and approximately 70,000 phenological observations of nine woody plant species, focussing on leaf emergence and colouration in Switzerland. We extensively compare PhenoFormer to 18 different process‐based models and traditional machine learning methods, including Random Forest (RF) and Gradient Boosted Machine (GBM). Our results demonstrate that PhenoFormer outperforms traditional statistical methods in phenology prediction while achieving significant improvements or comparable performance to the best process‐based models. When predicting under climatic conditions similar to the training data, our model improved over the best process‐based models by 6% normalised root‐mean‐squared error (nRMSE) for spring phenology and 7% nRMSE for autumn phenology. Under conditions involving substantial climatic shifts between training and testing (+1.21°C), PhenoFormer reduced the nRMSE by an average of 8% across species compared to RF and GBM, and performed on par with the best process models. These findings highlight the potential of deep learning for phenology modelling and call for further research in this direction, particularly for future climate projections. Meanwhile, the advancements achieved by PhenoFormer can provide valuable insights for anticipating species‐specific phenological responses to climate change.",
    "authors": [
      "Vivien Sainte Fare Garnot",
      "Lynsay Spafford",
      "J. Lever",
      "Christian Sigg",
      "B. Pietragalla",
      "Y. Vitasse",
      "Arthur Gessler",
      "Jan Dirk Wegner"
    ],
    "url": "",
    "venue": "Methods in Ecology and Evolution",
    "publicationDate": "2025-05-26",
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.29207/joseit.v2i2.5460",
    "title": "An Optimal Solution to the Overfitting and Underfitting Problem of Healthcare Machine Learning Models",
    "abstract": "In the current technological era, artificial intelligence is becoming increasingly popular.  Machine learning, as the branch of AI is taking charge in every field such as healthcare, the Stock market, Automation, Robotics, Image Processing, and so on. In the current scenario, machine learning and/or deep learning are becoming very popular in medical science for disease prediction. Much research is underway in the form of disease prediction models by machine learning. To ensure the performance and accuracy of the machine learning model, it is important to keep some basic things in mind during training. The machine learning model has several issues which must be rectified duration of the training of the model so that the learning model works efficiently such as model selection, parameter tuning, dataset splitting, cross-validation, bias-variance tradeoff, overfitting, underfitting, and so on. Under- and over-fitting are the two main issues that affect machine learning models. This research paper mainly focuses on minimizing and/or preventing the problem of overfitting and underfitting machine learning models.",
    "authors": [
      "Anil Kumar Prajapati Anil",
      "Umesh Kumar Singh"
    ],
    "url": "https://www.jurnal.iaii.or.id/index.php/JOSEIT/article/download/5460/845",
    "venue": "Journal of Systems Engineering and Information Technology (JOSEIT)",
    "publicationDate": "2023-10-03",
    "CitationCount": 5,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 1
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.3390/electronics14071351",
    "title": "Novel Learning Framework with Generative AI X-Ray Images for Deep Neural Network-Based X-Ray Security Inspection of Prohibited Items Detection with You Only Look Once",
    "abstract": "As the rapid expansion of future mobility systems increases, along with the demand for fast and accurate X-ray security inspections, deep neural network (DNN)-based systems have gained significant attention for detecting prohibited items by constructing high-quality datasets and enhancing detection performance. While Generative AI has been widely explored across various fields, its application in DNN-based X-ray security inspection remains largely underexplored. The accessibility of commercial Generative AI raises safety concerns about the creation of new prohibited items, highlighting the need to integrate synthetic X-ray images into DNN training to improve detection performance, adapt to emerging threats, and investigate its impact on object detection. To address this, we propose a novel machine learning framework that enhances DNN-based X-ray security inspection by integrating real-world X-ray images with Generative AI images utilizing a commercial text-to-image model, improving dataset diversity and detection accuracy. Our proposed framework provides an effective solution to mitigate potential security threats posed by Generative AI, significantly improving the reliability of DNN-based X-ray security inspection systems, as verified through comprehensive evaluations.",
    "authors": [
      "Dongsik Kim",
      "J. Kang"
    ],
    "url": "",
    "venue": "Electronics",
    "publicationDate": "2025-03-28",
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1007/s10909-020-02545-9",
    "title": "Fe-Based Superconducting Transition Temperature Modeling through Gaussian Process Regression",
    "abstract": null,
    "authors": [
      "Yun Zhang",
      "Xiaojie Xu"
    ],
    "url": "",
    "venue": "Journal of Low Temperature Physics",
    "publicationDate": "2020-11-10",
    "CitationCount": 0,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/JBHI.2025.3587961",
    "title": "DeepBindi: An End-to-End Fear Detection System Optimized for Extreme-Edge Deployment.",
    "abstract": "The growing interest in affective computing has resulted in substantial advancements in emotion recognition through the application of various machine learning and deep learning techniques. Nevertheless, existing methodologies exhibit notable limitations. Specifically, they often fail to address extreme-edge design requirements, making them unfeasible for deployment in wearable systems under real-world conditions. With this aim, this paper introduces a novel end-to-end fear recognition system based on physiological signals designed specifically for deployment in extreme-edge contexts. This solution combines advanced feature engineering techniques with optimized lightweight 1D-CNN model architecture that integrates the advantages of both hand-crafted features and advanced deep-learning convolutional techniques. An experimental validation conducted with the WEMAC dataset provides f1-scores of 80% and accuracy rates of 74%, and reveals significant performance improvements with respect to our previous model proposed: 11.6% and 26.4% in accuracy and F1-score metrics, respectively. Additionally, this research demonstrates the successful integration and validation of the model within an ultra-low-power ARM Cortex-M4 architecture, which exhibits an average power consumption of 16 mW at 5 V, with each inference requiring 496 ms. These results pave the way to a sustainable implementation of deep learning solutions in extreme-edge devices.",
    "authors": [
      "Laura Gutiérrez-Martín",
      "Celia López-Ongil",
      "J. A. Miranda-Calero"
    ],
    "url": "",
    "venue": "IEEE journal of biomedical and health informatics",
    "publicationDate": "2025-07-10",
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1051/SHSCONF/20219209006",
    "title": "The Machine Prediction of the Mutual Trade between the PRC and the Czech Republic in the Global Extraordinary Situation",
    "abstract": "Research background: International trade is a substantial constituent of the global and regional economic development. The analysis of mutual trade serves as a tool for a monetary expression of economic transactions between a particular country and its foreign partners for a specific period. For the Czech Republic (CR), the People’s Republic of China (PRC) is the biggest exporter and the second biggest importer. The USA, however, imposes a number of economic sanctions against the PRC that do not have any significant impact on the trade between both countries and the overall growth of the Chinese economy, yet they affect the behavior of consumers and producers both in the USA and in the PRC.\nPurpose of the article: The aim of this paper is to use machine learning for predicting the future values of the mutual trade between the CR and the PRC for one calendar year (i.e. 12 months).\nMethods: Monthly data of these two states´ import and export are used to predict bilateral trade flow. The time series begins in January 2005 and ends in April 2020. Thus, the time series contains 184 data lines. Artificial intelligence - artificial neural networks - is used to predict bilateral trade flow between the PRC and the CR. The development of trade is then compared with the mutual sanctions of the PRC and the USA.\nFindings & Value added: This is expected that the mutual trade balance to be negative from the perspective of the CR. COVID-19 or the sanctions imposed in the international trade will not significantly affect the development of the mutual trade between the CR and the PRC.",
    "authors": [
      "J. Horák",
      "J. Kucera"
    ],
    "url": "https://doi.org/10.1051/shsconf/20219209006",
    "venue": "SHS Web of Conferences",
    "publicationDate": null,
    "CitationCount": 1,
    "type": [
      "Conference"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.22399/ijasrar.20",
    "title": "Leveraging Predictive Analytics for Customer Churn: A Cross-Industry Approach in the US Market",
    "abstract": "Customer churn prediction is an important aspect of businesses to ensure their profitability in the USA. After a customer attrition calculation, which constitutes the percentage of lost customers compared to the total number of customers over a given period, companies in the USA need to develop predictive models that will help them make appropriate moves to retain customers and maximize profits. The dataset used contained highly elaborate information on customer demographics, service usage, and several indicators that are essential for the analysis of customer retention and churn. Data anonymization and protection were also considered to ensure privacy and protect sensitive company information. In this research, we develop five main machine learning models to predict customer churn using customer data from company databases and systems. The four machine learning models employed in this research include XGBoost, Random Forest, MLP(multi-layer perceptron), and Logistic Regression. The study also assesses model performance using metrics such as mean absolute error (MAE), mean squared error (MSE), and R² score.",
    "authors": [
      "Oluwatomisin Olawale Fowowe",
      "Rasheed Agboluaje"
    ],
    "url": null,
    "venue": "",
    "publicationDate": "2025-04-02",
    "CitationCount": 24,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1007/s13042-013-0171-7",
    "title": "A comparison of ℓ1-regularizion, PCA, KPCA and ICA for dimensionality reduction in logistic regression",
    "abstract": null,
    "authors": [
      "Abdallah Bashir Musa"
    ],
    "url": "",
    "venue": "International Journal of Machine Learning and Cybernetics",
    "publicationDate": "2013-05-08",
    "CitationCount": 45,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 3
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/s25051548",
    "title": "Measuring the Level of Aflatoxin Infection in Pistachio Nuts by Applying Machine Learning Techniques to Hyperspectral Images",
    "abstract": "This paper investigates the use of machine learning techniques on hyperspectral images of pistachios to detect and classify different levels of aflatoxin contamination. Aflatoxins are toxic compounds produced by moulds, posing health risks to consumers. Current detection methods are invasive and contribute to food waste. This paper explores the feasibility of a non-invasive method using hyperspectral imaging and machine learning to classify aflatoxin levels accurately, potentially reducing waste and enhancing food safety. Hyperspectral imaging with machine learning has shown promise in food quality control. The paper evaluates models including Dimensionality Reduction with K-Means Clustering, Residual Networks (ResNets), Variational Autoencoders (VAEs), and Deep Convolutional Generative Adversarial Networks (DCGANs). Using a dataset from Leeds Beckett University with 300 hyperspectral images, covering three aflatoxin levels (&lt;8 ppn, &gt;160 ppn, and &gt;300 ppn), key wavelengths were identified to indicate contamination presence. Dimensionality Reduction with K-Means achieved 84.38% accuracy, while a ResNet model using the 866.21 nm wavelength reached 96.67%. VAE and DCGAN models, though promising, were constrained by dataset size. The findings highlight the potential for machine learning-based hyperspectral imaging in pistachio quality control, and future research should focus on expanding datasets and refining models for industry application.",
    "authors": [
      "LC Williams",
      "Pancham Shukla",
      "Akbar Sheikh-Akbari",
      "Sina Mahroughi",
      "Iosif Mporas"
    ],
    "url": null,
    "venue": "Sensors",
    "publicationDate": "2025-03-02",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1080/19396368.2024.2384386",
    "title": "Classification of idiopathic recurrent spontaneous miscarriage using FTIR and Raman spectroscopic fusion technology",
    "abstract": "Abstract Recurrent spontaneous miscarriage refers to the repeated loss of two or more clinically detected pregnancies occurring within 24 weeks of gestation. No identifiable cause has been identified for nearly 50% of these cases. This group is referred to as idiopathic recurrent spontaneous miscarriage (IRSM) or miscarriage of unknown origin. Due to lack of robust scientific evidence, guidelines on the diagnosis and management of IRSM are not well defined and often contradictory. This motivates us to explore the vibrational fingerprints of endometrial tissue in these women. Endometrial tissues were collected from women undergoing IRSM (n = 20) and controls (n = 20) corresponding to the window of implantation. Attenuated total reflectance-Fourier transform infrared (ATR-FTIR) spectra were obtained within the range of 400–4000 cm−1 using Agilent Cary 630 FTIR spectrometer. Raman spectra were also generated within the spectral window of 400–4000 cm−1 using Thermo Fisher Scientific, DXR Raman spectrophotometer. Based on the limited molecular information provided by a single spectroscopic tool, fusion strategy combining Raman and ATR-FTIR spectroscopic data of IRSM is proposed. The significant features were extracted applying principal component analysis (PCA) and wavelet threshold denoising (WTD) and fused spectral data used as input into support vector machine (SVM), adaptive boosting (AdaBoost) and decision tree (DT) models. Altered molecular vibrations associated with proteins, glutamate, and lipid metabolism were observed in IRSM using Raman spectroscopy. FTIR analysis indicated changes in the molecular vibrations of lipids and proteins, collagen dysregulation and impaired glucose metabolism. Combination of both spectroscopic data using mid-level fusion (MLF: 92% using AdaBoost and DT models) and high-level fusion (HLF: 92% using SVM models) methods showed improved IRSM classification accuracy as compared to individual spectral models. Our results indicate that spectral fusion technology hold promise in enhancing diagnostic accuracy of IRSM in clinical settings. Validation of these findings in a larger patient population is underway. Graphical Abstract Machine learning algorithms applied to spectroscopic fusion data for prediction of idiopathic recurrent spontaneous miscarriage. (A) Recruitment of two groups of subjects – (i) idiopathic recurrent spontaneous miscarriage (IRSM) cases and (ii) controls. (B) Raman and Fourier transform infrared (FTIR) spectroscopic data were generated from endometrial tissue of IRSM and controls collected during implantation window. Data were subjected to chemometric analysis, such as unsupervised hierarchical cluster analysis (HCA) and supervised orthogonal partial least squares-discriminant analysis (OPLS-DA) which showed optimized discrimination between the two groups. (C) Raman and FTIR data were subjected to mid-level and high-level fusion where data matrix were extracted using principal component analysis (PCA) and wavelet denoising. (D) The selected features were used as input into adaptive boosting, decision tree and support vector machine models and the best performing models selected.",
    "authors": [
      "Dadoma Sherpa",
      "Chiranjib Bhowmick",
      "Tummala Pavan",
      "Dhruva Rajwade",
      "Sumana Halder",
      "I. Mitra",
      "Sunita Sharma",
      "Pratip Chakraborty",
      "Sanjukta Dasgupta",
      "K. Chaudhury"
    ],
    "url": "",
    "venue": "Systems Biology in Reproductive Medicine",
    "publicationDate": "2024-08-16",
    "CitationCount": 3,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1016/j.aiig.2022.10.003",
    "title": "Advanced geochemical exploration knowledge using machine learning: Prediction of unknown elemental concentrations and operational prioritization of Re-analysis campaigns",
    "abstract": null,
    "authors": [
      "Steven E. Zhang",
      "J. Bourdeau",
      "G. Nwaila",
      "Y. Ghorbani"
    ],
    "url": "https://doi.org/10.1016/j.aiig.2022.10.003",
    "venue": "Artificial Intelligence in Geosciences",
    "publicationDate": "2022-11-01",
    "CitationCount": 10,
    "type": null,
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1145/3410530.3414390",
    "title": "A preliminary attempt of an intelligent system predicting users' correctness of notifications' sender speculation",
    "abstract": "Prior interruptibility research has focused on identifying interruptible or opportune moments for users to handle notifications. Yet, users may not want to attend to all notifications even at these moments. Research has shown that users' current practices for selective attendance are through speculating about notification sources. Yet, sometimes the above information is insufficient, making speculations difficult. This paper describes the first research attempt to examine how well a machine learning model can predict the moments when users would incorrectly speculate the sender of a notification. We built a machine learning model that can achieve an recall: 84.39%, precision: 56.78%, and F1-score of 0.68. We also show that important features for predicting these moments.",
    "authors": [
      "Tang-Jie Chang",
      "Jian-Hua Jiang Chen",
      "Hao-Ping Lee",
      "Yung-Ju Chang"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2020-09-10",
    "CitationCount": 0,
    "type": [
      "Book",
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1186/s12877-025-05837-5",
    "title": "Network-based predictive models for artificial intelligence: an interpretable application of machine learning techniques in the assessment of depression in stroke patients",
    "abstract": "Depression is a common complication after a stroke that may lead to increased disability and decreased quality of life. The objective of this study was to develop and validate an interpretable predictive model to assess the risk of depression in stroke patients using machine learning (ML) methods. This study included 1143 stroke patients from the NHANES database between 2005 and 2020. First, risk factors for depression in stroke patients were determined by univariate and multivariate logistic regression analysis. Next, five machine learning algorithms were used to construct predictive models, and several evaluation metrics (including area under the curve (AUC)) were used to compare the predictive performance of the models. In addition, the SHAP (Shapley Additive Explanations) method was used to rank the importance of features and to interpret the final model. We screened seven features to construct a predictive model. Among the 5 machine learning models, the XGBoost (extreme gradient boosting) model showed the best discriminative ability, with an AUC of the ROC (receiver operating characteristic curve) in the test set of 0.746 and an accuracy of 0.834. In addition, the prediction results of the XGBoost model were interpreted in detail using the SHAP algorithm. We also developed a web-based calculator that provides a convenient tool for predicting the risk of depression in stroke patients at the following link: https://prediction-model-for-depression.streamlit.app . Our interpretable machine learning model serves as an auxiliary tool for clinical judgment, aimed at early and effective identification of depression risk in stroke patients.",
    "authors": [
      "Wenwei Zuo",
      "Xuelian Yang"
    ],
    "url": null,
    "venue": "BMC Geriatrics",
    "publicationDate": "2025-03-22",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.22399/ijcesen.825",
    "title": "CoralMatrix: A Scalable and Robust Secure Framework for Enhancing IoT Cybersecurity",
    "abstract": "In the current age of digital transformation, the Internet of Things (IoT) has revolutionized everyday objects, and IoT gateways play a critical role in managing the data flow within these networks. However, the dynamic and extensive nature of IoT networks presents significant cybersecurity challenges that necessitate the development of adaptive security systems to protect against evolving threats. This paper proposes the CoralMatrix Security framework, a novel approach to IoT cybersecurity that employs advanced machine learning algorithms. This framework incorporates the AdaptiNet Intelligence Model, which integrates deep learning and reinforcement learning for effective real-time threat detection and response. To comprehensively evaluate the performance of the framework, this study utilized the N-BaIoT dataset, facilitating a quantitative analysis that provided valuable insights into the model's capabilities. The results of the analysis demonstrate the robustness of the CoralMatrix Security framework across various dimensions of IoT cybersecurity. Notably, the framework achieved a high detection accuracy rate of approximately 83.33%, highlighting its effectiveness in identifying and responding to cybersecurity threats in real-time. Additionally, the research examined the framework's scalability, adaptability, resource efficiency, and robustness against diverse cyber-attack types, all of which were quantitatively assessed to provide a comprehensive understanding of its capabilities. This study suggests future work to optimize the framework for larger IoT networks and adapt continuously to emerging threats, aiming to expand its application across diverse IoT scenarios. With its proposed algorithms, the CoralMatrix Security framework has emerged as a promising, efficient, effective, and scalable solution for the dynamic challenges of IoT Cyber Security.",
    "authors": [
      "Srikanth Reddy Vutukuru",
      "Srinivasa Chakravarthi Lade"
    ],
    "url": null,
    "venue": "International Journal of Computational and Experimental Science and Engineering",
    "publicationDate": "2025-01-07",
    "CitationCount": 13,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1146/annurev.fl.12.010180.001511",
    "title": "Instabilities of Waves on Deep Water",
    "abstract": "The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from experiments, field measurements, and large-scale simulations at multiple spatiotemporal scales. Machine learning (ML) offers a wealth of techniques to extract ...Read More",
    "authors": [
      "Henry C. Yuen",
      "Bruce M. Lake"
    ],
    "url": null,
    "venue": "Annual Review of Fluid Mechanics",
    "publicationDate": "1980-01-01",
    "CitationCount": 127,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1101/2025.06.09.658375",
    "title": "Advancing Fair and Explainable Machine Learning for Neuroimaging Dementia Pattern Classification in Multi-Ethnic Populations",
    "abstract": null,
    "authors": [
      "Ngoc-Huynh Ho",
      "S. Charisis",
      "Nicolas Honnorat",
      "Sachintha R. Brandigampala",
      "Di Wang",
      "S. Heckbert",
      "Peter T. Fox",
      "David Martinez",
      "David H. Wang",
      "Timothy M Hughes",
      "D. Archer",
      "Timothy J. Hohman",
      "Sudha Seshadri",
      "C. Davatzikos",
      "Mohamad Habes"
    ],
    "url": "",
    "venue": "bioRxiv",
    "publicationDate": "2025-06-12",
    "CitationCount": 0,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": null,
    "title": "Learning the Effective Dynamics of Complex Multiscale Systems",
    "abstract": null,
    "authors": [
      "Pantelis R. Vlachas",
      "G. Arampatzis",
      "Caroline Uhler",
      "P. Koumoutsakos"
    ],
    "url": "",
    "venue": "arXiv.org",
    "publicationDate": "2020-06-24",
    "CitationCount": 8,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1007/s10462-024-11058-w",
    "title": "Systematic review on neural architecture search",
    "abstract": "Machine Learning (ML) has revolutionized various fields, enabling the development of intelligent systems capable of solving complex problems. However, the process of manually designing and optimizing ML models is often time-consuming, labor-intensive, and requires specialized expertise. To address these challenges, Automatic Machine Learning (AutoML) has emerged as a promising approach that automates the process of selecting and optimizing ML models. Within the realm of AutoML, Neural Architecture Search (NAS) has emerged as a powerful technique that automates the design of neural network architectures, the core components of ML models. It has recently gained significant attraction due to its capability to discover novel and efficient architectures that surpass human-designed counterparts. This manuscript aims to present a systematic review of the literature on this topic published between 2017 and 2023 to identify, analyze, and classify the different types of algorithms developed for NAS. The methodology follows the guidelines of Systematic Literature Review (SLR) methods. Consequently, this study identified 160 articles that provide a comprehensive overview of the field of NAS, encompassing discussion on current works, their purposes, conclusions, and predictions of the direction of this science branch in its main core pillars: Search Space (SSp), Search Strategy (SSt), and Validation Strategy (VSt). Subsequently, the key milestones and advancements that have shaped the field are highlighted. Moreover, we discuss the challenges and open issues that remain in the field. We envision that NAS will continue to play a pivotal role in the advancement of ML, enabling the development of more intelligent and efficient ML models for a wide range of applications.",
    "authors": [
      "Sasan Salmani Pour Avval",
      "Nathan D. Eskue",
      "Roger M. Groves",
      "Vahid Yaghoubi"
    ],
    "url": null,
    "venue": "Artificial Intelligence Review",
    "publicationDate": "2025-01-06",
    "CitationCount": 7,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/ijms26062535",
    "title": "Utilization of Machine Learning in the Prediction, Diagnosis, Prognosis, and Management of Chronic Myeloid Leukemia",
    "abstract": "Chronic myeloid leukemia is a clonal hematologic disease characterized by the presence of the Philadelphia chromosome and the BCR::ABL1 fusion protein. Integrating different molecular, genetic, clinical, and laboratory data would improve the diagnostic, prognostic, and predictive sensitivity of chronic myeloid leukemia. However, without artificial intelligence support, managing such a vast volume of data would be impossible. Considering the advancements and growth in machine learning throughout the years, several models and algorithms have been proposed for the management of chronic myeloid leukemia. Here, we provide an overview of recent research that used specific algorithms on patients with chronic myeloid leukemia, highlighting the potential benefits of adopting machine learning in therapeutic contexts as well as its drawbacks. Our analysis demonstrated the great potential for advancing precision treatment in CML through the combination of clinical and genetic data, laboratory testing, and machine learning. We can use these powerful research instruments to unravel the molecular and spatial puzzles of CML by overcoming the current obstacles. A new age of patient-centered hematology care will be ushered in by this, opening the door for improved diagnosis accuracy, sophisticated risk assessment, and customized treatment plans.",
    "authors": [
      "Fabio Stagno",
      "Sabina Russo",
      "Giuseppe Murdaca",
      "Giuseppe Mirabile",
      "Maria Eugenia Alvaro",
      "Maria Nasso",
      "Mohamed Zemzem",
      "Sebastiano Gangemi",
      "Alessandro Allegra"
    ],
    "url": null,
    "venue": "International Journal of Molecular Sciences",
    "publicationDate": "2025-03-12",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1002/adem.202401944",
    "title": "Artificial Intelligence and Machine Learning in Tribology: Selected Case Studies and Overall Potential",
    "abstract": "Artificial intelligence (AI) and machine learning (ML) have been the subjects of increased interest in recent years due to their benefits across several fields. One sector that can benefit from these tools is the tribology industry, with an emphasis on friction and wear prediction. This industry hopes to train and utilize AI algorithms to classify equipment life status and forecast component failure, mainly using supervised and unsupervised learning approaches. This article examines some of the methods that have been used to accomplish this, such as condition monitoring for predictions in material selection, lubrication performance, and lubricant formulation. Furthermore, AI and ML can support the determination of tribological characteristics of engineering systems, allowing for a better fundamental understanding of friction, wear, and lubrication mechanisms. Moreover, the study also finds that the continued use of AI and ML requires access to findable, accessible, interoperable, and reusable data to ensure the integrity of the prediction tools. The advances of AI and ML methods in tribology show considerable promise, providing more accurate and extensible predictions than traditional approaches.",
    "authors": [
      "Raj Shah",
      "Rudy Jaramillo",
      "Garvin Thomas",
      "Thohid Rayhan",
      "Nayem Hossain",
      "Mohamed Kchaou",
      "Francisco J. Profito",
      "Andreas Rosenkranz"
    ],
    "url": null,
    "venue": "Advanced Engineering Materials",
    "publicationDate": "2025-01-15",
    "CitationCount": 9,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.48175/ijarsct-15350",
    "title": "Literature Survey Paper on Epilepsy and Autism Spectrum Disorder Detection and Analysis Using Machine Learning",
    "abstract": "The detection and cure of epilepsy and autism spectrum disorder (ASD) are significantly complicated by their co-occurrence. This survey research investigates an integrated method for identifying ASD using behavioural characteristic questionnaires and epilepsy using EEG corpus inside a single system. We provide an overview of all the relevant research, emphasizing the difficulties in diagnosing each of these disorders separately and in combination. Our suggested approach combines behavioural questionnaire assessments for ASD with EEG-based analysis for epilepsy detection in an effort to improve diagnostic accuracy and expedite the evaluation process. This study examines the approaches, difficulties, and developments in both domains, providing perspectives on possible overlaps and prospects for further investigation. So, an attempt has been made to review on the pattern detection methods for epilepsy seizure detection from EEG signals. More than 150 research papers have been discussed to determine the techniques for detecting epileptic seizures. Further, the literature review confirms that the pattern recognition techniques required to detect epileptic seizures varies across the electroencephalogram (EEG) datasets of different conditions. This is mostly owing to the fact that EEG detected under different conditions have different characteristics.",
    "authors": [
      "Ms. Likitha. K",
      "Ms. Harshitha S",
      "Pathanjali C"
    ],
    "url": "",
    "venue": "International Journal of Advanced Research in Science, Communication and Technology",
    "publicationDate": "2024-02-06",
    "CitationCount": 0,
    "type": [
      "JournalArticle",
      "Review"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1126/science.add8258",
    "title": "AlphaCode and “data-driven” programming",
    "abstract": "Is ignoring everything that is known about code the best way to write programs? Competitive programming problems represent a challenging task for even skilled programmers: Given a short natural language description of an algorithmic problem, contestants must quickly write a program that solves the task. On page 1092 of this issue, Li et al. (1) present the AlphaCode system, which represents a substantial step forward in the development of machine learning (ML) models that can synthesize computer programs to solve these types of challenging problems. But what is perhaps most surprising about the system is what AlphaCode does not do: AlphaCode contains no explicit built-in knowledge about the structure of computer code. Instead, AlphaCode relies on a purely “data-driven” approach to writing code, learning the structure of computer programs by simply observing lots of existing code.",
    "authors": [
      "J. Kolter"
    ],
    "url": "",
    "venue": "Science",
    "publicationDate": "2022-12-09",
    "CitationCount": 2,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.62486/agsalud2025197",
    "title": "Diabetic Detection from Images of the Eye",
    "abstract": "This cross-sectional study aims to detect Diabetic Retinopathy (DR) in patients who have had retinal scans and ophthalmological exams. The research makes use of tailored retinal images together with the OPF (Optimum-Path Forest) and RBM (Restricted Boltzmann Machine) models to categorize images according to the presence or absence of DR. In this work, features were extracted from the retinal images using both the RBM and OPF models. In particular, after a thorough system training phase, RBM was able to extract between 500 and 1000 features from the images. The study included fifteen distinct trial series, each with thirty cycles of repetition. The research comprised 122 eyes, or 73 diabetic patients, with a gender distribution that was reasonably balanced and an average age of 59.7 years. Remarkably, the RBM-1000 model stood out as the top performer, with the highest overall accuracy of 89.47% in diagnosis. In terms of specificity, the RBM-1000 and OPF-1000 models surpassed the competition, correctly categorizing all images free of DR symptoms. These findings highlight the potential of machine learning, particularly the RBM model, for self-identifying illnesses. The potential of machine learning models—in particular, RBM and OPF—to automate the diagnosis of diabetic retinopathy is demonstrated by this work. The results show how well the RBM model diagnoses, how sensitive it is, and how well it can be applied for efficient DR screening and diagnosis. This information may be used to improve the effectiveness of systems that identify retinal illnesses",
    "authors": [
      "Arepalli Gopi",
      "L. Sudha",
      "Joseph S Iwin Thanakumar"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2025-01-01",
    "CitationCount": 1,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.48047/r2mhn978",
    "title": "Diabetes Diagnosis Using Machine Learning with Cloud Security",
    "abstract": "This program uses open 5G technology to screen the soundness of diabetes patients at any rate cost. Countless people are right now burdened with diabetes because of word related pressure or ill-advised way of life decisions. People will stay unaware of their current wellbeing status except if they manifest side effects or get a finding through a clinical assessment. By then, the illness will be in a serious state, and it will be unimaginable for them to discover this data ahead of time. The two types of diabetes that will be available are Type 1 and Type 2 diabetes. In type 2 diabetes, hospitalization is fundamental; in any case, in type 1 diabetes, we can screen the patient and convey their ongoing condition to them or their doctors. ",
    "authors": [
      "Viswanath G",
      "Krishna Prasad K",
      "J. M. Lakshmi",
      "G. Swapna"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2025-01-02",
    "CitationCount": 19,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1016/j.anucene.2024.110952",
    "title": "Advancing source reactor-type discrimination using machine learning techniques and SFCOMPO-2.0 experimental database",
    "abstract": null,
    "authors": [
      "Tianxiang Wang",
      "Hao Yang",
      "Shengli Chen",
      "Cenxi Yuan"
    ],
    "url": "",
    "venue": "Annals of Nuclear Energy",
    "publicationDate": null,
    "CitationCount": 1,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1002/adem.202401353",
    "title": "Electrospinning Technology, Machine Learning, and Control Approaches: A Review",
    "abstract": "Electrospinning is a versatile technique for producing micro‐ and nanoscale fibers, offering vast potential to address critical market demands, particularly in biomedical engineering. However, the industrial adoption of electrospinning as a manufacturing technology faces significant hurdles, notably in achieving precise control over fiber properties and ensuring reproducibility and scalability. These challenges directly impact its viability for creating advanced biomedical products. Bridging the gap between material properties, end‐user requirements, and process parameters is essential for unlocking the full potential of electrospinning. This work provides a comprehensive review of electrospinning modalities, operational factors, and modeling techniques, emphasizing their role in optimizing the electrospinning process. The use of control strategies and machine learning methods is explored, showcasing their potential to enhance the electrospinning performance. This review highlights the connection between product properties and performance in electrospinning, as well as the necessary conditions for its use in biomedical applications. In addition, the review identifies gaps and unexplored areas, offering a roadmap for future innovation in fiber fabrication. By emphasizing the synergy between intelligent process design and biomedical applications, this work lays the groundwork for advancements, positioning electrospinning as a cornerstone of next‐generation manufacturing technologies.",
    "authors": [
      "Arya Shabani",
      "Gorkem Anil Al",
      "Nael Berri",
      "Bernardo Castro‐Dominguez",
      "Hannah S. Leese",
      "Uriel Martínez-Hernández"
    ],
    "url": null,
    "venue": "Advanced Engineering Materials",
    "publicationDate": "2025-02-13",
    "CitationCount": 10,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1007/978-3-319-50427-8_12",
    "title": "Context Awareness for Semantic Mobile Computing",
    "abstract": null,
    "authors": [
      "Alejandro Rivero-Rodriguez",
      "O. Nykänen"
    ],
    "url": "",
    "venue": null,
    "publicationDate": null,
    "CitationCount": 0,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": null,
    "title": "Transferability of datasets between Machine-Learning Interaction Potentials",
    "abstract": "With the emergence of Foundational Machine Learning Interatomic Potential (FMLIP) models trained on extensive datasets, transferring data between different ML architectures has become increasingly important. In this work, we examine the extent to which training data optimised for one machine-learning forcefield algorithm may be re-used to train different models, aiming to accelerate FMLIP fine-tuning and to reduce the need for costly iterative training. As a test case, we train models of an organic liquid mixture that is commonly used as a solvent in rechargeable battery electrolytes, making it an important target for reactive MLIP development. We assess model performance by analysing the properties of molecular dynamics trajectories, showing that this is a more stringent test than comparing prediction errors for fixed datasets. We consider several types of training data, and several popular MLIPs - notably the recent MACE architecture, a message-passing neural network designed for high efficiency and smoothness. We demonstrate that simple training sets constructed without any ab initio dynamics are sufficient to produce stable models of molecular liquids. For simple neural-network architectures, further iterative training is required to capture thermodynamic and kinetic properties correctly, but MACE performs well with extremely limited datsets. We find that configurations designed by human intuition to correct systematic model deficiencies transfer effectively between algorithms, but active-learned data that are generated by one MLIP do not typically benefit a different algorithm. Finally, we show that any training data which improve model performance also improve its ability to generalise to similar unseen molecules. This suggests that trajectory failure modes are connected with chemical structure rather than being entirely system-specific.",
    "authors": [
      "Samuel P Niblett",
      "Panagiotis Kourtis",
      "Ioan B Magduau",
      "Clare P. Grey",
      "G'abor Cs'anyi"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2024-09-09",
    "CitationCount": 6,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1186/s12877-025-05840-w",
    "title": "A cross-sectional study comparing machine learning and logistic regression techniques for predicting osteoporosis in a group at high risk of cardiovascular disease among old adults",
    "abstract": "Osteoporosis has become a significant public health concern that necessitates the application of appropriate techniques to calculate disease risk. Traditional methods, such as logistic regression,have been widely used to identify risk factors and predict disease probability. However,with the advent of advanced statistics techniques,machine learning models offer promising alternatives for improving prediction accuracy. What's more, studies that use risk factors and prediction models for osteoporosis in high-risk groups for cardiovascular diseases are scarce. We aimed to explore the risk factors and disease probability of osteoporosis by comparing logistic regression with four machine learning models. By doing so,we seek to provide insights into the most effective methods for osteoporosis risk assessment and contribute to the development of tailored prevention strategies at high risk of cardiovascular disease among old adults. We carried out a cross-sectional investigation of a high-risk group in cardiovascular patients. A logistic regression model and four common machine learning methods,DT,RF,SVM,and XGBoost were implemented to create a prediction model using information from 211 participants who met the inclusion requirements. Metrics for calibration and discrimination were used to compare the models. In total,211 patients were enrolled. The AUCs were 0.751 for the logistic regression model,0.72 for the SVM model,0.70 for the random forest model,0.697 for the model XGBoost,and 0.69 for the decision tree model. The logistic regression model outperforms other models for machine learning. According to the logistic regression model,there were nine predictors,including age,sex,glucose,TG (triglyceride),fracture history,stroke history,and CNV (copy number variation) nssv659422, and low-sodium salt. A well-calibrated result of 0.199 on the Brier scale. The findings of the internal validation demonstrated the high degree of repeatability of the prediction model employed in this study. In this study, we discovered that when predicting osteoporosis,a number of machine learning techniques fell short of logistic regression. In a specific population, we have innovatively developed a risk prediction model for osteoporosis events that integrates genetic and environmental factors, is an effective tool for assessing osteoporosis risk and can serve as the basis for specialized intervention approaches.",
    "authors": [
      "Yuyi Peng",
      "Chi Zhang",
      "Bo Zhou"
    ],
    "url": null,
    "venue": "BMC Geriatrics",
    "publicationDate": "2025-03-29",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1186/s12904-022-01113-0",
    "title": "Impact of a machine learning algorithm on time to palliative care in a primary care population: protocol for a stepped-wedge pragmatic randomized trial",
    "abstract": "Background As primary care populations age, timely identification of palliative care need is becoming increasingly relevant. Previous studies have targeted particular patient populations with life-limiting disease, but few have focused on patients in a primary care setting. Toward this end, we propose a stepped-wedge pragmatic randomized trial whereby a machine learning algorithm identifies patients empaneled to primary care units at Mayo Clinic (Rochester, Minnesota, United States) with high likelihood of palliative care need. Methods 42 care team units in 9 clusters were randomized to 7 wedges, each lasting 42 days. For care teams in treatment wedges, palliative care specialists review identified patients, making recommendations to primary care providers when appropriate. Care teams in control wedges receive palliative care under the standard of care. Discussion This pragmatic trial therefore integrates machine learning into clinical decision making, instead of simply reporting theoretical predictive performance. Such integration has the possibility to decrease time to palliative care, improving patient quality of life and symptom burden. Trial registration Clinicaltrials.gov NCT04604457 , restrospectively registered 10/26/2020. Protocol v0.5, dated 9/23/2020",
    "authors": [
      "E. Heinzen",
      "Patrick M. Wilson",
      "C. Storlie",
      "Gabriel Demuth",
      "Shusaku W. Asai",
      "Gavin M. Schaeferle",
      "M. Bartley",
      "Rachel D. Havyer"
    ],
    "url": "https://bmcpalliatcare.biomedcentral.com/counter/pdf/10.1186/s12904-022-01113-0",
    "venue": "BMC Palliative Care",
    "publicationDate": "2023-02-03",
    "CitationCount": 6,
    "type": [
      "JournalArticle",
      "Review"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/ISEDA62518.2024.10617489",
    "title": "High-Dimensional Analog Circuit Sizing via Bayesian Optimization in the Variational Autoencoder Enhanced Latent Space",
    "abstract": "High-dimensional analog circuit sizing with machine learning-based surrogate models suffers from the high sampling cost of evaluating expensive black-box objective functions in huge design spaces. This work addresses the sampling efficiency challenge by elaborately reducing the dimensionality of the input spaces, enabling efficient optimization for automated analog circuit sizing. We propose a latent space optimization method that includes an iteratively updated generative model based on a variational autoencoder to embed the solution manifold of analog circuits to a low-dimensional and continuous space, where the latent variables are optimized using Bayesian optimization. The effectiveness of the proposed method has been verified on two real-world analog circuits with 18 and 59 design variables. In comparison with BO in the original high-d spaces or latent low-d spaces assisted by other embedding strategies, the proposed method achieves 23%~73% improvements in optimization per-formance within the same runtime limitations. We also conduct a technology migration experiment using the pre-trained variational autoencoder model, which demonstrates the necessity of pre-training and the scalability of the proposed method.",
    "authors": [
      "Wangzhen Li",
      "Zhaori Bi",
      "Xuan Zeng"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2024-05-10",
    "CitationCount": 1,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.21468/scipostphys.18.2.070",
    "title": "The landscape of unfolding with machine learning",
    "abstract": "Recent innovations from machine learning allow for data unfolding, without binning and including correlations across many dimensions. We describe a set of known, upgraded, and new methods for ML-based unfolding. The performance of these approaches are evaluated on the same two datasets. We find that all techniques are capable of accurately reproducing the particle-level spectra across complex observables. Given that these approaches are conceptually diverse, they offer an exciting toolkit for a new class of measurements that can probe the Standard Model with an unprecedented level of detail and may enable sensitivity to new phenomena.",
    "authors": [
      "Nathan Huetsch",
      "Javier Mariño Villadamigo",
      "Alexander Shmakov",
      "Sascha Diefenbacher",
      "V. M. Mikuni",
      "Theo Heimel",
      "M. J. Fenton",
      "Kevin Thomas Greif",
      "Benjamin Nachman",
      "D. Whiteson",
      "Anja Butter",
      "Tilman Plehn"
    ],
    "url": null,
    "venue": "SciPost Physics",
    "publicationDate": "2025-02-25",
    "CitationCount": 6,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.5555/2037151.2037189",
    "title": "Using a document classification task to introduce machine learning",
    "abstract": "We present an automated document classification task from the field of machine learning and argue that from both a conceptual and technical standpoint, this task can be addressed using algorithms accessible to first year students. Additionally, we provide some guidance to instructors in how to select a dataset to reinforce a particular learning objective within this simple machine learning project.",
    "authors": [
      "S. Wallace",
      "V. Pavlenko"
    ],
    "url": "",
    "venue": "Journal of Computing Sciences in Colleges (JCSC; Formerly: Journal of Computing in Small Colleges)",
    "publicationDate": "2011-10-01",
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1146/annurev.pc.31.100180.001105",
    "title": "Theory of the Main Lipid Bilayer Phase Transition",
    "abstract": "Machine learning (ML) is transforming all areas of science. The complex and time-consuming calculations in molecular simulations are particularly suitable for an ML revolution and have already been profoundly affected by the application of existing ML ...Read More",
    "authors": [
      "John F. Nagle"
    ],
    "url": null,
    "venue": "Annual Review of Physical Chemistry",
    "publicationDate": "1980-10-01",
    "CitationCount": 497,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1108/lhtn-08-2024-0132",
    "title": "Approaching beyond reality to connect realism in the library",
    "abstract": "Purpose\nThe purpose of this study is to investigate how libraries adopt beyond reality technologies like virtual reality, augmented reality, mixed reality and extended reality to provide an engaging environment and transform user service provision.\n\nDesign/methodology/approach\nThe study explained different facets of beyond reality. It surveyed various library websites and analysed literature dealing with varying forms of beyond reality technology to gain an idea of how libraries perceive the relevance of this emerging technology for incorporation in its workflow.\n\nFindings\nThe study presented some use case studies to give an overview of the adoption of this technology in libraries. The study also outlines the scope of future possibilities for the expansion of applications.\n\nOriginality/value\nThe practical examples will help improve the understanding of practicing librarians who are contemplating implementation or preparing to cover more areas under this technology in libraries and encourage researchers to explore the integration of artificial intelligence and machine learning with this technology in a cloud infrastructure to leverage maximum outcome in a broader perspective from this immersive technology.\n",
    "authors": [
      "Tanmay De Sarkar"
    ],
    "url": "",
    "venue": "Library Hi Tech News",
    "publicationDate": "2024-10-14",
    "CitationCount": 0,
    "type": [
      "JournalArticle",
      "Review"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/ISCIT63075.2024.10793695",
    "title": "Designing a User-Centric AI-Driven Mobile App for Personalized Time Management: Integrating Machine Learning and Design Thinking",
    "abstract": "Recent advancements in artificial intelligence (AI) have led to the development of innovative personalized intelligent assistants such as Google Home and Siri. Despite these technological strides, the integration of established design frameworks and user experience (UX) principles in user-centric AI applications remains insufficiently explored. This study utilizes the design thinking methodology-emphasizing empathy, ideation, and prototype testing-and existing UX laws to develop ‘TimeSync,’ an AI-based smart time management application university students in Thailand. ‘TimeSync’ employs a machine learning model to customize schedules and alarms by incorporating variables such as preparation time, weather, and traffic conditions, ensuring users arrive on time. Usability testing based on specific user satisfaction and usability metrics revealed that ‘TimeSync’ offers an intuitive interface and enhances user experience, promoting consistent utilization for effective time management. These findings demonstrate the significant potential of design thinking and UX principles in crafting user-centric AI applications, providing valuable insights and a robust framework for future AI development.",
    "authors": [
      "Punpaporn Saardloun",
      "Napacha Mahadumrongkul",
      "Kanis Surajarus",
      "Kankanit Suppataratarn",
      "Kantapong Horaraung",
      "Nalanlak Wonggulya",
      "Pann Klankasem",
      "Pitchapa Chaicharoen",
      "Weeraya Hew",
      "Sasinapa Anugulsawad",
      "Mohamed Skander Mahjoub",
      "Aung Pyae"
    ],
    "url": "",
    "venue": "International Symposium on Communications and Information Technologies",
    "publicationDate": "2024-09-23",
    "CitationCount": 2,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.3390/app112210795",
    "title": "Fine-Grained Named Entity Recognition Using a Multi-Stacked Feature Fusion and Dual-Stacked Output in Korean",
    "abstract": "Named entity recognition (NER) is a natural language processing task to identify spans that mention named entities and to annotate them with predefined named entity classes. Although many NER models based on machine learning have been proposed, their performance in terms of processing fine-grained NER tasks was less than acceptable. This is because the training data of a fine-grained NER task is much more unbalanced than those of a coarse-grained NER task. To overcome the problem presented by unbalanced data, we propose a fine-grained NER model that compensates for the sparseness of fine-grained NEs by using the contextual information of coarse-grained NEs. From another viewpoint, many NER models have used different levels of features, such as part-of-speech tags and gazetteer look-up results, in a nonhierarchical manner. Unfortunately, these models experience the feature interference problem. Our solution to this problem is to adopt a multi-stacked feature fusion scheme, which accepts different levels of features as its input. The proposed model is based on multi-stacked long short-term memories (LSTMs) with a multi-stacked feature fusion layer for acquiring multilevel embeddings and a dual-stacked output layer for predicting fine-grained NEs based on the categorical information of coarse-grained NEs. Our experiments indicate that the proposed model is capable of state-of-the-art performance. The results show that the proposed model can effectively alleviate the unbalanced data problem that frequently occurs in a fine-grained NER task. In addition, the multi-stacked feature fusion layer contributes to the improvement of NER performance, confirming that the proposed model can alleviate the feature interference problem. Based on this experimental result, we conclude that the proposed model is well-designed to effectively perform NER tasks.",
    "authors": [
      "Hongjin Kim",
      "Harksoo Kim"
    ],
    "url": "https://www.mdpi.com/2076-3417/11/22/10795/pdf?version=1637052254",
    "venue": "Applied Sciences",
    "publicationDate": "2021-11-15",
    "CitationCount": 6,
    "type": null,
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3389/fmars.2025.1523267",
    "title": "Application, opportunities, and challenges of digital technologies in the decarbonizing shipping industry: a bibliometric analysis",
    "abstract": "Introduction As Digital Industry 4.0 advances, shipping operators are progressively implementing digital technologies for maritime decarbonization efforts. Methods This review employs a bibliometric methodology to thoroughly examine and analyze the application of digital technology in decarbonizing shipping from 2005 to 2024. Examining 201 publications from the SCI-EXPANDED and SSCI databases elucidates the present condition, challenges, and prospects of digital technology applications in this domain. Results The review demonstrates the swift expansion of research on digital technologies for decarbonization within the shipping sector via an analysis of annual publication trends. Subsequent journal metrics and collaborative network analysis with VOSviewer identified particularly prolific journals, nations, institutions, and authors. Furthermore, this review delineates the field's principal research clusters and hotspots via keyword co-occurrence analysis, offering direction for future investigations. Ultimately, it examines research gaps in speed optimization, emission prediction, and autonomous ships by integrating keyword co-occurrence analysis with the content of recent publications, and then proposes prospective research options. Discussions Future studies on ship speed optimization could benefit from adopting multi-objective optimization methods, combining more machine-learning techniques with the FCP model, etc. Concerning emission prediction, future research efforts could focus on integrating more diverse external data sources into emission prediction models, adopting emerging technology applications, such as ship-based carbon capture (SBCC), introducing blockchain into smart emission monitoring systems, etc. Future research regarding autonomous ships can further refine optimizing route planning and navigation safety, autonomous ship energy efficiency and emission control, maritime communications and navigation systems, ship electrification, and green design.",
    "authors": [
      "Guangnian Xiao",
      "Lei Pan",
      "Fengbo Lai"
    ],
    "url": null,
    "venue": "Frontiers in Marine Science",
    "publicationDate": "2025-01-31",
    "CitationCount": 21,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.22399/ijasrar.18",
    "title": "Artificial Intelligence in Financial and Supply Chain Optimization: Predictive Analytics for Business Growth and Market Stability in The USA",
    "abstract": "This study investigates the application of Artificial Intelligence (AI) and Machine Learning (ML) in optimizing supply chain operations and financial forecasting in the USA. The research examines how AI-driven predictive analytics can foster business growth and stabilize markets. A diverse set of ML models is employed to address various challenges: Long Short-Term Memory (LSTM) networks are used for sequence forecasting in financial and economic domains, while Logistic Regression, Random Forest, and Boosting techniques support fraud detection. Additionally, autoencoders and Isolation Forest algorithms are applied to identify unusual financial transactions, and ARIMA models forecast demand spikes and seasonality. For logistics optimization, Reinforcement Learning ( Deep Q-Networks) is used to improve route planning, and Neural Networks predict optimal restocking periods based on demand patterns. XGBoost is used to assess customer price sensitivity and optimize pricing strategies. The performance of forecasting models is evaluated using Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE). In contrast, fraud detection effectiveness is measured through Precision, Recall, F1-score, and the Area Under the Curve (AUC-ROC). Logistics models are assessed by Total Delivery Time, Cost Reduction, and Efficiency Gains while restocking predictions are validated via accuracy, Mean Squared Error (MSE), and inventory turnover rates. Pricing strategies are evaluated based on Revenue Impact, Elasticity Metrics, and Customer Retention Rates.",
    "authors": [
      "Toyosi Motilola Olola",
      "Timilehin Isaiah Olatunde"
    ],
    "url": null,
    "venue": "",
    "publicationDate": "2025-03-07",
    "CitationCount": 41,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1016/j.conbuildmat.2022.127933",
    "title": "Prediction on compressive strength of Engineered Cementitious composites using Machine learning approach",
    "abstract": null,
    "authors": [
      "N. Shanmugasundaram",
      "S. Praveenkumar",
      "K. Gayathiri",
      "S. Divya"
    ],
    "url": "",
    "venue": "Construction and Building Materials",
    "publicationDate": "2022-08-01",
    "CitationCount": 34,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 1
  },
  {
    "source": "semantic_scholar",
    "DOI": null,
    "title": "Edge Sampling of Graphs: Graph Signal Processing Approach With Edge Smoothness",
    "abstract": "Finding important edges in a graph is a crucial problem for various research fields, such as network epidemics, signal processing, machine learning, and sensor networks. In this paper, we tackle the problem based on sampling theory on graphs. We convert the original graph to a line graph where its nodes and edges, respectively, represent the original edges and the connections between the edges. We then perform node sampling of the line graph based on the edge smoothness assumption: This process selects the most critical edges in the original graph. We present a general framework of edge sampling based on graph sampling theory and reveal a theoretical relationship between the degree of the original graph and the line graph. We also propose an acceleration method for edge sampling in the proposed framework by using the relationship between two types of Laplacian of the node and edge domains. Experimental results in synthetic and real-world graphs validate the effectiveness of our approach against some alternative edge selection methods.",
    "authors": [
      "Kenta Yanagiya",
      "Koki Yamada",
      "Yasuo Katsuhara",
      "Tomoya Takatani",
      "Yuichi Tanaka"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2024-07-14",
    "CitationCount": 1,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1016/j.ijmedinf.2025.105859",
    "title": "Stress monitoring using low-cost electroencephalogram devices: A systematic literature review",
    "abstract": "The use of low-cost, consumer-grade wearable health monitoring devices has become increasingly prevalent in mental health research, including stress studies. While cortisol response magnitude remains the gold standard for stress assessment, an expanding body of research employs low-cost EEG devices as primary tools for recording biomarker data, often combined with wrist and ring-based wearables. However, the technical variability among low-cost EEG devices, particularly in sensor count and placement according to the 10-20 Electrode Placement System, poses challenges for reproducibility in study outcomes. This review aims to provide an overview of the growing application of low-cost EEG devices and machine learning techniques for assessing brain function, with a focus on stress detection. It also highlights the strengths and weaknesses of various machine learning methods commonly used in stress research, and evaluates the reproducibility of reported findings along with sensor count and placement importance. A comprehensive review was conducted of published studies utilizing EEG devices for stress detection and their associated machine learning approaches. Searches were performed across databases including Scopus, Google Scholar, ScienceDirect, Nature, and PubMed, yielding 69 relevant articles for analysis. The selected studies were synthesized into four thematic categories: stress assessment using EEG, low-cost EEG devices, datasets for EEG-based stress measurement, and machine learning techniques for EEG-based stress analysis. For machine learning-focused studies, validation and reproducibility methods were critically assessed. Study quality was evaluated and scored using the IJMEDI checklist. The review identified several studies employing low-cost EEG devices to monitor brain activity during stress and relaxation phases, with many reporting high predictive accuracy using various machine learning validation techniques. However, only 54% of the studies included health screening prior to experimentation, and 58% were categorized as low-powered due to limited sample sizes. Additionally, few studies validated their results using an independent validation set or cortisol response as a correlating biomarker and there was a lack of consensus on data pre-processing and sensor placement as a key contributor to improving model generalization and accuracy. Low-cost consumer-grade wearable devices, including EEG and wrist-based monitors, are increasingly utilized in stress-related research, offering promising avenues for non-invasive biomarker monitoring. However, significant gaps remain in standardizing EEG signal processing and sensor placement, both of which are critical for enhancing model generalization and accuracy. Furthermore, the limited use of independent validation sets and cortisol response as correlating biomarkers highlights the need for more robust validation methodologies. Future research should focus on addressing these limitations and establishing consensus on data pre-processing techniques and sensor configurations to improve the reliability and reproducibility of findings in this growing field.",
    "authors": [
      "Gideon Vos",
      "Maryam Ebrahimpour",
      "Liza van Eijk",
      "Zoltán Sarnyai",
      "Mostafa Rahimi Azghadi"
    ],
    "url": null,
    "venue": "International Journal of Medical Informatics",
    "publicationDate": "2025-03-06",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1007/978-3-642-72201-1",
    "title": "Face Recognition",
    "abstract": null,
    "authors": [
      "Alice J. O'Toole",
      "Hervé Abdi",
      "Dominique Valentin"
    ],
    "url": "",
    "venue": "NATO ASI Series",
    "publicationDate": "1998-10-01",
    "CitationCount": 3,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/TASE.2024.3513354",
    "title": "Trajectory Progress-Based Prioritizing and Intrinsic Reward Mechanism for Robust Training of Robotic Manipulations",
    "abstract": "Training robots by model-free deep reinforcement learning (DRL) to carry out robotic manipulation tasks without sufficient successful experiences is challenging. Hindsight experience replay (HER) is introduced to enable DRL agents to learn from failure experiences. However, the HER-enabled model-free DRL still suffers from limited training performance due to its uniform sampling strategy and scarcity of reward information in the task environment. Inspired by the progress incentive mechanism in human psychology, we propose Progress Intrinsic Motivation-based HER (P-HER) in this work to overcome these difficulties. First, the Trajectory Progress-based Prioritized Experience Replay (TPPER) module is developed to prioritize sampling valuable trajectory data thereby achieving more efficient training. Second, the Progress Intrinsic Reward (PIR) module is introduced in agent training to add extra intrinsic rewards for encouraging the agents throughout the exploration of task space. Experiments in challenging robotic manipulation tasks demonstrate that our P-HER method outperforms original HER and state-of-the-art HER-based methods in training performance. Our code of P-HER and its experimental videos in both virtual and real environments are available at https://github.com/weixiang-smart/P-HER. Note to Practitioners—This work is motivated to develop a fast and effective learning method for intelligent robotic manipulation of typical industrial tasks, including pushing, picking, and placing workpieces, which are essential and fundamental processing plan activities for accomplishing robotic machining and assembly applications towards smart manufacturing. The introduction of reinforcement learning enables robots to learn manipulation tasks autonomously, which can save the effort for engineers to teach or hard program the robot and also reduce labor costs. However, the existing HER-based reinforcement learning algorithms are with low training efficiency and performance due to the uniform sampling and scant task reward. Inspired by human learning, this work introduces a progress incentive mechanism to identify valuable trajectory data for effective training. In addition, a novel rewarding method, that applies additional intrinsic rewards for agents learning valuable trajectory space, results in fast and robust learning. The setting of important weight parameters in the rewarding method is given in the paper, which provides a practical reference for applying the proposed algorithm. The average success rate of two actual manipulation tasks in simulation and real robotic manipulation environments are 96% and 92.5%, respectively, which demonstrates that the method is effective for both environments and there is 3.5% average gap of successful rate dropping from simulation scenarios to real ones due to the inherent mismatches between simulation and reality. The high success rate demonstrated in the real Workpieces-sorting task exemplifies the potential of the trained policies for application in industrial scenarios.",
    "authors": [
      "Weixiang Liang",
      "Yinlong Liu",
      "Jikun Wang",
      "Zhi-xin Yang"
    ],
    "url": "",
    "venue": "IEEE Transactions on Automation Science and Engineering",
    "publicationDate": null,
    "CitationCount": 1,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1016/j.ejogrb.2022.12.008",
    "title": "Artificial intelligence and machine learning in cardiotocography: A scoping review.",
    "abstract": null,
    "authors": [
      "J. L. Aeberhard",
      "Anda Radan",
      "R. Delgado-Gonzalo",
      "K. Strahm",
      "Halla Sigurthorsdottir",
      "S. Schneider",
      "D. Surbek"
    ],
    "url": "",
    "venue": "European Journal of Obstetrics, Gynecology, and Reproductive Biology",
    "publicationDate": "2022-12-01",
    "CitationCount": 17,
    "type": [
      "Review",
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 1
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/bs15020211",
    "title": "Estimating the Minimum Sample Size for Neural Network Model Fitting—A Monte Carlo Simulation Study",
    "abstract": "In the era of machine learning, many psychological studies use machine learning methods. Specifically, neural networks, a set of machine learning methods that exhibit exceptional performance in various tasks, have been used on psychometric datasets for supervised model fitting. From the computer scientist's perspective, psychometric independent variables are typically ordinal and low-dimensional-characteristics that can significantly impact model performance. To our knowledge, there is no guidance about the sample planning suggestion for this task. Therefore, we conducted a simulation study to test the performance of an NN with different sample sizes and the simulation of both linear and nonlinear relationships. We proposed the minimum sample size for the neural network model fitting with two criteria: the performance of 95% of the models is close to the theoretical maximum, and 80% of the models can outperform the linear model. The findings of this simulation study show that the performance of neural networks can be unstable with ordinal variables as independent variables, and we suggested that neural networks should not be used on ordinal independent variables with at least common nonlinear relationships in psychology. Further suggestions and research directions are also provided.",
    "authors": [
      "Yongtian Cheng",
      "K. V. Petrides",
      "Johnson Li"
    ],
    "url": null,
    "venue": "Behavioral Sciences",
    "publicationDate": "2025-02-14",
    "CitationCount": 5,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/URTC60662.2023.10534939",
    "title": "Path Synthesis of Planar Linkage Mechanisms Using Deep Generative Models",
    "abstract": "The problem of path generation of planar mechanisms, or determining their motion as traced by a coupler curve, has been almost exclusively met with analytical solutions, leading to high run-time and low efficiency. In contrast, our approach utilizes a Machine Learning model, implementing a novel approach combining a generative AI model known as a Variational Autoencoder with a Fully Connected Neural Network to produce four-bar, six-bar, and eight-bar mechanisms to fit a desired path. We also determine which representations of the input coupler curve lead to the most accurate mechanisms. This work significantly improves the efficiency and automation of mechanism design.",
    "authors": [
      "Abhay Bhaskar",
      "Anar Nurizada",
      "A. Purwar"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2023-10-06",
    "CitationCount": 0,
    "type": [
      "Conference"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/polym17040491",
    "title": "Support Vector Machines in Polymer Science: A Review",
    "abstract": "Polymer science, a discipline focusing on the synthesis, characterization, and application of macromolecules, has increasingly benefited from the adoption of machine learning (ML) techniques. Among these, Support Vector Machines (SVMs) stand out for their ability to handle nonlinear relationships and high-dimensional datasets, which are common in polymer research. This review explores the diverse applications of SVM in polymer science. Key examples include the prediction of mechanical and thermal properties, optimization of polymerization processes, and modeling of degradation mechanisms. The advantages of SVM are contrasted with its challenges, including computational cost, data dependency, and the need for hyperparameter tuning. Future opportunities, such as the development of polymer-specific kernels and integration with real-time manufacturing systems, are also discussed.",
    "authors": [
      "Ivan Malashin",
      "В С Тынченко",
      "Andrei Gantimurov",
      "Vladimir Nelyub",
      "А. С. Бородулин"
    ],
    "url": null,
    "venue": "Polymers",
    "publicationDate": "2025-02-13",
    "CitationCount": 8,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": null,
    "title": "Property rights, market access and crop cultivation in Southern Rhodesia: evidence from historical satellite data",
    "abstract": null,
    "authors": [
      "T. Chingozha",
      "D. V. Fintel"
    ],
    "url": "",
    "venue": null,
    "publicationDate": null,
    "CitationCount": 0,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1201/9781003472094",
    "title": "Applied Survey Data Analysis",
    "abstract": "Highly recommended by the Journal of Official Statistics, The American Statistician, and other top statistical journals, Applied Survey Data Analysis, Third Edition provides an up-to-date overview of state-of-the-art approaches to the analysis of complex sample survey data. Building on the wealth of material on practical approaches to descriptive analysis and regression modeling from the first and second editions, this third edition further expands the topics covered and presents more step-by-step examples of modern approaches to the analysis of survey data using the newest statistical software procedures. New to the Third Edition: Applied Bayesian methods for the analysis of complex sample survey data using available software implementing these methods State-of-the-art methods and software for the analysis of survey data collected from non-probability samples Software for modern applications of machine learning techniques to complex sample survey data A completely revamped website providing code for replicating all the analyses illustrated in the book using Stata, SAS, SPSS, R, Mplus, SUDAAN, WesVar, and IVEware New end-of-chapter exercises, allowing for practice implementing the methods, including Bayesian analysis exercises Updated summaries of the newest literature on the analysis of survey data collected from complex samples An updated review of software packages currently available for the analysis of complex sample survey data Designed for readers working in a wide array of disciplines who conduct secondary analyses of survey data as part of their applied work, this book continues to provide a practical and accessible guide to the analysis of survey data. Continuing to use an example-driven approach to clearly illustrate analysis methods and software, the third edition contains many new examples and practical exercises based on recent versions of real-world survey data sets. Although the authors continue to use Stata for most examples in the text, they also offer the newest code for replicating the examples in other popular software packages on the book's revamped website.",
    "authors": [
      "Brady T. West",
      "Steve Heeringa",
      "Patricia A. Berglund"
    ],
    "url": null,
    "venue": "",
    "publicationDate": "2025-03-13",
    "CitationCount": 36,
    "type": "monograph",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.54216/mor.030203",
    "title": "A Review on Designing Hybrid Energy Systems for Renewable Integration",
    "abstract": "This paper reviews the design and integration of hybrid energy systems (HES) as a solution to solve the challenges of renewable energy integration. It emphasizes the role of optimization algorithms in improving system performance, reducing costs and enhancing environmental sustainability by effectively managing energy supply and demand. Recent advances in energy estimating, machine learning, and accurate resource forecasting demonstrate significant system flexibility and efficiency increases. Furthermore, it identifies existing challenges, such as scalability, high initial costs and integration complexities, while proposing future research and innovation pathways. The study argues that HES can revolutionize energy systems and contribute to global sustainability goals by addressing key gaps.",
    "authors": [
      "Khaled Khaled"
    ],
    "url": null,
    "venue": "",
    "publicationDate": "2025-01-01",
    "CitationCount": 6,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1146/annurev.pc.31.100180.003131",
    "title": "Surface Diffusion",
    "abstract": "Machine learning (ML) is transforming all areas of science. The complex and time-consuming calculations in molecular simulations are particularly suitable for an ML revolution and have already been profoundly affected by the application of existing ML ...Read More",
    "authors": [
      "G. Ehrlich",
      "Kaj Stolt"
    ],
    "url": null,
    "venue": "Annual Review of Physical Chemistry",
    "publicationDate": "1980-10-01",
    "CitationCount": 330,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1186/s43556-024-00238-3",
    "title": "The role of artificial intelligence in pandemic responses: from epidemiological modeling to vaccine development",
    "abstract": "Abstract Integrating Artificial Intelligence (AI) across numerous disciplines has transformed the worldwide landscape of pandemic response. This review investigates the multidimensional role of AI in the pandemic, which arises as a global health crisis, and its role in preparedness and responses, ranging from enhanced epidemiological modelling to the acceleration of vaccine development. The confluence of AI technologies has guided us in a new era of data-driven decision-making, revolutionizing our ability to anticipate, mitigate, and treat infectious illnesses. The review begins by discussing the impact of a pandemic on emerging countries worldwide, elaborating on the critical significance of AI in epidemiological modelling, bringing data-driven decision-making, and enabling forecasting, mitigation and response to the pandemic. In epidemiology, AI-driven epidemiological models like SIR (Susceptible-Infectious-Recovered) and SIS (Susceptible-Infectious-Susceptible) are applied to predict the spread of disease, preventing outbreaks and optimising vaccine distribution. The review also demonstrates how Machine Learning (ML) algorithms and predictive analytics improve our knowledge of disease propagation patterns. The collaborative aspect of AI in vaccine discovery and clinical trials of various vaccines is emphasised, focusing on constructing AI-powered surveillance networks. Conclusively, the review presents a comprehensive assessment of how AI impacts epidemiological modelling, builds AI-enabled dynamic models by collaborating ML and Deep Learning (DL) techniques, and develops and implements vaccines and clinical trials. The review also focuses on screening, forecasting, contact tracing and monitoring the virus-causing pandemic. It advocates for sustained research, real-world implications, ethical application and strategic integration of AI technologies to strengthen our collective ability to face and alleviate the effects of global health issues.",
    "authors": [
      "Mayur Suresh Gawande",
      "N. N. Zade",
      "Praveen Kumar",
      "Swapnil Gundewar",
      "Induni Nayodhara Weerarathna",
      "Prateek Verma"
    ],
    "url": null,
    "venue": "Molecular Biomedicine",
    "publicationDate": "2025-01-03",
    "CitationCount": 21,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.32996/jcsts.2025.7.1.15",
    "title": "Predicting Energy Consumption in Hospitals Using Machine Learning: A Data-Driven Approach to Energy Efficiency in the USA",
    "abstract": "In the USA, hospitals are confronted with significant challenges regarding energy consumption, which not only impacts operational costs but also contributes to environmental concerns. The primary objective of this research was to develop and evaluate machine learning models that are capable of accurately predicting energy consumption in U.S. hospitals. This study will be focused on United States hospital energy consumption data, recognizing the unique difficulties and opportunities present in the U.S. healthcare setting. The data used for this hospital energy consumption analysis has been carefully gathered from multiple credible sources, including the U.S. Department of Energy's Energy Star program, whole-building hospital energy audits, and information from local utility providers. This variety in sourcing guarantees a strong and complete dataset that accurately represents real-world energy dynamics in healthcare buildings. In the model selection phase, three powerful algorithms were employed: the Random Forest Classifier, XG-Boost, and Artificial Neural Network (ANN). XG-Boost outperformed other models after tuning, achieving an 81.8% accuracy on the test set. Random Forest showed a decent improvement post-tuning but still lagged behind XG-Boost. Hospital managers can utilize machine learning (ML)--based predictions to achieve substantial cost savings in operational expenditures related to energy usage. With predictive analytics, hospitals can anticipate energy needs based on several parameters, such as patient occupancy rates, time of day, and seasonality. Integration of AI-driven energy prediction in hospital sustainability plans has significant policy implications for the U.S. healthcare sector. The integration of machine learning models and the Internet of Things (IoT)-)-)-enabled energy management systems is a breakthrough step in embracing smart hospital initiatives.",
    "authors": [
      "Adib Ahmed",
      "Tanaya Jakir",
      "Md Nazmul Hossain Mir",
      "MD Abdul Fahim Zeeshan",
      "Arat Hossain",
      "Afrin Hoque Jui",
      "Md Sakibul Hasan"
    ],
    "url": null,
    "venue": "Journal of Computer Science and Technology Studies",
    "publicationDate": "2025-02-14",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1007/s11340-024-01136-z",
    "title": "An Inverse Parameter Identification in Finite Element Problems Using Machine Learning-Aided Optimization Framework",
    "abstract": "The ability of finite element analysis to produce high fidelity results is greatly dependent on quality of constitutive model and the accuracy of their parameters. As such, the calibration of phenomenological constitutive models to replicate real-world behaviors has remained a focal point of many research works. A new inverse identification approach combining numerical-experimental methods and data-driven techniques to characterize the nonlinear response of materials using a single experiment is proposed. This approach integrates finite element analysis, optimization methods and machine learning techniques, such as Artificial Neural Networks and Support Vector Regression, to accurately determine model parameters while significantly reducing computational time. This approach can be used to characterize a wide range of models irrespective of the number of parameters involved. A detailed flowchart of the methodology focusing on its implementation aspects is provided and its each module is explained. The proposed model calibration approach successfully identified eight parameters for a cohesive zone model implemented in user element subroutine (UEL), four parameters for a hardening model implemented in user material subroutine (UMAT), and five parameters for a Johnson–Cook plasticity model. In all cases, this method achieved an excellent fit between the simulation and experimental results. Moreover, it demonstrated a significant improvement in efficiency, being 2–3 times faster than traditional optimization algorithms in determining optimal parameters. Based on the presented investigations, the proposed machine learning-based inverse method can significantly accelerate the parameter identification procedure and can be extended to a wide range of material models.",
    "authors": [
      "Aiman Tarıq",
      "Babür Deliktaş"
    ],
    "url": "https://link.springer.com/content/pdf/10.1007/s11340-024-01136-z.pdf",
    "venue": "Experimental Mechanics",
    "publicationDate": "2025-01-16",
    "CitationCount": 10,
    "type": "journal-article",
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": null,
    "title": "Cluster-analytic classification of facial expressions using infrared measurements of facial thermal features",
    "abstract": null,
    "authors": [
      "M. Khan"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2008-03-01",
    "CitationCount": 9,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/BIBM52615.2021.9669784",
    "title": "Convolutional Neural Network Techniques on X-ray Images for Covid-19 Classification",
    "abstract": "At the end of 2019, the World Health Organization (WHO) referred that the Public Health Commission of Hubei Province, China, reported cases of severe and unknown pneumonia. A new coronavirus, SARS-CoV-2, was identified as responsible for the lung infection, called COVID-19 (coronavirus disease 2019). An early diagnosis of those carrying the virus becomes crucial to contain the spread, morbidity and mortality of the pandemic. The definitive diagnosis is made through specific tests, among which imaging tests play a very important role. Achieving this goal cannot be separated from radiological examination, and chest X-ray is the most easily available and least expensive alternative. The use of X-ray chest radiographs, as an element that assists the diagnosis and that allows the follow up of the disease, is the subject of many publications that adopt machine learning approaches. This work focuses on the most adopted Convolutional Neural Network Techniques applied on chest X-ray images.",
    "authors": [
      "Eugenio Vocaturo",
      "E. Zumpano",
      "Luciano Caroprese"
    ],
    "url": "",
    "venue": "IEEE International Conference on Bioinformatics and Biomedicine",
    "publicationDate": "2021-12-09",
    "CitationCount": 9,
    "type": [
      "JournalArticle",
      "Conference"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 1
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.32523/2616-7263-2024-149-4-256-268",
    "title": "Modern types of machine vision for vehicle inspection",
    "abstract": "In this scientific article, modern types of machine vision are examined, which are widely used in the process of inspecting vehicles at various stages of their production and operation. Machine vision serves as an important tool that enhances the quality and safety of vehicles, as well as optimizes production processes. The article discusses key technologies such as lighting technologies that provide the necessary illumination for accurate image analysis, as well as image processing, which allows for the extraction of useful information from visual data.\n\nAdditionally, special attention is given to machine learning algorithms that enable machine vision systems to adapt and improve their accuracy over time. Stereovision, as a method, is also considered in the context of creating three-dimensional models of objects, significantly increasing the accuracy of defect detection. The article emphasizes automated quality control methods, including the use of high-resolution cameras capable of detecting defects, damages, and discrepancies in the design and finish of vehicles. These technologies play a crucial role in ensuring high standards of quality and reliability in vehicles, which, in turn, contributes to increasing consumer trust in manufacturers.",
    "authors": [
      "A.E. Kairatova",
      "N.S. Kamzanov",
      "T.S. Beketov",
      "A.Z. Abekova",
      "K.K. Zabiyeva"
    ],
    "url": "",
    "venue": "Bulletin of L.N. Gumilyov Eurasian National University. Technical Science and Technology Series",
    "publicationDate": null,
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1146/annurev.fl.12.010180.001255",
    "title": "Scientific Progress on Fire",
    "abstract": "The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from experiments, field measurements, and large-scale simulations at multiple spatiotemporal scales. Machine learning (ML) offers a wealth of techniques to extract ...Read More",
    "authors": [
      "Howard W. Emmons"
    ],
    "url": null,
    "venue": "Annual Review of Fluid Mechanics",
    "publicationDate": "1980-01-01",
    "CitationCount": 23,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s44385-024-00003-9",
    "title": "Application of Artificial Intelligence In Drug-target Interactions Prediction: A Review",
    "abstract": "Abstract Predicting drug-target interactions (DTI) is a complex task. With the introduction of artificial intelligence (AI) methods such as machine learning and deep learning, AI-based DTI prediction can significantly enhance speed, reduce costs, and screen potential drug design options before conducting actual experiments. However, the application of AI methods also faces several challenges that need to be addressed. This article reviews various AI-based approaches and suggests possible future directions.",
    "authors": [
      "Qian Liao",
      "Yu Zhang",
      "Ying Chu",
      "Yi Ding",
      "Han‐Xiong Li",
      "Xianyi Zhao",
      "Yizheng Wang",
      "Jie Wan",
      "Yijie Ding",
      "Prayag Tiwari",
      "Quan Zou",
      "Ke Han"
    ],
    "url": null,
    "venue": "npj Biomedical Innovations.",
    "publicationDate": "2025-01-13",
    "CitationCount": 5,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.4018/979-8-3693-9341-3.ch003",
    "title": "AI-Powered Breakthroughs",
    "abstract": "This chapter examines how artificial intelligence (AI) is improving neuropsychological practice and how AI tools can be used to diagnose treat and rehabilitate cognitive disorders. Through a critical analysis of recent research and developing patterns the chapter emphasizes AIs potential for neuropsychology real-time interventions personalized care and early detection. It explores how artificial intelligence (AI) has advanced to create tools like virtual assistants chatbots and machine learning algorithms that have greatly enhanced neuropsychological testing and treatment. AI in neurorehabilitation shows encouraging results improving the precision and effectiveness of treatment regimens particularly for patients with brain injuries or cognitive decline. The chapter also examines the effects of AI on neuropsychological training and education with a focus on preparing the next generation of neuropsychologists for practice settings enhanced by AI.",
    "authors": [
      "Muhammad Usman Tariq"
    ],
    "url": null,
    "venue": "Advances in psychology, mental health, and behavioral studies (APMHBS) book series",
    "publicationDate": "2025-01-03",
    "CitationCount": 14,
    "type": "book-chapter",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/jtaer20010028",
    "title": "An Analysis of Consumer Purchase Behavior Following Cart Addition in E-Commerce Utilizing Explainable Artificial Intelligence",
    "abstract": "To optimize personalized offers and reduce cart abandonment, it is essential to understand customer behavior in e-commerce after products are added to the cart. Although purchase prediction models are well researched, session-level changes, including price variations, product category shifts, and geographical context, are less examined concerning their impact on machine learning models for predicting purchase behavior after cart additions. This study incorporates these factors into machine learning models to examine their impacts on predictions using explainable AI techniques. The comprehensive experimental results obtained from two datasets and eight models demonstrate that machine learning algorithms can achieve an F1 score of 89% in predicting purchase behavior following cart additions. This study highlights the significant impact of session-specific factors, like price fluctuations, category transitions, and geographical context, coupled with consumers’ previous browsing patterns, on model predictions.",
    "authors": [
      "Ramazan Esmeli",
      "Aytac Gokce"
    ],
    "url": null,
    "venue": "Journal of theoretical and applied electronic commerce research",
    "publicationDate": "2025-02-13",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.30574/ijsra.2023.10.1.0720",
    "title": "Machine learning practices in accounting and auditing",
    "abstract": "In the current technological era, Machine Learning applications are becoming popular every day. This research paper provides information about the effectiveness of the ML technique in accounting as well as the auditing process. To get proper results, different ML libraries are utilized, concluding seaborn, matplotlib, NumPy and so on. In the introduction section, the research purpose and this research objectives have been developed, through which the entire research process will be developed. “Logistic Regression Machine Learning Model” is built. Literary sources have been analyzed in the literature review section, through which it can be easy to gain different perceptions based on the research context. The effectiveness of different types of machine learning algorithms in accounting and auditing has been evaluated properly. To develop a knowledge level, it is important to increase proper attention, and this research paper will provide proper information based on ML effectiveness.",
    "authors": [
      "Chetanpal Singh",
      "Rahul Thakkar",
      "Rashikala Weerawarna",
      "Vimal B. Patel"
    ],
    "url": "https://ijsra.net/sites/default/files/IJSRA-2023-0720_0.pdf",
    "venue": "International Journal of Science and Research Archive",
    "publicationDate": "2023-09-30",
    "CitationCount": 1,
    "type": [
      "JournalArticle",
      "Review"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1007/s10462-024-11082-w",
    "title": "Advancements in securing federated learning with IDS: a comprehensive review of neural networks and feature engineering techniques for malicious client detection",
    "abstract": "Federated Learning (FL) is a technique that can learn a global machine-learning model at a central server by aggregating locally trained models. This distributed machine-learning approach preserves the privacy of local models. However, FL systems are inherently vulnerable to significant security challenges such as cyber-attacks, handling non-independent and identically distributed (non-IID) data, and data privacy concerns. This systematic literature review addresses these issues by examining advanced neural network models, feature engineering methods, and privacy-preserving techniques within intrusion detection systems (IDS) for FL environments. These are key elements for improving the security of FL systems. To the best of our knowledge, this review is among the first to comprehensively explore the combined impacts of these technologies. We analyzed 88 studies published between 2021 and October 2024. This study offers valuable insights for future research directions, including scaling FL in a real-world environment.",
    "authors": [
      "Naila Latif",
      "Wenping Ma",
      "Hafiz Bilal Ahmad"
    ],
    "url": null,
    "venue": "Artificial Intelligence Review",
    "publicationDate": "2025-01-13",
    "CitationCount": 7,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1002/eng2.13091",
    "title": "PD_EBM: An Integrated Boosting Approach Based on Selective Features for Unveiling Parkinson's Disease Diagnosis With Global and Local Explanations",
    "abstract": "ABSTRACT Early detection and characterization are crucial for treating and managing Parkinson's disease (PD). The increasing prevalence of PD and its significant impact on the motor neurons of the brain impose a substantial burden on the healthcare system. Early‐stage detection is vital for improving patient outcomes and reducing healthcare costs. This study introduces an ensemble boosting machine, termed PD_EBM, for the detection of PD. PD_EBM leverages machine learning (ML) algorithms and a hybrid feature selection approach to enhance diagnostic accuracy. While ML has shown promise in medical applications for PD detection, the interpretability of these models remains a significant challenge. Explainable machine learning (XML) addresses this by providing transparency and clarity in model predictions. Techniques such as Local Interpretable Model‐agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP) have become popular for interpreting these models. Our experiment used a dataset of 195 clinical records of PD patients from the University of California Irvine (UCI) Machine Learning repository. Comprehensive data preparation included encoding categorical features, imputing missing values, removing outliers, addressing data imbalance, scaling data, selecting relevant features, and so on. We propose a hybrid boosting framework that focuses on the most important features for prediction. Our boosting model employs a Decision Tree (DT) classifier with AdaBoost, followed by a linear discriminant analysis (LDA) optimizer, achieving an impressive accuracy of 99.44%, outperforming other boosting models.",
    "authors": [
      "Fahmida Khanom",
      "Mohammad Shorif Uddin",
      "Rafid Mostafiz"
    ],
    "url": null,
    "venue": "Engineering Reports",
    "publicationDate": "2025-01-01",
    "CitationCount": 6,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.48175/ijarsct-14367",
    "title": "Challenges Faced During Implementation of Digital Twin in Construction Project Monitoring",
    "abstract": "Digital Twins (DTs) are gaining popularity because they provide precise digital copies of assets, processes, and systems. This is especially true when these DTs are paired with real-time simulation models that make use of modern technologies like machine learning, artificial intelligence, and data analytics. These combinations can provide a comprehensive and dynamic view of the monitored systems. Digital twin (DT) has shown tremendous potential to bring about revolutionary improvements in the field of construction site surveillance. There is, however, a notable paucity of empirical research identifying the constant elements affecting DT adoption in this industry. This research tries to fill that void by identifying the important elements that determine the usage of DT in construction. The study adopts a complete framework with the goal of increasing the use of DT in building site monitoring. The elements influencing the adoption and effectiveness of distributed ledger technology (DT) are divided into three categories: technological, organizational, and economic. Technological factors include the system's appropriateness and the robustness of the data infrastructure. Organizational considerations include the company's openness to innovation and leadership support. Economic aspects include things like return on investment (ROI) and cost-effectiveness. The research technique combines case studies and literature reviews to examine the benefits and drawbacks of DT in construction monitoring. This study's expected output is a comprehensive framework that aids construction businesses in optimizing the use of DT in site monitoring. This would allow for more efficient, data-driven, and forward-thinking processes. The study's ultimate purpose is to provide critical knowledge that will assist the building sector in adopting cutting-edge methods. The industry may better plan for the integration of this sophisticated technology into their operations by knowing the potential of DT and the variables driving its adoption. This, in turn, can lead to more efficiency, lower risks, and improved overall performance",
    "authors": [
      "M. Dhayanand",
      "M. Bharath",
      "M. P. Prabakaran",
      "M. S. vaardhini",
      "Construction Management Student"
    ],
    "url": "https://doi.org/10.48175/ijarsct-14367",
    "venue": "International Journal of Advanced Research in Science, Communication and Technology",
    "publicationDate": "2023-12-31",
    "CitationCount": 0,
    "type": [
      "JournalArticle",
      "Review"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s41598-024-82282-1",
    "title": "Enhancing predictive accuracy for urinary tract infections post-pediatric pyeloplasty with explainable AI: an ensemble TabNet approach",
    "abstract": "Ureteropelvic junction obstruction (UPJO) is a common pediatric condition often treated with pyeloplasty. Despite the surgical intervention, postoperative urinary tract infections (UTIs) occur in over 30% of cases within six months, adversely affecting recovery and increasing both clinical and economic burdens. Current prediction methods for postoperative UTIs rely on empirical judgment and limited clinical parameters, underscoring the need for a robust, multifactorial predictive model. We retrospectively analyzed data from 764 pediatric patients who underwent unilateral pyeloplasty at the Children's Hospital affiliated with the Capital Institute of Pediatrics between January 2012 and January 2023. A total of 25 clinical features were extracted, including patient demographics, medical history, surgical details, and various postoperative indicators. Feature engineering was initially performed, followed by a comparative analysis of five machine learning algorithms (Logistic Regression, SVM, Random Forest, XGBoost, and LightGBM) and the deep learning TabNet model. This comparison highlighted the respective strengths and limitations of traditional machine learning versus deep learning approaches. Building on these findings, we developed an ensemble learning model, meta-learner, that effectively integrates both methodologies, and utilized SHAP(Shapley Additive Explanation, SHAP) to complete the visualization of the integrated black-box model. Among the 764 pediatric pyeloplasty cases analyzed, 265 (34.7%) developed postoperative UTIs, predominantly within the first three months. Early UTIs significantly increased the likelihood of re-obstruction (P < 0.01), underscoring the critical impact of infection on surgical outcomes. In evaluating the performance of six algorithms, TabNet outperformed traditional models, with the order from lowest to highest as follows: Logistic Regression, SVM, Random Forest, XGBoost, LightGBM, and TabNet. Feature engineering markedly improved the predictive accuracy of traditional models, as evidenced by the enhanced performance of LightGBM (Accuracy: 0.71, AUC: 0.78 post-engineering). The proposed ensemble approach, combining LightGBM and TabNet with a Logistic Regression meta-learner, achieved superior predictive accuracy (Accuracy: 0.80, AUC: 0.80) while reducing dependence on feature engineering. SHAP analysis further revealed eGFR and ALB as significant predictors of UTIs post-pyeloplasty, providing new clinical insights into risk factors. In summary, we have introduced the first ensemble prediction model, incorporating both machine learning and deep learning (meta-learner), to predict urinary tract infections following pediatric pyeloplasty. This ensemble approach mitigates the dependency of machine learning models on feature engineering while addressing the issue of overfitting in deep learning-based models like TabNet, particularly in the context of small medical datasets. By improving prediction accuracy, this model supports proactive interventions, reduces postoperative infections and re-obstruction rates, enhances pyeloplasty outcomes, and alleviates health and economic burdens. Level of evidence IV Case series with no comparison group.",
    "authors": [
      "Hongyang Wang",
      "Junpeng Ding",
      "Shuochen Wang",
      "Long Li",
      "Jinqiu Song",
      "Dongsheng Bai"
    ],
    "url": null,
    "venue": "Scientific Reports",
    "publicationDate": "2025-01-19",
    "CitationCount": 6,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/bios15020075",
    "title": "Artificial-Intelligence Bio-Inspired Peptide for Salivary Detection of SARS-CoV-2 in Electrochemical Biosensor Integrated with Machine Learning Algorithms",
    "abstract": "Developing affordable, rapid, and accurate biosensors is essential for SARS-CoV-2 surveillance and early detection. We created a bio-inspired peptide, using the SAGAPEP AI platform, for COVID-19 salivary diagnostics via a portable electrochemical device coupled to Machine Learning algorithms. SAGAPEP enabled molecular docking simulations against the SARS-CoV-2 Spike protein's RBD, leading to the synthesis of Bio-Inspired Artificial Intelligence Peptide 1 (BIAI1). Molecular docking was used to confirm interactions between BIAI1 and SARS-CoV-2, and BIAI1 was functionalized on rhodamine-modified electrodes. Cyclic voltammetry (CV) using a [Fe(CN)6]3-/4 solution detected virus levels in saliva samples with and without SARS-CoV-2. Support vector machine (SVM)-based machine learning analyzed electrochemical data, enhancing sensitivity and specificity. Molecular docking revealed stable hydrogen bonds and electrostatic interactions with RBD, showing an average affinity of -250 kcal/mol. Our biosensor achieved 100% sensitivity, 80% specificity, and 90% accuracy for 1.8 × 10⁴ focus-forming units in infected saliva. Validation with COVID-19-positive and -negative samples using a neural network showed 90% sensitivity, specificity, and accuracy. This BIAI1-based electrochemical biosensor, integrated with machine learning, demonstrates a promising non-invasive, portable solution for COVID-19 screening and detection in saliva.",
    "authors": [
      "Marcelo Augusto Garcia-Júnior",
      "Bruno Silva Andrade",
      "Ana P. Lima",
      "Iara Pereira Soares",
      "Ana Flávia Oliveira Notário",
      "Sttephany Silva Bernardino",
      "Marco Guevara-Vega",
      "Ghabriel Honório-Silva",
      "Rodrigo A.A. Muñoz",
      "Ana Carolina Gomes Jardim",
      "Mário Machado Martins",
      "Luíz Ricardo Goulart",
      "Thúlio Marquez Cunha",
      "Murillo G. Carneiro",
      "Robinson Sabino‐Silva"
    ],
    "url": null,
    "venue": "Biosensors",
    "publicationDate": "2025-01-28",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1146/annurev.pc.31.100180.003015",
    "title": "Two-Photon Molecular Electronic Spectroscopy",
    "abstract": "Machine learning (ML) is transforming all areas of science. The complex and time-consuming calculations in molecular simulations are particularly suitable for an ML revolution and have already been profoundly affected by the application of existing ML ...Read More",
    "authors": [
      "Donald M. Friedrich",
      "W. M. McClain"
    ],
    "url": null,
    "venue": "Annual Review of Physical Chemistry",
    "publicationDate": "1980-10-01",
    "CitationCount": 108,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s41598-025-88704-y",
    "title": "Constructing a machine learning model for systemic infection after kidney stone surgery based on CT values",
    "abstract": "This study aims to develop a machine learning model utilizing Computed Tomography (CT) values to predict systemic inflammatory response syndrome (SIRS) after endoscopic surgery for kidney stones. The goal is to identify high-risk patients early and provide valuable guidance for urologists in the early diagnosis and intervention of post-operative urosepsis. This study included 833 patients who underwent retrograde intrarenal surgery (RIRS) or percutaneous nephrolithotomy (PCNL) for kidney stones. Five machine learning algorithms and ten preoperative or intraoperative variables were used to develop a predictive model for SIRS. The SHapley Additive exPlanations (SHAP) method was used to explain the distribution of feature importance in the model's predictions. Among the 833 patients, 126 (15.1%) developed SIRS postoperatively. All five machine learning models demonstrated strong discrimination on the validation set (AUC: 0.690–0.858). The eXtreme Gradient Boosting (XGBoost) model was the best performer [AUC: 0.858; sensitivity: 0.877; specificity: 0.981; accuracy: 0.841; positive predictive value: 0.629; negative predictive value: 0.851]. The characteristic importance of the Machine Learning model (ML model) and SHAP results indicated Hounsfield Unit (HU), Urinary protein, Stone burden, and Serum uric acid as important predictors for the model. A machine learning model utilizing CT values was developed to predict postoperative SIRS in endoscopic kidney stone surgery. The model demonstrates strong predictive performance and can assist in assessing the risk of urosepsis in postoperative patients.",
    "authors": [
      "Jiaxin Li",
      "Yao Du",
      "Gaoming Huang",
      "Yawei Huang",
      "Xiaoqing Xi",
      "Zhenfeng Ye"
    ],
    "url": null,
    "venue": "Scientific Reports",
    "publicationDate": "2025-02-05",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.22399/ijasrar.21",
    "title": "Enhancing Digital Finance Security: AI-Based Approaches for Credit Card and Cryptocurrency Fraud Detection",
    "abstract": "The rise of digital finance has led to a surge in fraudulent activities, particularly in credit card transactions and cryptocurrency ecosystems. With financial crimes becoming more sophisticated, traditional fraud detection methods often fail to identify complex fraudulent patterns. This research explores the application of machine learning (ML) and artificial intelligence (AI) techniques to enhance the security of digital finance by detecting fraudulent activities in credit card transactions and cryptocurrency wallets within the USA. The study utilizes large-scale transaction datasets containing key financial indicators such as transaction frequency, spending patterns, anomaly scores, and network behaviors. To develop an AI-driven fraud detection framework, we implement and compare six machine learning models: XGBoost, RLightGBM, Decision Trees, K-Nearest Neighbors (KNN), Convolutional Neural Networks (CNNs), and Autoencoders. The models are trained on both structured financial data (e.g., credit card transaction logs) and unstructured blockchain transaction records (e.g., Bitcoin wallet addresses and transaction flows). To address data imbalance, the study applies the Synthetic Minority Over-sampling Technique (SMOTE), ensuring fair representation of fraudulent transactions. Model performance is evaluated using Precision, Recall, F1-score, and ROC-AUC metrics to determine the most effective fraud detection approach. Additionally, the research emphasizes data privacy and security, incorporating anonymization techniques and regulatory compliance measures to safeguard sensitive financial information. This study contributes to the ongoing fight against financial fraud by demonstrating how AI-based solutions can enhance the security and resilience of digital finance systems in the USA.",
    "authors": [
      "Ibrahim Y. Hafez",
      "Amr A. Abd El-Mageed"
    ],
    "url": null,
    "venue": "",
    "publicationDate": "2025-04-08",
    "CitationCount": 27,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s41598-025-86763-9",
    "title": "Machine learning classification and biochemical characteristics in the real-time diagnosis of gastric adenocarcinoma using Raman spectroscopy",
    "abstract": "This study aimed to identify biomolecular differences between benign gastric tissues (gastritis/intestinal metaplasia) and gastric adenocarcinoma and to evaluate the diagnostic power of Raman spectroscopy-based machine learning in gastric adenocarcinoma. Raman spectroscopy-based machine learning was applied in real-time during endoscopy in 19 patients (aged 51–85 years) with high-risk for gastric adenocarcinoma. Raman spectra were captured from suspicious lesions and adjacent normal mucosa, which were biopsied for matched histopathologic diagnosis. Spectral data were analyzed using principal component analysis (PCA) and linear discriminant analysis (LDA) with leave-one-out cross-validation (LOOCV) to develop a machine learning model for diagnosing gastric adenocarcinoma. High-quality spectra (800–3300 cm⁻¹) revealed distinct patterns: adenocarcinoma tissues had higher intensities below 3150 cm⁻¹, while benign tissues exhibited higher intensities between 3150 and 3290 cm⁻¹ (p < 0.001). The model achieved diagnostic accuracy, sensitivity, specificity, and AUC values of 0.905, 0.942, 0.787, and 0.957, respectively. Biochemical correlations suggested adenocarcinoma tissues had increased protein (e.g., phenylalanine), reduced lipids, and lower water content compared to benign tissues. This study highlights the potential of Raman spectroscopy with machine learning as a real-time diagnostic tool for gastric adenocarcinoma. Further validation could establish this technique as a non-invasive, accurate method to aid clinical decision-making during endoscopy.",
    "authors": [
      "Alex Noh",
      "Sabrina Xin Zi Quek",
      "Nuraini Zailani",
      "J. Wee",
      "Derrick Yong",
      "Byeong Yun Ahn",
      "Khek Yu Ho",
      "Hyunsoo Chung"
    ],
    "url": null,
    "venue": "Scientific Reports",
    "publicationDate": "2025-01-20",
    "CitationCount": 5,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1016/J.MATDES.2021.109532",
    "title": "Revealing high-fidelity phase selection rules for high entropy alloys: A combined CALPHAD and machine learning study",
    "abstract": null,
    "authors": [
      "Yingzhi Zeng",
      "Mengren Man",
      "K. Bai",
      "Yong-Wei Zhang"
    ],
    "url": "https://doi.org/10.1016/j.matdes.2021.109532",
    "venue": null,
    "publicationDate": "2021-01-29",
    "CitationCount": 80,
    "type": null,
    "isOpenAccess": true,
    "relevanceMetric": 1
  },
  {
    "source": "open_alex",
    "DOI": "10.56294/gr202581",
    "title": "Phishing Website Detection Using Machine Learning",
    "abstract": "Phishing attacks continue to be a danger in our digital world, with users being manipulated via rogue websites that trick them into disclosing confidential details. This article focuses on the use of machine learning techniques in the process of identifying phishing websites. In this case, a study was undertaken on critical factors such as URL extension, age of domain, and presence of HTTPS whilst exploring the effectiveness of Random Forest, Gradient Boosting and, Support Vector Machines algorithms in allocating a status of phishing or non-phishing. In this study, a dataset containing real URLs and phishing URLs are employed to build the model using feature extraction. Following this, the various algorithms were put to the test on this dataset; out of all the models, Random Forest performed exceptionally well having achieved an accuracy of 97.6%, Gradient Boosting was also found to be extremely effective possessing strong accuracy and accuracy. In this study we also compared and discussed methods to detect a phishing site. Some features that affect detection performance include URL length, special characters and the focus on even more aspects that need further development. The new proposed method improves the detection accuracy of the phishing websites because machine learning techniques are applied, recall (true positive) increase, while false positive decrease. The results enrich the electronic security system, as they enable effective detection in real time mode. This study has demonstrated the importance of employing cutting-edge techniques to deal with phishing attacks and safeguard users against advanced cyber threats, thus laying the groundwork for innovation in phishing detection systems in the future",
    "authors": [
      "Mowafaq Salem Alzboon",
      "Mohammad Subhi Al-Batah",
      "Muhyeeddin Alqaraleh",
      "Faisal Alzboon",
      "Lujin Alzboon"
    ],
    "url": null,
    "venue": "Gamification and Augmented Reality.",
    "publicationDate": "2025-01-16",
    "CitationCount": 6,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/en18040811",
    "title": "Sustainable Geothermal Energy: A Review of Challenges and Opportunities in Deep Wells and Shallow Heat Pumps for Transitioning Professionals",
    "abstract": "Geothermal energy has emerged as a cornerstone in renewable energy, delivering reliable, low-emission baseload electricity and heating solutions. This review bridges the current knowledge gap by addressing challenges and opportunities for engineers and scientists, especially those transitioning from other professions. It examines deep and shallow geothermal systems and explores the advanced technologies and skills required across various climates and environments. Transferable expertise in drilling, completion, subsurface evaluation, and hydrological assessment is required for geothermal development but must be adapted to meet the demands of high-temperature, high-pressure environments; abrasive rocks; and complex downhole conditions. Emerging technologies like Enhanced Geothermal Systems (EGSs) and closed-loop systems enable sustainable energy extraction from impermeable and dry formations. Shallow systems utilize near-surface thermal gradients, hydrology, and soil conditions for efficient heat pump operations. Sustainable practices, including reinjection, machine learning-driven fracture modeling, and the use of corrosion-resistant alloys, enhance well integrity and long-term performance. Case studies like Utah FORGE and the Geysers in California, US, demonstrate hydraulic stimulation, machine learning, and reservoir management, while Cornell University has advanced integrated hybrid geothermal systems. Government incentives, such as tax credits under the Inflation Reduction Act, and academic initiatives, such as adopting geothermal energy at Cornell and Colorado Mesa Universities, are accelerating geothermal integration. These advancements, combined with transferable expertise, position geothermal energy as a major contributor to the global transition to renewable energy.",
    "authors": [
      "Tawfik Elshehabi",
      "Mohammad Alfehaid"
    ],
    "url": "https://www.mdpi.com/1996-1073/18/4/811/pdf?version=1739099907",
    "venue": "Energies",
    "publicationDate": "2025-02-09",
    "CitationCount": 6,
    "type": "journal-article",
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1007/3-540-32390-2_77",
    "title": "Machine Learning Methods for Dialysis Therapy Decision Problem - Comparative Study",
    "abstract": null,
    "authors": [
      "W. Penar",
      "Michal Wozniak"
    ],
    "url": "",
    "venue": "International Conference on Computer Recognition Systems",
    "publicationDate": null,
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.71097/ijsat.v16.i1.1305",
    "title": "A Comprehensive Review of Cross-Validation Techniques in Machine Learning",
    "abstract": "In order to make sure that machine learning models are reliable and broadly applicable, cross-validation approaches are essential. They offer a methodical approach for adjusting hyperparameters, assessing model performance, and resolving issues with overfitting, unbalanced data, and temporal dependencies. This review article provides a thorough analysis of the many cross-validation strategies used in machine learning, from conventional techniques like k-fold cross-validation to more specialized strategies for particular kinds of data and learning objectives. In addition to current developments and best practices in cross-validation methodology, we go over the fundamentals, uses, benefits, and drawbacks of each technique. We also highlight important factors to take into account and recommendations for choosing suitable cross-validation procedures based on the properties of the dataset and the modelling goals. The objective of this study is to give academics and practitioners a thorough grasp of cross-validation approaches and their significance in developing robust and dependable machine learning models by synthesizing the available literature.",
    "authors": [
      "Meenu Bhagat",
      "Brijesh Bakariya"
    ],
    "url": null,
    "venue": "",
    "publicationDate": "2025-01-03",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.26434/chemrxiv-2025-tcr5h",
    "title": "Atomate2: Modular workflows for materials science",
    "abstract": "High-throughput density functional theory (DFT) calculations have become a vital element of computational materials science, enabling materials screening, property database generation, and training of “universal” machine learning models. While several software frameworks have emerged to support these computational efforts, new developments such as machine learned force fields have increased demands for more flexible and programmable workflow solutions. This manuscript introduces atomate2, a comprehensive evolution of our original atomate framework, designed to address existing limitations in computational materials research infrastructure. Key features include the support for multiple electronic structure packages and interoperability between them, along with generalizable workflows that can be written in an abstract form irrespective of the DFT package or machine learning force field used within them. Our hope is that atomate2’s improved usability and extensibility can reduce technical barriers for high-throughput research workflows and facilitate the rapid adoption of emerging methods in computational material science.",
    "authors": [
      "Alex M. Ganose",
      "Hrushikesh Sahasrabuddhe",
      "Mark Asta",
      "Kévin Beck",
      "Tathagata Biswas",
      "Alexander Bonkowski",
      "Joana Bustamante",
      "Xin Chen",
      "Yuan Chiang",
      "D. C. Chrzan",
      "Jacob M. Clary",
      "Orion Cohen",
      "Christina Ertural",
      "Max C. Gallant",
      "Janine George",
      "Sophie Gerits",
      "Rhys E. A. Goodall",
      "Rishabh D. Guha",
      "Geoffroy Hautier",
      "Matthew K. Horton",
      "Aaron D. Kaplan",
      "Ryan Kingsbury",
      "Matthew C. Kuner",
      "Bryant Li",
      "Xavier Linn",
      "Matthew J. McDermott",
      "Rohith Srinivaas Mohanakrishnan",
      "Aakash Ashok Naik",
      "Jeffrey B. Neaton",
      "Kristin A. Persson",
      "Guido Petretto",
      "Thomas A. R. Purcell",
      "Francesco Ricci",
      "Benjamin Rich",
      "Janosh Riebesell",
      "Gian‐Marco Rignanese",
      "Andrew Rosen",
      "Matthias Scheffler",
      "Jonathan Schmidt",
      "Jimmy‐Xuan Shen",
      "Alexander S. Sobolev",
      "Ravishankar Sundararaman",
      "Cooper Tezak",
      "Victor Trinquet",
      "Joel B. Varley",
      "Derek Vigil‐Fowler",
      "Duo Wang",
      "David Waroquiers",
      "Mingjian Wen",
      "Han Yang",
      "Hui Zheng",
      "Jiongzhi Zheng",
      "Zhuoying Zhu",
      "Anubhav Jain"
    ],
    "url": null,
    "venue": "",
    "publicationDate": "2025-01-22",
    "CitationCount": 4,
    "type": "posted-content",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s41524-024-01509-x",
    "title": "Feature engineering descriptors, transforms, and machine learning for grain boundaries and variable-sized atom clusters",
    "abstract": "Abstract Obtaining microscopic structure-property relationships for grain boundaries is challenging due to their complex atomic structures. Recent efforts use machine learning to derive these relationships, but the way the atomic grain boundary structure is represented can have a significant impact on the predictions. Key steps for property prediction common to grain boundaries and other variable-sized atom clustered structures include: (1) describing the atomic structure as a feature matrix, (2) transforming the variable-sized feature matrix to a fixed length common to all structures, and (3) applying a machine learning algorithm to predict properties from the transformed matrices. We examine how these steps and different combinations of engineered features impact the accuracy of grain boundary energy predictions using a database of over 7000 grain boundaries. Additionally, we assess how different engineered features support interpretability, offering insights into the physics of the structure-property relationships.",
    "authors": [
      "C. Braxton Owens",
      "Nithin Mathew",
      "Tyce W. Olaveson",
      "Jacob P. Tavenner",
      "Edward M. Kober",
      "Garritt J. Tucker",
      "Gus L. W. Hart",
      "Eric R. Homer"
    ],
    "url": null,
    "venue": "npj Computational Materials",
    "publicationDate": "2025-01-26",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/SMART52563.2021.9676299",
    "title": "Detection of Diseases in Plants using Convolutional Neural Networks",
    "abstract": "Most of the global population depends on agriculture and consider agricultural activities as their primary source of occupation to earn their income. If any problem occurs in this primary sector, then it is going to affect the livelihood and lives of the population seriously. Henceforth, it is important to keep up balance in the agricultural area by preventing it from something similar like the adverse effect of plant diseases. The area of artificial intelligence has taken an interesting turn in present times, with the growth of the Neural Networks based Intelligence and Machine Learning. These organically roused computational models can far outshines the presentation of past types of human-made consciousness in like manner artificial intelligence errands. One of the most amazing forms of Artificial Neural Network engineering is CNN. CNN is basically utilized to tackle troublesome picture-driven pattern recognition tasks and with their exact yet straightforward construction, provide a untangle method for starting with ANNs.A new strategy for identification of diseases in plants using CNN is proposed in this paper. The dataset utilized contains around 70,000 images including training and testing dataset. This paper gives a short prologue to CNNs, discussing lately expressed documents and newly framed strategies in evolving these brilliantly tremendous picture recognition models.",
    "authors": [
      "N. Agrawal",
      "Ajeet K. Sharma"
    ],
    "url": "",
    "venue": "SMART",
    "publicationDate": "2021-12-10",
    "CitationCount": 1,
    "type": [
      "Conference"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/info16020130",
    "title": "Text Classification: How Machine Learning Is Revolutionizing Text Categorization",
    "abstract": "The automated classification of texts into predefined categories has become increasingly prominent, driven by the exponential growth of digital documents and the demand for efficient organization. This paper serves as an in-depth survey of text classification and machine learning, consolidating diverse aspects of the field into a single, comprehensive resource—a rarity in the current body of literature. Few studies have achieved such breadth, and this work aims to provide a unified perspective, offering a significant contribution to researchers and the academic community. The survey examines the evolution of machine learning in text categorization (TC), highlighting its transformative advantages over manual classification, such as enhanced accuracy, reduced labor, and adaptability across domains. It delves into various TC tasks and contrasts machine learning methodologies with knowledge engineering approaches, demonstrating the strengths and flexibility of data-driven techniques. Key applications of TC are explored, alongside an analysis of critical machine learning methods, including document representation techniques and dimensionality reduction strategies. Moreover, this study evaluates a range of text categorization models, identifies persistent challenges like class imbalance and overfitting, and investigates emerging trends shaping the future of the field. It discusses essential components such as document representation, classifier construction, and performance evaluation, offering a well-rounded understanding of the current state of TC. Importantly, this paper also provides clear research directions, emphasizing areas requiring further innovation, such as hybrid methodologies, explainable AI (XAI), and scalable approaches for low-resource languages. By bridging gaps in existing knowledge and suggesting actionable paths forward, this work positions itself as a vital resource for academics and industry practitioners, fostering deeper exploration and development in text classification.",
    "authors": [
      "Hesham Allam",
      "Lisa Makubvure",
      "Benjamin Gyamfi",
      "K. Graham",
      "Kehinde Akinwolere"
    ],
    "url": null,
    "venue": "Information",
    "publicationDate": "2025-02-10",
    "CitationCount": 6,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1063/5.0124917",
    "title": "Biology-inspired optimization algorithms applied to intelligent input weights selection of an extreme learning machine in regression problems",
    "abstract": null,
    "authors": [
      "L. Demidova",
      "A. Gorchakov"
    ],
    "url": "",
    "venue": null,
    "publicationDate": null,
    "CitationCount": 2,
    "type": [
      "Conference"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.48550/arXiv.2405.15709",
    "title": "Information-theoretic Generalization Analysis for Expected Calibration Error",
    "abstract": "While the expected calibration error (ECE), which employs binning, is widely adopted to evaluate the calibration performance of machine learning models, theoretical understanding of its estimation bias is limited. In this paper, we present the first comprehensive analysis of the estimation bias in the two common binning strategies, uniform mass and uniform width binning. Our analysis establishes upper bounds on the bias, achieving an improved convergence rate. Moreover, our bounds reveal, for the first time, the optimal number of bins to minimize the estimation bias. We further extend our bias analysis to generalization error analysis based on the information-theoretic approach, deriving upper bounds that enable the numerical evaluation of how small the ECE is for unknown data. Experiments using deep learning models show that our bounds are nonvacuous thanks to this information-theoretic generalization analysis approach.",
    "authors": [
      "Futoshi Futami",
      "Masahiro Fujisawa"
    ],
    "url": "",
    "venue": "Neural Information Processing Systems",
    "publicationDate": "2024-05-24",
    "CitationCount": 5,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.32996/jcsts.2025.7.5.62",
    "title": "Proactive Cyber Threat Detection Using AI and Open-Source Intelligence",
    "abstract": "Frequent developments in cyber threats seriously threaten the digital systems in both the public and private sectors. Today, modern cyberattacks are too unpredictable for the old cybersecurity defenses and time-bound detection methods. Because there are more complex, numerous and distant threats today, to find them and address them before much damage can occur. In this work, look at integrating AI and OSINT to develop a system that can quickly detect any cyber threats in an organization. The researchers used the Hornet 40 dataset which includes network traffic collected over the course of 40 days from honeypots in eight places: Amsterdam, London, Frankfurt, San Francisco, New York, Singapore, Toronto, and Bangalore. To capture different activities from uninvited users, these honeypots received requests only on a specific non-standard SSH port. The information provided by Argus is in the form of detailed bidirectional NetFlow data that displays the effects of geography on various cyber-attacks. Various machine learning approaches are used within a data-driven system to spot and detect abnormal traffic and threats in the network such as Random Forest, Support Vector Machines (SVM), Long Short-Term Memory (LSTM) networks and Isolation Forests. At the same time, data, and findings from public threat intelligence, darknet sources and cybersecurity forums are studied using Natural Language Processing (NLP) to find important information about threats. As a result of this, the detection rate is improved by comparing suspicious traffic in honeypots with global findings and the reported IOCs. Combining AI and OSINT together allows the engine to read and analyze a lot of network data quickly and in almost real time. Joining these processes allows quick and early identification of advanced attacks such as zero-day attacks and intrusions. It is clear from the results that using this approach improves the accuracy of detection, lowers the number of false positives, and reveals attacks that tend to come from specific locations and are typically overlooked by other systems.",
    "authors": [
      "Jafrin Reza",
      "Md Imran Khan",
      "Sanjida Akrer Sarna"
    ],
    "url": "",
    "venue": "Journal of Computer Science and Technology Studies",
    "publicationDate": "2025-06-03",
    "CitationCount": 0,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.3991/ijet.v16i16.23405",
    "title": "Web-Based Learning Under Tacit Mining of Various Data Sources",
    "abstract": "Nowadays, many platforms provide open educational resources to learners. So, they must browse and explore several suggested contents to better assimilate their courses. To facilitate the selecting task of these resources, the present paper proposes an intelligent tutoring system that can access teaching contents available on the web automatically and offers them to learners as additional information sources. In doing so, the authors highlight the description logic approach and its knowledge representation strength that underwrites the modulization, inference, and querying about a web ontology language, and enhanced traditional tutoring systems architecture using ontologies and description logic to enable them to access various data sources on the web. Finally, this article concludes that the combination of machine learning with the semantic web has provided a supportive study environment and enhanced the schooling conditions within open and distance learning.",
    "authors": [
      "Abdelouahab Belazoui",
      "Abdelmoutia Telli",
      "C. Arar"
    ],
    "url": "https://online-journals.org/index.php/i-jet/article/download/23405/9791",
    "venue": "International Journal of Emerging Technologies in Learning (iJET)",
    "publicationDate": "2021-08-23",
    "CitationCount": 6,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 1
  },
  {
    "source": "open_alex",
    "DOI": "10.63180/jcsra.thestap.2025.3.3",
    "title": "Security and Privacy Challenges and Solutions in Autonomous Driving Systems: A Comprehensive Review",
    "abstract": "The rapid advancement of autonomous driving technology has transformed modern transportation, offering enhanced safety, efficiency, and convenience. However, as these vehicles become increasingly connected and reliant on complex software and sensor-based systems, they also become prime targets for a wide range of cyber and privacy threats. This review paper comprehensively examines the current landscape of security and privacy in autonomous driving systems. We explore emerging attack vectors targeting key components such as sensor perception, vehicle-to-everything (V2X) communication, machine learning models, and internal control systems. Particular attention is given to adversarial machine learning, GPS spoofing, Controller Area Network (CAN) bus attacks, and data privacy breaches. In parallel, we evaluate existing defense mechanisms and mitigation strategies, including intrusion detection systems (IDS), secure communication protocols, hardware-based security modules, and privacy-preserving architectures. We also highlight key challenges in securing autonomous systems, identify gaps in current research, and propose directions for future work to build resilient and trustworthy autonomous vehicles. This review aims to provide researchers and practitioners with a consolidated foundation for understanding and advancing the security posture of next-generation autonomous driving technologies.",
    "authors": [
      "Giuseppe Lippi",
      "Mahmoud Aljawarneh",
      "Qais Al-Na’amneh",
      "Rahaf Hazaymih",
      "Lachhman Das Dhomeja"
    ],
    "url": null,
    "venue": "",
    "publicationDate": "2025-05-05",
    "CitationCount": 7,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1007/978-3-319-14899-1_7",
    "title": "Fusion of Text and Audio Semantic Representations Through CCA",
    "abstract": null,
    "authors": [
      "Kamelia Aryafar",
      "A. Shokoufandeh"
    ],
    "url": "",
    "venue": "IAPR TC3 Workshop on Multimodal Pattern Recognition of Social Signals",
    "publicationDate": "2014-08-24",
    "CitationCount": 1,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.31891/csit-2024-2-1",
    "title": "THE CONCEPT OF AN INFORMATION SYSTEM FOR FORECASTING THE TEMPERATURE REGIME OF THE EARTH’S SURFACE BASED ON MACHINE LEARNING",
    "abstract": "The paper presents the concept of an information system for forecasting the temperature regime of the Earth’s surface using machine learning. Forecasting is based on historical data for a specific area. In order to increase the accuracy of forecasting results, an analysis of the features of climatic zones was carried out to identify patterns. A comparison of the dependence of the average monthly temperatures of the earth’s surface in countries depending on their location in climate zones was carried out. \nThe analysis of sources and scientific publications confirmed the relevance of the chosen research topic. Historical aspects of forecasting changes in climatic indicators are considered. Modern methods and approaches to temperature forecasting, their advantages and disadvantages are analyzed. An overview of the subject area was conducted and the regularities of temperature changes according to climate features were determined. \nA comparison of temperature regimes for countries located in different climate zones was made. For clarity, graphs of temperature changes were plotted and average indicators were calculated for each climate zone. \nThe results of the study confirm the need to adjust the temperature forecast for certain areas, taking into account their location in a specific climate zone. The revealed regularities in the temperature regime of the countries indicate the need for an individual approach to forecasting and the use of such machine learning methods that are best adapted to the dependencies observed in the climate zone. \nThe architecture of the information system for forecasting future temperatures depending on the climatic features of the studied territories is proposed. A concept has been formed for further research to find more accurate and effective approaches to predicting climate parameters and achieving the goals of sustainable development. \n  \n ",
    "authors": [
      "Olga Pavlova",
      "Vitalii Alekseiko"
    ],
    "url": "",
    "venue": "Computer Systems and Information Technologies",
    "publicationDate": "2024-06-27",
    "CitationCount": 5,
    "type": [
      "JournalArticle",
      "Review"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1016/j.dt.2024.06.004",
    "title": "Physics-informed machine learning model for prediction of ground reflected wave peak overpressure",
    "abstract": null,
    "authors": [
      "Haoyu Zhang",
      "Yuxin Xu",
      "Lihan Xiao",
      "Canjie Zhen"
    ],
    "url": "https://doi.org/10.1016/j.dt.2024.06.004",
    "venue": "Defence Technology",
    "publicationDate": "2024-06-01",
    "CitationCount": 3,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": null,
    "title": "St John's wort and depression.",
    "abstract": null,
    "authors": [
      "Andreas Völp"
    ],
    "url": "",
    "venue": null,
    "publicationDate": null,
    "CitationCount": 0,
    "type": [
      "LettersAndComments",
      "Review"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.3390/app15020672",
    "title": "C-SHAP: A Hybrid Method for Fast and Efficient Interpretability",
    "abstract": "Model interpretability is essential in machine learning, particularly for applications in critical fields like healthcare, where understanding model decisions is paramount. While SHAP (SHapley Additive exPlanations) has proven to be a robust tool for explaining machine learning predictions, its high computational cost limits its practicality for real-time use. To address this, we introduce C-SHAP (Clustering-Boosted SHAP), a hybrid method that combines SHAP with K-means clustering to reduce execution times significantly while preserving interpretability. C-SHAP excels across various datasets and machine learning methods, matching SHAP’s accuracy in selected features while maintaining an accuracy of 0.73 for Random Forest with substantially faster performance. Notably, in the Diabetes dataset collected by the National Institute of Diabetes and Digestive and Kidney Diseases, C-SHAP reduces the execution time from nearly 2000 s to just 0.21 s, underscoring its potential for scalable, efficient interpretability in time-sensitive applications. Such advancements in interpretability and efficiency may hold value for enhancing decision-making within software-intensive systems, aligning with evolving engineering approaches.",
    "authors": [
      "Golshid Ranjbaran",
      "Diego Reforgiato Recupero",
      "Chanchal K. Roy",
      "Kevin A. Schneider"
    ],
    "url": null,
    "venue": "Applied Sciences",
    "publicationDate": "2025-01-11",
    "CitationCount": 5,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.3390/agriculture14111900",
    "title": "UAV-Based Multispectral Winter Wheat Growth Monitoring with Adaptive Weight Allocation",
    "abstract": "Comprehensive growth index (CGI) more accurately reflects crop growth conditions than single indicators, which is crucial for precision irrigation, fertilization, and yield prediction. However, many current studies overlook the relationships between different growth parameters and their varying contributions to yield, leading to overlapping information and lower accuracy in monitoring crop growth. Therefore, this study focuses on winter wheat and constructs a comprehensive growth monitoring index (CGIac), based on adaptive weight allocation of growth parameters’ contribution to yield, using data such as leaf area index (LAI), soil plant analysis development (SPAD) values, plant height (PH), biomass (BM), and plant water content (PWC). Using UAV data on vegetation indices, feature selection was performed using the Elastic Net. The growth inversion model was then constructed using machine learning methods, including linear regression (LR), random forest (RF), gradient boosting (GB), and support vector regression (SVR). Based on the optimal growth inversion model for winter wheat, spatial distribution of wheat growth in the study area is obtained. The findings demonstrated that CGIac outperforms CGIav (constructed using equal weighting) and CGIcv (built using the coefficient of variation) in yield correlation and prediction accuracy. Specifically, the yield correlation of CGIac improved by up to 0.76 compared to individual indices, while yield prediction accuracy increased by up to 23.14%. Among the evaluated models, the RF model achieved the best performance, with a coefficient of determination (R2) of 0.895 and a root mean square error (RMSE) of 0.0058. A comparison with wheat orthophotos from the same period confirmed that the inversion results were highly consistent with actual growth conditions in the study area. The proposed method significantly improved the accuracy and applicability of winter wheat growth monitoring, overcoming the limitations of single parameters in growth prediction. Additionally, it provided new technological support and innovative solutions for regional crop monitoring and precision farming operations.",
    "authors": [
      "Lulu Zhang",
      "Xiaowen Wang",
      "Huanhuan Zhang",
      "Bo Zhang",
      "Jin Zhang",
      "Xinkang Hu",
      "Xintong Du",
      "Jianrong Cai",
      "Weidong Jia",
      "Chundu Wu"
    ],
    "url": "https://doi.org/10.3390/agriculture14111900",
    "venue": "Agriculture",
    "publicationDate": "2024-10-26",
    "CitationCount": 4,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1021/acs.est.4c12835",
    "title": "Predicting Membrane Fouling of Submerged Membrane Bioreactor Wastewater Treatment Plants Using Machine Learning",
    "abstract": "Membrane fouling remains a significant challenge in the operation of membrane bioreactors (MBRs). Plant operators rely heavily on observations of filtration performance from noisy sensor data to assess membrane fouling conditions and lab-based protocols for plant maintenance, often leading to inaccurate estimations of future performance and delayed membrane cleaning. This challenge is further compounded by the difficulty in integrating existing complex mechanistic models with the Internet of Things (IoT) systems of wastewater treatment plants (WWTPs). By harnessing data obtained from WWTPs, along with innovative data denoising and model training strategies, we developed a machine learning application (MBR-Net) that is capable of forecasting membrane fouling, as indicated by permeability, for a full-scale submerged MBR plant in real time. We show that the trained model can effectively predict one-day-ahead changes in irreversible fouling under different desired fluxes, cleaning conditions and feedwater conditions (with MAPE < 6.45%, MAE < 3.71 LMH bar-1, and R2 > 0.87 on two independent testing sets). Although data availability presented certain limitations in the model development process, the current results demonstrate the significant value of machine learning in membrane fouling predictions and in providing decision support for fouling mitigation strategies in full-scale WWTPs.",
    "authors": [
      "Yunyi Zhu",
      "Yuan Wang",
      "Elisabeth Zhu",
      "Zeyu Ma",
      "Hanchen Wang",
      "Chunsheng Chen",
      "Jing Guan",
      "T. David Waite"
    ],
    "url": null,
    "venue": "Environmental Science & Technology",
    "publicationDate": "2025-03-05",
    "CitationCount": 6,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1021/acs.iecr.4c03715",
    "title": "Advancing PFAS Remediation through Physics-Based Modeling of 2D Materials: Recent Progress, Challenges, and Opportunities",
    "abstract": "In recent years, the discovery and optimization of two-dimensional (2D) materials for environmental applications have garnered significant attention, particularly in the treatment of per- and polyfluoroalkyl substances (PFAS). PFAS, known for their strong carbon–fluorine bonds and persistence in the environment, present a critical challenge due to their resistance to degradation and harmful health effects. Traditional methods for PFAS remediation are often resource-intensive and inefficient. In this study, we propose leveraging physics-based machine learning (PBM) models to accelerate the discovery and optimization of 2D materials for PFAS treatment, particularly through adsorption and electrochemical degradation. The integration of fundamental physical laws with machine learning in an inverse PBM (IPBM) framework enables faster, more cost-effective predictions of material properties tailored to PFAS remediation. We highlight recent advancements in 2D materials, such as graphene, MXenes, and boron nitride, and their potential applications in environmental remediation. This approach promises to provide scalable, high-performance solutions to address the global PFAS contamination crisis, offering a path forward in developing advanced materials for sustainable water treatment technologies.",
    "authors": [
      "Monzure-Khoda Kazi",
      "Sunith Varghese",
      "Nahid Sarker",
      "Nirupam Aich",
      "Venkataramana Gadhamshetty"
    ],
    "url": null,
    "venue": "Industrial & Engineering Chemistry Research",
    "publicationDate": "2025-01-15",
    "CitationCount": 5,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": null,
    "title": "Predicting a Stock Portfolio with the Multivariate Bayesian Structural Time Series Model: Do News or Emotions Matter?",
    "abstract": null,
    "authors": [
      "S. Jammalamadaka",
      "Jinwen Qiu",
      "Ning Ning"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2019-09-21",
    "CitationCount": 33,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 1
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.2174/2210676612666220408095913",
    "title": "Artificial Intelligence Tools for Suicide Prevention in Adolescents and Young Adults",
    "abstract": "\n\nArtificial Intelligence is making a significant transformation in human lives. Its application in the medical and healthcare field has been also observed making an impact and improving overall outcomes. There has been a quest for similar processes in mental health due to the lack of observable changes in the areas of suicide prevention. In the last five years, there has been an emerging body of empirical research applying the technology of artificial intelligence (AI) and machine learning (ML) in mental health.\n\n\n\nTo review the clinical applicability of the AI/ML-based tools in suicide prevention.\n\n\n\nThe compelling question of predicting suicidality has been the focus of this research. \nWe performed a broad literature search and then identified 36 articles relevant to meet the objectives of this review. We review the available evidence and provide a brief overview of the advances in this field.\n\n\n\nIn the last five years, there has been more evidence supporting the implementation of these algorithms in clinical practice. Its current clinical utility is limited to using electronic health records and could be highly effective in conjunction with existing tools for suicide prevention. Other potential sources of relevant data include smart devices and social network sites. There are some serious questions about data privacy and ethics which need more attention while developing these new modalities in suicide research.\n",
    "authors": [
      "Mayank Gupta",
      "D. Ramar",
      "Rekha Vijayan",
      "Nihit Gupta"
    ],
    "url": "",
    "venue": "Adolescent Psychiatry",
    "publicationDate": "2022-04-08",
    "CitationCount": 0,
    "type": [
      "Review"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1155/2023/9853636",
    "title": "Retracted: Review on Epileptic Seizure Prediction: Machine Learning and Deep Learning Approaches",
    "abstract": "[This retracts the article DOI: 10.1155/2022/7751263.].",
    "authors": [
      "Computational and Mathematical Methods in Medicine"
    ],
    "url": "https://downloads.hindawi.com/journals/cmmm/2023/9853636.pdf",
    "venue": "Computational and Mathematical Methods in Medicine",
    "publicationDate": "2023-12-13",
    "CitationCount": 1,
    "type": [
      "JournalArticle",
      "Review"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.55041/ijsrem40567",
    "title": "Conversion of Sign Language into Text",
    "abstract": "This project is based on mark creation of new system which will be capable to translate sign language in the text which will helpful for the hearing impaired and Speech impaired people for better communication. With reference to state of art computer vision processes along with machine learning and deep learning the proposed system detects the sign language gesture in real time. It is for this reason that the primary objective of this solution is to reduce exclusion of sign language users from other individuals within their community and develop the most convenient, efficient, and stable means of turning gestures into words. Index Terms—Sign language recognition, text conversion, com- puter vision, machine learning, deep learning, real time gesture recognition, assistive technology for communication, use of ar- tificial sign language for hearing and speech impaired, human computer interface.",
    "authors": [
      "B B Neelakantappa",
      "N Akshatha",
      "M R Amrutha",
      "S. Anusha"
    ],
    "url": null,
    "venue": "INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "publicationDate": "2025-01-07",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/SP.2019.00073",
    "title": "F-BLEAU: Fast Black-Box Leakage Estimation",
    "abstract": "We consider the problem of measuring how much a system reveals about its secret inputs. We work in the black-box setting: we assume no prior knowledge of the system's internals, and we run the system for choices of secrets and measure its leakage from the respective outputs. Our goal is to estimate the Bayes risk, from which one can derive some of the most popular leakage measures (e.g., min-entropy leakage). The state-of-the-art method for estimating these leakage measures is the frequentist paradigm, which approximates the system's internals by looking at the frequencies of its inputs and outputs. Unfortunately, this does not scale for systems with large output spaces, where it would require too many input-output examples. Consequently, it also cannot be applied to systems with continuous outputs (e.g., time side channels, network traffic). In this paper, we exploit an analogy between Machine Learning (ML) and black-box leakage estimation to show that the Bayes risk of a system can be estimated by using a class of ML methods: the universally consistent learning rules; these rules can exploit patterns in the input-output examples to improve the estimates' convergence, while retaining formal optimality guarantees. We focus on a set of them, the nearest neighbor rules; we show that they significantly reduce the number of black-box queries required for a precise estimation whenever nearby outputs tend to be produced by the same secret; furthermore, some of them can tackle systems with continuous outputs. We illustrate the applicability of these techniques on both synthetic and real-world data, and we compare them with the state-of-the-art tool, leakiEst, which is based on the frequentist approach.",
    "authors": [
      "Giovanni Cherubin",
      "K. Chatzikokolakis",
      "C. Palamidessi"
    ],
    "url": "https://ieeexplore.ieee.org/ielx7/8826229/8835208/08835250.pdf",
    "venue": "IEEE Symposium on Security and Privacy",
    "publicationDate": "2019-02-04",
    "CitationCount": 36,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 4
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1016/j.cor.2022.105897",
    "title": "Towards a machine learning-aided metaheuristic framework for a production/distribution system design problem",
    "abstract": null,
    "authors": [
      "Zhifeng Xiao",
      "Jianing Zhi",
      "B. Keskin"
    ],
    "url": "",
    "venue": "Computers & Operations Research",
    "publicationDate": null,
    "CitationCount": 8,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/cictn57981.2023.10141225",
    "title": "Establishing the Correlation between Parkinson's and Heart Disease using Machine Learning Algorithm",
    "abstract": "Rhythmic shaking or tremors in a limb are symptoms of the medical condition known as Parkinson's Disease(PD) that affects the nervous system. A person with PD manifests PD-related symptoms. The condition slows down movement, affects speech, and the ability to perform a task, and writing becomes time-consuming for a person suffering from it. The prevalence of PD is 1-2 per 1000 people at any time. Parkinson's Disease cases rise with age and affect 1% of those over the age of 60. Even in this day and age, despite the numerous technological developments and advancements that have been made, the process of early disease detection is still challenging to achieve. As a result of this, it is important to develop automatic methods that are based on machine learning and that assist clinicians in accurately identifying this disease in its early phases. Literature supports the link between Parkinson's disease and the cardiovascular system. In research, the main objective is to establish the correlation between PD and heart disease by using a Machine learning algorithm named Extreme Gradient Boosting. The experiments were run utilizing python libraries such as Numpy, Pandas, and Scikit Learn. The study and experiment suggested that the PD in patients suffering from heart disease (HD) is comparatively less than in patients with a healthy heart.",
    "authors": [
      "Naman Kumar",
      "Sandhya Avasthi",
      "Ayushi Prakash"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2023-04-20",
    "CitationCount": 6,
    "type": [
      "Conference"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.18653/v1/D17-1156",
    "title": "Regularization techniques for fine-tuning in neural machine translation",
    "abstract": "We investigate techniques for supervised domain adaptation for neural machine translation where an existing model trained on a large out-of-domain dataset is adapted to a small in-domain dataset. In this scenario, overfitting is a major challenge. We investigate a number of techniques to reduce overfitting and improve transfer learning, including regularization techniques such as dropout and L2-regularization towards an out-of-domain prior. In addition, we introduce tuneout, a novel regularization technique inspired by dropout. We apply these techniques, alone and in combination, to neural machine translation, obtaining improvements on IWSLT datasets for English→German and English→Russian. We also investigate the amounts of in-domain training data needed for domain adaptation in NMT, and find a logarithmic relationship between the amount of training data and gain in BLEU score.",
    "authors": [
      "Antonio Valerio Miceli Barone",
      "B. Haddow",
      "Ulrich Germann",
      "Rico Sennrich"
    ],
    "url": "https://www.aclweb.org/anthology/D17-1156.pdf",
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "publicationDate": "2017-07-31",
    "CitationCount": 109,
    "type": [
      "JournalArticle",
      "Conference"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 9
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1038/s41467-019-10827-4",
    "title": "Approaching coupled cluster accuracy with a general-purpose neural network potential through transfer learning",
    "abstract": "Computational modeling of chemical and biological systems at atomic resolution is a crucial tool in the chemist’s toolset. The use of computer simulations requires a balance between cost and accuracy: quantum-mechanical methods provide high accuracy but are computationally expensive and scale poorly to large systems, while classical force fields are cheap and scalable, but lack transferability to new systems. Machine learning can be used to achieve the best of both approaches. Here we train a general-purpose neural network potential (ANI-1ccx) that approaches CCSD(T)/CBS accuracy on benchmarks for reaction thermochemistry, isomerization, and drug-like molecular torsions. This is achieved by training a network to DFT data then using transfer learning techniques to retrain on a dataset of gold standard QM calculations (CCSD(T)/CBS) that optimally spans chemical space. The resulting potential is broadly applicable to materials science, biology, and chemistry, and billions of times faster than CCSD(T)/CBS calculations. Computational modelling of chemical systems requires a balance between accuracy and computational cost. Here the authors use transfer learning to develop a general purpose neural network potential that approaches quantum-chemical accuracy for reaction thermochemistry, isomerization, and drug-like molecular torsions.",
    "authors": [
      "Justin S. Smith",
      "B. Nebgen",
      "R. Zubatyuk",
      "N. Lubbers",
      "Christian Devereux",
      "K. Barros",
      "S. Tretiak",
      "O. Isayev",
      "A. Roitberg"
    ],
    "url": "https://www.nature.com/articles/s41467-019-10827-4.pdf",
    "venue": "Nature Communications",
    "publicationDate": "2019-06-14",
    "CitationCount": 515,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": true,
    "relevanceMetric": 11
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1007/s00477-022-02188-0",
    "title": "Forecasting solar photosynthetic photon flux density under cloud cover effects: novel predictive model using convolutional neural network integrated with long short-term memory network",
    "abstract": "Forecast models of solar radiation incorporating cloud effects are useful tools to evaluate the impact of stochastic behaviour of cloud movement, real-time integration of photovoltaic energy in power grids, skin cancer and eye disease risk minimisation through solar ultraviolet (UV) index prediction and bio-photosynthetic processes through the modelling of solar photosynthetic photon flux density (PPFD). This research has developed deep learning hybrid model (i.e., CNN-LSTM) to factor in role of cloud effects integrating the merits of convolutional neural networks with long short-term memory networks to forecast near real-time (i.e., 5-min) PPFD in a sub-tropical region Queensland, Australia. The prescribed CLSTM model is trained with real-time sky images that depict stochastic cloud movements captured through a total sky imager (TSI-440) utilising advanced sky image segmentation to reveal cloud chromatic features into their statistical values, and to purposely factor in the cloud variation to optimise the CLSTM model. The model, with its competing algorithms (i.e., CNN, LSTM, deep neural network, extreme learning machine and multivariate adaptive regression spline), are trained with 17 distinct cloud cover inputs considering the chromaticity of red, blue, thin, and opaque cloud statistics, supplemented by solar zenith angle (SZA) to predict short-term PPFD. The models developed with cloud inputs yield accurate results, outperforming the SZA-based models while the best testing performance is recorded by the objective method (i.e., CLSTM) tested over a 7-day measurement period. Specifically, CLSTM yields a testing performance with correlation coefficient r = 0.92, root mean square error RMSE = 210.31 μ mol of photons m−2 s−1, mean absolute error MAE = 150.24 μ mol of photons m−2 s−1, including a relative error of RRMSE = 24.92% MAPE = 38.01%, and Nash Sutcliffe’s coefficient ENS = 0.85, and Legate and McCabe’s Index LM = 0.68 using cloud cover in addition to the SZA as an input. The study shows the importance of cloud inclusion in forecasting solar radiation and evaluating the risk with practical implications in monitoring solar energy, greenhouses and high-value agricultural operations affected by stochastic behaviour of clouds. Additional methodological refinements such as retraining the CLSTM model for hourly and seasonal time scales may aid in the promotion of agricultural crop farming and environmental risk evaluation applications such as predicting the solar UV index and direct normal solar irradiance for renewable energy monitoring systems.",
    "authors": [
      "R. Deo",
      "R. H. Grant",
      "Ann R. Webb",
      "Sujan Ghimire",
      "D. Igoe",
      "N. Downs",
      "Mohanad S. Al-Musaylh",
      "A. Parisi",
      "J. Soar"
    ],
    "url": "https://link.springer.com/content/pdf/10.1007/s00477-022-02188-0.pdf",
    "venue": null,
    "publicationDate": "2022-04-06",
    "CitationCount": 21,
    "type": null,
    "isOpenAccess": true,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1038/s41467-025-55987-8",
    "title": "Active learning-assisted directed evolution",
    "abstract": "Abstract Directed evolution (DE) is a powerful tool to optimize protein fitness for a specific application. However, DE can be inefficient when mutations exhibit non-additive, or epistatic, behavior. Here, we present Active Learning-assisted Directed Evolution (ALDE), an iterative machine learning-assisted DE workflow that leverages uncertainty quantification to explore the search space of proteins more efficiently than current DE methods. We apply ALDE to an engineering landscape that is challenging for DE: optimization of five epistatic residues in the active site of an enzyme. In three rounds of wet-lab experimentation, we improve the yield of a desired product of a non-native cyclopropanation reaction from 12% to 93%. We also perform computational simulations on existing protein sequence-fitness datasets to support our argument that ALDE can be more effective than DE. Overall, ALDE is a practical and broadly applicable strategy to unlock improved protein engineering outcomes.",
    "authors": [
      "Jason Yang",
      "Ravi Lal",
      "James C. Bowden",
      "Raul Astudillo",
      "Mikhail A. Hameedi",
      "Sukhvinder Kaur",
      "Matthew Hill",
      "Yisong Yue",
      "Frances H. Arnold"
    ],
    "url": null,
    "venue": "Nature Communications",
    "publicationDate": "2025-01-16",
    "CitationCount": 14,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1002/pen.27170",
    "title": "Machine learning for screw design in single‐screw extrusion",
    "abstract": "Abstract Artificial intelligence (AI) methods have significantly impacted various areas of technology, particularly in fields where large datasets are available. Screw designs are proprietary, and there is very limited information available in the open literature. In this study, we generated a dataset of 232 designs using computer simulation software for screw extrusion, involving solids transport, melting, and melt pumping. The parameters (features) and the outputs (targets) were introduced into four powerful machine learning (ML) algorithms. The capabilities of the four algorithms were assessed by comparing the predictions of each of the algorithms to the corresponding results of the simulations. Three of the algorithms demonstrated satisfactory performance, with the best‐performing one being further tested on an “unseen” dataset, which involved a screw of 75 mm and another of 127 mm in diameter. A machine‐learning technique called Permutation Feature Importance (PFI) was used to identify the features (parameters) with the greatest impact on the predictions. It is suggested that the same ML methodologies could be applied to datasets of existing real screw designs. Highlights Dataset obtained from simulation software. Four machine learning algorithms were employed. Assessment of algorithms based on training and testing data. Identification of parameters having greatest impact. Satisfactory predictions of mass flow rate, exit temperature, melting length, and more.",
    "authors": [
      "Nickolas D. Polychronopoulos",
      "Konstantinos Moustris",
      "Theodoros E. Karakasidis",
      "Janusz Sikora",
      "Volodymyr Krasinskyi",
      "Ioannis E. Sarris",
      "J. Vlachopoulos"
    ],
    "url": null,
    "venue": "Polymer Engineering and Science",
    "publicationDate": "2025-03-10",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1186/s12890-024-03160-0",
    "title": "Development and validation of radiology-clinical statistical and machine learning model for stroke-associated pneumonia after first intracerebral haemorrhage",
    "abstract": "Background Society is burdened with stroke-associated pneumonia (SAP) after intracerebral haemorrhage (ICH). Cerebral small vessel disease (CSVD) complicates clinical manifestations of stroke. In this study, we redefined the CSVD burden score and incorporated it into a novel radiological-clinical prediction model for SAP. Materials and methods A total of 1278 patients admitted to a tertiary hospital between 1 January 2010 and 31 December 2019 were included. The participants were divided into training and testing groups using fivefold cross-validation method. Four models, two traditional statistical models (logistic regression and ISAN) and two machine learning models (random forest and support vector machine), were established and evaluated. The outcomes and baseline characteristics were compared between the SAP and non-SAP groups. Results Among the of 1278 patients, 281(22.0%) developed SAP after their first ICH. Multivariate analysis revealed that the logistic regression (LR) model was superior in predicting SAP in both the training and testing groups. Independent predictors of SAP after ICH included total CSVD burden score (OR, 1.29; 95% CI, 1.03–1.54), haematoma extension into ventricle (OR, 2.28; 95% CI, 1.87–3.31), haematoma with multilobar involvement (OR, 2.14; 95% CI, 1.44–3.18), transpharyngeal intubation operation (OR, 3.89; 95% CI, 2.7–5.62), admission NIHSS score ≥ 10 (OR, 2.06; 95% CI, 1.42–3.01), male sex (OR, 1.69; 95% CI, 1.16–2.52), and age ≥ 67 (OR, 2.24; 95% CI, 1.56–3.22). The patients in the SAP group had worse outcomes than those in the non-SAP group. Conclusion This study established a clinically combined imaging model for predicting stroke-associated pneumonia and demonstrated superior performance compared with the existing ISAN model. Given the poor outcomes observed in patients with SAP, the use of individualised predictive nomograms is vital in clinical practice.",
    "authors": [
      "Wenru Zhang",
      "Ying Zhou",
      "Liuhui Xu",
      "Chaomin Qiu",
      "Zhixian Luo",
      "Zhenghao Jiang",
      "Xinyi Tao",
      "Yingjie Wu",
      "Shishi Yao",
      "Hang Huang",
      "Xinshi Wang",
      "Yunjun Yang",
      "Ru Lin"
    ],
    "url": "",
    "venue": "BMC Pulmonary Medicine",
    "publicationDate": "2024-07-24",
    "CitationCount": 2,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.15680/ijirset.2025.1401014",
    "title": "Integrating Predictive Analytics into Risk Management: A Modern Approach for Financial Institutions",
    "abstract": "This paper examines how predictive analytics enhances risk management in financial institutions. Advanced tools like machine learning and statistical modeling help predict risks, identify trends, and implement strategies to prevent losses by analyzing historical and real-time data. It covers the use of predictive analytics for credit risk, market risk, operational risk, and fraud detection, with practical case studies. Additionally, it discusses challenges, ethical issues, and prospects in this field.",
    "authors": [
      "Naga Ramesh Palakurti"
    ],
    "url": null,
    "venue": "International Journal of Innovative Research in Science Engineering and Technology",
    "publicationDate": "2025-01-30",
    "CitationCount": 7,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/BigData62323.2024.10825786",
    "title": "Personalized Federated Learning by Domain-Aware Network Pruning and Re-growth",
    "abstract": "Federated learning (FL) is a machine learning paradigm where multiple clients train their local machine learning models collaboratively (without sharing private data). One of the main challenges in FL is statistical heterogeneity of the data distributions across clients. Personalized FL (PFL) mitigates statistical heterogeneity by collaborative model training across homogeneous clients. In this paper, we propose a novel personalized federated learning by domain-aware network pruning and re-growth, called FedDNPR, that is more accurate as compared to existing PFL methods while maintaining high efficiency. This is achieved by 1) introducing a regularization term capturing heterogeneity of weights in iterative network pruning in order to reduce network sharing among unrelated clients, and 2) iterative network re-growing only from weights of related clients to increase network sharing among related clients. With FedDNPR, model clustering is performed considering the similarity between gradient updates in the last layers of the networks, with cosine as the similarity measure to achieve both accuracy and efficiency in model personalization. With extensive experimental evaluation, we show that FedDNPR significantly outperforms the state-of-the-art PFL approaches, while maintaining comparable efficiency.",
    "authors": [
      "Yuto Suzuki",
      "F. Kashani"
    ],
    "url": "",
    "venue": "BigData Congress [Services Society]",
    "publicationDate": "2024-12-15",
    "CitationCount": 1,
    "type": [
      "JournalArticle",
      "Conference"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1016/j.csbj.2025.01.006",
    "title": "The Role of Artificial Intelligence and Machine Learning in Predicting and Combating Antimicrobial Resistance",
    "abstract": "Antimicrobial resistance (AMR) is a major threat to global public health. The current review synthesizes to address the possible role of Artificial Intelligence and Machine Learning (AI/ML) in mitigating AMR. Supervised learning, unsupervised learning, deep learning, reinforcement learning, and natural language processing are some of the main tools used in this domain. AI/ML models can use various data sources, such as clinical information, genomic sequences, microbiome insights, and epidemiological data for predicting AMR outbreaks. Although AI/ML are relatively new fields, numerous case studies offer substantial evidence of their successful application in predicting AMR outbreaks with greater accuracy. These models can provide insights into the discovery of novel antimicrobials, the repurposing of existing drugs, and combination therapy through the analysis of their molecular structures. In addition, AI-based clinical decision support systems in real-time guide healthcare professionals to improve prescribing of antibiotics. The review also outlines how can AI improve AMR surveillance, analyze resistance trends, and enable early outbreak identification. Challenges, such as ethical considerations, data privacy, and model biases exist, however, the continuous development of novel methodologies enables AI/ML to play a significant role in combating AMR.",
    "authors": [
      "Hazrat Bilal",
      "Muhammad Nadeem Khan",
      "Sabir Khan",
      "Muhammad Shafiq",
      "Wenjie Fang",
      "Rahat Ullah Khan",
      "Mujeeb Ur Rahman",
      "Xiaohui Li",
      "Qiao‐Li Lv",
      "Bin Xu"
    ],
    "url": null,
    "venue": "Computational and Structural Biotechnology Journal",
    "publicationDate": "2025-01-01",
    "CitationCount": 14,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.1186/s40168-024-01996-6",
    "title": "Effects of data transformation and model selection on feature importance in microbiome classification data",
    "abstract": "Abstract Background Accurate classification of host phenotypes from microbiome data is crucial for advancing microbiome-based therapies, with machine learning offering effective solutions. However, the complexity of the gut microbiome, data sparsity, compositionality, and population-specificity present significant challenges. Microbiome data transformations can alleviate some of the aforementioned challenges, but their usage in machine learning tasks has largely been unexplored. Results Our analysis of over 8500 samples from 24 shotgun metagenomic datasets showed that it is possible to classify healthy and diseased individuals using microbiome data with minimal dependence on the choice of algorithm or transformation. Presence-absence transformations performed comparably to abundance-based transformations, and only a small subset of predictors is necessary for accurate classification. However, while different transformations resulted in comparable classification performance, the most important features varied significantly, which highlights the need to reevaluate machine learning–based biomarker detection. Conclusions Microbiome data transformations can significantly influence feature selection but have a limited effect on classification accuracy. Our findings suggest that while classification is robust across different transformations, the variation in feature selection necessitates caution when using machine learning for biomarker identification. This research provides valuable insights for applying machine learning to microbiome data and identifies important directions for future work.",
    "authors": [
      "Zuzanna Karwowska",
      "Oliver Aasmets",
      "Tomasz Kościółek",
      "Elin Org"
    ],
    "url": null,
    "venue": "Microbiome",
    "publicationDate": "2025-01-04",
    "CitationCount": 4,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.3389/fimmu.2024.1461424",
    "title": "Unraveling the role of ADAMs in clinical heterogeneity and the immune microenvironment of hepatocellular carcinoma: insights from single-cell, spatial transcriptomics, and bulk RNA sequencing",
    "abstract": "Background Hepatocellular carcinoma (HCC) is a prevalent and heterogeneous tumor with limited treatment options and unfavorable prognosis. The crucial role of a disintegrin and metalloprotease (ADAM) gene family in the tumor microenvironment of HCC remains unclear. Methods This study employed a novel multi-omics integration strategy to investigate the potential roles of ADAM family signals in HCC. A series of single-cell and spatial omics algorithms were utilized to uncover the molecular characteristics of ADAM family genes within HCC. The GSVA package was utilized to compute the scores for ADAM family signals, subsequently stratified into three categories: high, medium, and low ADAM signal levels through unsupervised clustering. Furthermore, we developed and rigorously validated an innovative and robust clinical prognosis assessment model by employing 99 mainstream machine learning algorithms in conjunction with co-expression feature spectra of ADAM family genes. To validate our findings, we conducted PCR and IHC experiments to confirm differential expression patterns within the ADAM family genes. Results Gene signals from the ADAM family were notably abundant in endothelial cells, liver cells, and monocyte macrophages. Single-cell sequencing and spatial transcriptomics analyses have both revealed the molecular heterogeneity of the ADAM gene family, further emphasizing its significant impact on the development and progression of HCC. In HCC tissues, the expression levels of ADAM9, ADAM10, ADAM15, and ADAM17 were markedly elevated. Elevated ADAM family signal scores were linked to adverse clinical outcomes and disruptions in the immune microenvironment and metabolic reprogramming. An ADAM prognosis signal, developed through the utilization of 99 machine learning algorithms, could accurately forecast the survival duration of HCC, achieving an AUC value of approximately 0.9. Conclusions This study represented the inaugural report on the deleterious impact and prognostic significance of ADAM family signals within the tumor microenvironment of HCC.",
    "authors": [
      "Junhong Chen",
      "Qihang Yuan",
      "Hewen Guan",
      "Yuying Cui",
      "Chang Fu",
      "Tianfu Wei",
      "Kai Liu"
    ],
    "url": "",
    "venue": "Frontiers in Immunology",
    "publicationDate": "2024-09-13",
    "CitationCount": 5,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": null,
    "title": "Using Multi-Class Machine Learning Methods to Predict Major League Baseball Pitches.",
    "abstract": null,
    "authors": [
      "Glenn Sidle"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2017-02-21",
    "CitationCount": 4,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 2
  },
  {
    "source": "open_alex",
    "DOI": "10.1002/cpt.3577",
    "title": "Machine Learning for Prediction of Drug Concentrations: Application and Challenges",
    "abstract": "With the advancements in algorithms and increased accessibility of multi‐source data, machine learning in pharmacokinetics is gaining interest. This review summarizes studies on machine learning‐based pharmacokinetics analysis up to September 2024, identified from the PubMed and IEEE Xplore databases. The main focus of this review is on the use of machine learning in predicting drug concentration. This review provides a comprehensive summary of the advances in the machine learning algorithms for pharmacokinetics analysis. Specifically, we describe the common practices in data preprocessing, the application scenarios of various algorithms, and the critical challenges that require attention. Most machine learning models show comparable performance to those of population pharmacokinetics models. Tree‐based algorithms and neural networks have the most applications. Furthermore, the use of ensemble modeling techniques can improve the accuracy of these models' predictions of drug concentrations, especially the ensembles of machine learning and pharmacometrics.",
    "authors": [
      "Shuqi Huang",
      "Qihan Xu",
      "Guoping Yang",
      "Junjie Ding",
      "Qi Pei"
    ],
    "url": null,
    "venue": "Clinical Pharmacology & Therapeutics",
    "publicationDate": "2025-02-03",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.48175/ijarsct-25619",
    "title": "A Review of Anomaly Identification in Finance Frauds Using Machine Learning Systems",
    "abstract": "The growing prevalence of digital financial payments has caused fraud in financial services to significantly increase globally. Artificial learning-based abnormality to identifying anomalies must be used because traditional fraud detection methods are not very adaptable to contemporary dishonest methods. This review examines various machine learning methodologies, including deep learning, techniques for detecting fraud using autonomous, freestanding, and semi-supervised learning methods in banking, insurance, stock market processes, and digital payment transactions. The study highlights challenges associated with imbalanced data distributions and adversarial attacks, which impact detection performance and interpretability. Furthermore, the paper explores current developments in the integration of transparent artificial intelligence with graph-based anomaly identification technologies to improve fraud detection systems' transparency and credibility. The constraints of the investigation are evaluated in order to guide the creation of contemporary counterfeiting detection platforms that use several machine learning techniques for enhanced accuracy, real-time processing, and privacy preservation. The findings provide insights into designing robust fraud detection systems aligned with banking institutions' requirements, ensuring enhanced financial security and compliance.",
    "authors": [
      "Ruhul Quddus Majumder"
    ],
    "url": null,
    "venue": "International Journal of Advanced Research in Science Communication and Technology",
    "publicationDate": "2025-04-25",
    "CitationCount": 5,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "open_alex",
    "DOI": "10.5194/acp-25-2365-2025",
    "title": "Opinion: Why all emergent constraints are wrong but some are useful – a machine learning perspective",
    "abstract": "Abstract. Global climate change projections are subject to substantial modelling uncertainties. A variety of emergent constraints, as well as several other statistical model evaluation approaches, have been suggested to address these uncertainties. However, they remain heavily debated in the climate science community. Still, the central idea to relate future model projections to already observable quantities has no real substitute. Here, we highlight the validation perspective of predictive skill in the machine learning community as a promising alternative viewpoint. Specifically, we argue for quantitative approaches in which each suggested constraining relationship can be evaluated comprehensively based on out-of-sample test data – on top of qualitative physical plausibility arguments that are already commonplace in the justification of new emergent constraints. Building on this perspective, we review machine learning ideas for new types of controlling-factor analyses (CFAs). The principal idea behind these CFAs is to use machine learning to find climate-invariant relationships in historical data which hold approximately under strong climate change scenarios. On the basis of existing data archives, these climate-invariant relationships can be validated in perfect-climate-model frameworks. From a machine learning perspective, we argue that such approaches are promising for three reasons: (a) they can be objectively validated for both past data and future data, (b) they provide more direct – and, by design, physically plausible – links between historical observations and potential future climates, and (c) they can take high-dimensional and complex relationships into account in the functions learned to constrain the future response. We demonstrate these advantages for two recently published CFA examples in the form of constraints on climate feedback mechanisms (clouds, stratospheric water vapour) and discuss further challenges and opportunities using the example of a rapid adjustment mechanism (aerosol–cloud interactions). We highlight several avenues for future work, including strategies to address non-linearity, to tackle blind spots in climate model ensembles, to integrate helpful physical priors into Bayesian methods, to leverage physics-informed machine learning, and to enhance robustness through causal discovery and inference.",
    "authors": [
      "Peer Nowack",
      "Duncan Watson‐Parris"
    ],
    "url": null,
    "venue": "Atmospheric chemistry and physics",
    "publicationDate": "2025-02-21",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.2172/1769745",
    "title": "Machine-Learning-Assisted Hybrid Earth System Modelling",
    "abstract": null,
    "authors": [
      "I. Szunyogh"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2021-03-09",
    "CitationCount": 0,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.16538/J.CNKI.JSUFE.2020.06.003",
    "title": "Innovation and Governance of Corporate Social Responsibility in the Digital and Intelligent Era",
    "abstract": "The essence of the digital and intelligent era is a round of economic and social changes driven by digital information technology. Human beings have moved from the traditional industrial economy era to the platform economy and intelligent algorithm society. Digital intelligence enterprises（Internet platform enterprises and artificial intelligence enterprises）driven by digital information technology have become micro organizations leading the new economic form to evolve continuously. Driven by artificial intelligence technology, products and services based on algorithm embedding have become important application scenarios of intelligent production and intelligent decision-making. Based on machine learning, intelligent data mining, and algorithm distribution, intelligent technology provides technical and organizational support for automatic production, automatic decision-making and automatic sales of all kinds of organizations. “Intelligent robot” has become a new “behavior subject”, which is different from the traditional moral subject and legal subject. The supervision and control of “intelligent robot” with independent analysis, reasoning and decision-making is becoming extremely urgent. However, the digital and intelligent technology in the digital society has not only reshaped the production efficiency and social productivity, but also caused a series of prominent social problems. The prominent problems are the lack and alienation of social responsibility of platform enterprises in the digital economy, the leakage of individual privacy caused by the application of intelligent algorithm, the ambiguity of the subject of enterprise ethics and responsibility, and the intensification of social inequality and social contradictions derived from data monopoly and algorithm discrimination. A series of new social problems need to be paid attention to in the digital and intelligent era. We believe that in the digital and intelligent era, corporate social responsibility faces all-round innovation, which is reflected in the fact that “intelligent robot” has become the new subject of CSR management and practice, platform enterprises and artificial intelligence enterprises（digital and intelligent enterprises）have become the new organizational carrier of CSR practice, platform business ecosystem has become the practice paradigm of corporate social responsibility, and algorithm governance has become the new focus of corporate social responsibility governance. Furthermore, based on the fact that algorithmic governance has become the key content of corporate social responsibility governance in the digital and intelligent era, this paper further studies three basic paradigms of algorithmic governance from the perspective of corporate social responsibility governance, namely, individual empowerment governance based on algorithm design and developers, traction governance based on digital and intelligent platform enterprises, and collaborative governance based on stakeholders（government, AI Association and application algorithm enterprises）, which reshape the new logic of algorithmic governance, and realize the sustainable and comprehensive value in the digital and intelligent era.",
    "authors": [
      "Yang Zhen",
      "Chen Jin"
    ],
    "url": "",
    "venue": null,
    "publicationDate": "2020-12-01",
    "CitationCount": 5,
    "type": null,
    "isOpenAccess": false,
    "relevanceMetric": 0
  },
  {
    "source": "semantic_scholar",
    "DOI": "10.1109/JBHI.2024.3372649",
    "title": "Developmental Prediction of Poststroke Patients in Activities of Daily Living by Using Tree-Structured Parzen Estimator–Optimized Stacking Ensemble Approaches",
    "abstract": "Poststroke injuries limit the daily activities of patients and cause considerable inconvenience. Therefore, predicting the activities of daily living (ADL) results of patients with stroke before hospital discharge can assist clinical workers in formulating more personalized and effective strategies for therapeutic intervention, and prepare hospital discharge plans that suit the patients needs. This study used the leave-one-out cross-validation procedure to evaluate the performance of the machine learning models. In addition, testing methods were used to identify the optimal weak learners, which were then combined to form a stacking model. Subsequently, a hyperparameter optimization algorithm was used to optimize the model hyperparameters. Finally, optimization algorithms were used to analyze each feature, and features of high importance were identified by limiting the number of features to be included in the machine learning models. After various features were fed into the learning models to predict the Barthel index (BI) at discharge, the results indicated that random forest (RF), adaptive boosting (AdaBoost), and multilayer perceptron (MLP) produced suitable results. The most critical prediction factor of this study was the BI at admission. Machine learning models can be used to assist clinical workers in predicting the ADL of patients with stroke at hospital discharge.",
    "authors": [
      "Pei-Hua Lin",
      "Ping-Huan Kuo",
      "Kuan-Lin Chen"
    ],
    "url": "",
    "venue": "IEEE journal of biomedical and health informatics",
    "publicationDate": "2024-03-04",
    "CitationCount": 5,
    "type": [
      "JournalArticle"
    ],
    "isOpenAccess": false,
    "relevanceMetric": 1
  },
  {
    "source": "open_alex",
    "DOI": "10.22399/ijcesen.2474",
    "title": "A Quantitative Framework for Portfolio Governance Using Machine Learning Techniques",
    "abstract": "This research explores how machine learning, a data-driven technology, can transform the management of investment portfolios. The objective is to assess whether machine learning can surpass the performance of traditional approaches, such as Modern Portfolio Theory, which have been established for decades. We explored various machine learning techniques, including those that predict stock prices, group investments based on patterns, and dynamically reallocate assets. Our comprehensive analysis leveraged a robust dataset spanning stock prices, economic indicators, as well as news and social media sentiment. Rigorous data processing and rigorous testing revealed that machine learning techniques substantially outclassed traditional approaches, generating higher returns while incurring lower risk, as reflected by a Sharpe ratio of 1.9 versus 1.3 for Modern Portfolio Theory. This technique also proved more adept at navigating volatile market conditions. Although this research faces challenges such as addressing noisy data or excessively complex models, the findings indicate that machine learning could be a transformative innovation in enhancing investment management practices. While the findings show promising results, there remains scope for further improvements, particularly in devising real-time adaptation mechanisms and ensuring equitable outcomes for all investors. The integration of machine learning into financial modeling presents a paradigm shift from traditional linear parametric methods, offering a more versatile framework for addressing complex challenges in portfolio governance (Dixon, and Halperin (2019)).",
    "authors": [
      "Yashasvi Makin",
      "Pavan K Gondhi"
    ],
    "url": null,
    "venue": "International Journal of Computational and Experimental Science and Engineering",
    "publicationDate": "2025-06-08",
    "CitationCount": 3,
    "type": "journal-article",
    "isOpenAccess": false,
    "relevanceMetric": 0
  }
]